# RD-Agent ç­–ç•¥å„ªåŒ–å¯¦ç¾æŒ‡å—

**ç›®æ¨™**ï¼šå¯¦ç¾ RD-Agent çš„ç­–ç•¥å„ªåŒ–åŠŸèƒ½ï¼Œè‡ªå‹•æ”¹é€²ç¾æœ‰äº¤æ˜“ç­–ç•¥

**ç•¶å‰ç‹€æ…‹**ï¼šåƒ…æœ‰ API æ¡†æ¶ï¼Œæ ¸å¿ƒé‚è¼¯æœªå¯¦ç¾
**é è¨ˆå·¥ä½œé‡**ï¼š2-3 é€±ï¼ˆ80-120 å°æ™‚ï¼‰
**é›£åº¦ç­‰ç´š**ï¼šğŸ”´ é«˜

---

## ğŸ“‹ åŠŸèƒ½æ¦‚è¿°

### è¼¸å…¥
- **ç­–ç•¥ ID**ï¼šè¦å„ªåŒ–çš„ç¾æœ‰ç­–ç•¥
- **å„ªåŒ–ç›®æ¨™**ï¼šä¾‹å¦‚ã€Œæå‡å¤æ™®æ¯”ç‡è‡³ 2.0ã€ã€Œé™ä½æœ€å¤§å›æ’¤è‡³ 15% ä»¥ä¸‹ã€
- **LLM æ¨¡å‹**ï¼š`gpt-4-turbo` æˆ– `gpt-4`
- **æœ€å¤§è¿­ä»£æ¬¡æ•¸**ï¼š5-20 æ¬¡

### è¼¸å‡º
- **å„ªåŒ–å¾Œçš„ç­–ç•¥ä»£ç¢¼**
- **å„ªåŒ–å‰å¾Œå°æ¯”**
  - Sharpe Ratio: 1.2 â†’ 1.8 (+50%)
  - Max Drawdown: 25% â†’ 18% (-28%)
  - Annual Return: 15% â†’ 22% (+47%)
- **æ”¹é€²å»ºè­°èªªæ˜**
  - ä¿®æ”¹äº†å“ªäº›åƒæ•¸
  - å¢åŠ äº†å“ªäº›é‚è¼¯
  - ç‚ºä»€éº¼é€™æ¨£æ”¹é€²

### å·¥ä½œåŸç†ï¼ˆCoSTEERï¼‰

```
1. åˆ†æåŸå§‹ç­–ç•¥
   â†“
2. è­˜åˆ¥å¼±é»ï¼ˆå›æ¸¬çµæœå·®çš„éƒ¨åˆ†ï¼‰
   â†“
3. LLM ç”Ÿæˆæ”¹é€²å‡è¨­
   â†“
4. ç”Ÿæˆæ”¹é€²å¾Œçš„ç­–ç•¥ä»£ç¢¼
   â†“
5. åŸ·è¡Œå›æ¸¬ä¸¦è©•ä¼°
   â†“
6. å°æ¯”åŸå§‹ç­–ç•¥ vs æ”¹é€²ç­–ç•¥
   â†“
7. å¦‚æœæ”¹é€²ä¸è¶³ï¼Œé‡è¤‡æ­¥é©Ÿ 3-6
   â†“
8. è¿”å›æœ€ä½³ç‰ˆæœ¬
```

---

## ğŸ—ï¸ å¯¦ç¾æ­¥é©Ÿ

### éšæ®µ 1ï¼šåŸºç¤æ¡†æ¶ï¼ˆ1-2 å¤©ï¼‰

#### 1.1 æ“´å±• RDAgentService

**æ–‡ä»¶**ï¼š`backend/app/services/rdagent_service.py`

æ–°å¢æ–¹æ³•ï¼š

```python
def execute_strategy_optimization(
    self,
    task_id: int,
    strategy_id: int,
    optimization_goal: str,
    max_iterations: int = 5,
    llm_model: str = "gpt-4-turbo"
) -> str:
    """åŸ·è¡Œç­–ç•¥å„ªåŒ–

    Args:
        task_id: RD-Agent ä»»å‹™ ID
        strategy_id: è¦å„ªåŒ–çš„ç­–ç•¥ ID
        optimization_goal: å„ªåŒ–ç›®æ¨™æè¿°
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•¸
        llm_model: LLM æ¨¡å‹

    Returns:
        log_dir: æ—¥èªŒç›®éŒ„è·¯å¾‘
    """
    logger.info(f"Starting strategy optimization for strategy {strategy_id}")

    # Step 1: ç²å–åŸå§‹ç­–ç•¥
    strategy = self.db.query(Strategy).filter(Strategy.id == strategy_id).first()
    if not strategy:
        raise ValueError(f"Strategy {strategy_id} not found")

    # Step 2: å›æ¸¬åŸå§‹ç­–ç•¥ï¼ˆç²å–åŸºæº–æŒ‡æ¨™ï¼‰
    baseline_metrics = self._backtest_strategy(strategy)

    # Step 3: æ§‹å»ºå„ªåŒ– Prompt
    optimization_prompt = self._build_optimization_prompt(
        strategy=strategy,
        baseline_metrics=baseline_metrics,
        optimization_goal=optimization_goal
    )

    # Step 4: åŸ·è¡Œ RD-Agent å„ªåŒ–å¾ªç’°
    log_dir = self._run_rdagent_optimization(
        strategy_id=strategy_id,
        prompt=optimization_prompt,
        max_iterations=max_iterations,
        llm_model=llm_model
    )

    return log_dir


def _backtest_strategy(self, strategy: Strategy) -> Dict[str, float]:
    """å›æ¸¬ç­–ç•¥ä¸¦è¿”å›ç¸¾æ•ˆæŒ‡æ¨™

    Args:
        strategy: ç­–ç•¥ç‰©ä»¶

    Returns:
        metrics: {
            "sharpe_ratio": 1.2,
            "annual_return": 0.15,
            "max_drawdown": -0.25,
            "win_rate": 0.55,
            "total_trades": 120
        }
    """
    from app.services.backtest_service import BacktestService
    from app.schemas.backtest import BacktestCreate

    # å‰µå»ºå›æ¸¬è«‹æ±‚
    backtest_request = BacktestCreate(
        strategy_id=strategy.id,
        start_datetime="2024-01-01",
        end_datetime="2024-12-31",
        initial_capital=100000.0,
        stock_ids=["TXCONT"]  # ä½¿ç”¨å°æŒ‡æœŸè²¨é€£çºŒåˆç´„
    )

    # åŸ·è¡Œå›æ¸¬
    backtest_service = BacktestService(self.db)
    backtest = backtest_service.create_backtest(
        user_id=strategy.user_id,
        data=backtest_request
    )

    # åŸ·è¡Œä¸¦ç­‰å¾…çµæœ
    result = backtest_service.execute_backtest(backtest.id)

    # æå–æŒ‡æ¨™
    return {
        "sharpe_ratio": result.sharpe_ratio or 0.0,
        "annual_return": result.annual_return or 0.0,
        "max_drawdown": result.max_drawdown or 0.0,
        "win_rate": result.win_rate or 0.0,
        "total_trades": result.total_trades or 0
    }


def _build_optimization_prompt(
    self,
    strategy: Strategy,
    baseline_metrics: Dict[str, float],
    optimization_goal: str
) -> str:
    """æ§‹å»ºç­–ç•¥å„ªåŒ–çš„ LLM Prompt

    Args:
        strategy: åŸå§‹ç­–ç•¥
        baseline_metrics: åŸºæº–ç¸¾æ•ˆæŒ‡æ¨™
        optimization_goal: å„ªåŒ–ç›®æ¨™

    Returns:
        prompt: å®Œæ•´çš„å„ªåŒ– Prompt
    """
    prompt = f"""
# ç­–ç•¥å„ªåŒ–ä»»å‹™

## åŸå§‹ç­–ç•¥

**åç¨±**: {strategy.name}
**æè¿°**: {strategy.description or "ç„¡æè¿°"}
**å¼•æ“**: {strategy.engine_type}

**ä»£ç¢¼**:
```python
{strategy.code}
```

## ç•¶å‰ç¸¾æ•ˆï¼ˆåŸºæº–ï¼‰

- **Sharpe Ratio**: {baseline_metrics['sharpe_ratio']:.2f}
- **Annual Return**: {baseline_metrics['annual_return']:.2%}
- **Max Drawdown**: {baseline_metrics['max_drawdown']:.2%}
- **Win Rate**: {baseline_metrics['win_rate']:.2%}
- **Total Trades**: {baseline_metrics['total_trades']}

## å„ªåŒ–ç›®æ¨™

{optimization_goal}

## è¦æ±‚

1. **åˆ†æç­–ç•¥å¼±é»**ï¼šè­˜åˆ¥ç•¶å‰ç­–ç•¥çš„å•é¡Œï¼ˆä¾‹å¦‚ï¼šéåº¦äº¤æ˜“ã€æ­¢æä¸ç•¶ã€åƒæ•¸ä¸ä½³ï¼‰
2. **æå‡ºæ”¹é€²æ–¹æ¡ˆ**ï¼šçµ¦å‡ºå…·é«”çš„æ”¹é€²å»ºè­°ï¼ˆä¾‹å¦‚ï¼šå„ªåŒ–åƒæ•¸ã€å¢åŠ éæ¿¾æ¢ä»¶ã€æ”¹é€²æ­¢æé‚è¼¯ï¼‰
3. **ç”Ÿæˆå„ªåŒ–å¾Œä»£ç¢¼**ï¼šè¼¸å‡ºå®Œæ•´çš„æ”¹é€²å¾Œç­–ç•¥ä»£ç¢¼ï¼ˆä¿æŒ {strategy.engine_type} æ ¼å¼ï¼‰
4. **é æœŸæ”¹é€²æ•ˆæœ**ï¼šèªªæ˜é æœŸåœ¨å“ªäº›æŒ‡æ¨™ä¸Šæœ‰æ”¹é€²

## å¯ç”¨æŠ€è¡“

### Backtrader ç­–ç•¥å¸¸ç”¨å„ªåŒ–æ–¹å‘

1. **åƒæ•¸å„ªåŒ–**
   - å‡ç·šé€±æœŸï¼ˆ5-200 æ—¥ï¼‰
   - RSI é–€æª»ï¼ˆ20-80ï¼‰
   - MACD åƒæ•¸ï¼ˆå¿«ç·šã€æ…¢ç·šã€ä¿¡è™Ÿç·šï¼‰

2. **é€²å‡ºå ´é‚è¼¯**
   - å¢åŠ ç¢ºèªä¿¡è™Ÿï¼ˆå¤šå€‹æŒ‡æ¨™å…±æŒ¯ï¼‰
   - éæ¿¾å™ªéŸ³ï¼ˆæˆäº¤é‡ç¢ºèªã€ATR éæ¿¾ï¼‰
   - é¿å…å‡çªç ´ï¼ˆå›æ¸¬ç¢ºèªã€æ™‚é–“éæ¿¾ï¼‰

3. **é¢¨éšªç®¡ç†**
   - å›ºå®šæ­¢æï¼ˆç™¾åˆ†æ¯”æˆ– ATR å€æ•¸ï¼‰
   - å‹•æ…‹æ­¢ç›ˆï¼ˆè¿½è¹¤æ­¢ç›ˆï¼‰
   - å€‰ä½ç®¡ç†ï¼ˆå‡±åˆ©å…¬å¼ã€å›ºå®šæ¯”ä¾‹ï¼‰

4. **äº¤æ˜“æˆæœ¬**
   - æ¸›å°‘éåº¦äº¤æ˜“ï¼ˆæŒå€‰æœ€ä½æ™‚é–“ï¼‰
   - è€ƒæ…®æ»‘é»å’Œæ‰‹çºŒè²»

### Qlib ç­–ç•¥å¸¸ç”¨å„ªåŒ–æ–¹å‘

1. **å› å­å„ªåŒ–**
   - å¢åŠ æ–°å› å­
   - å› å­çµ„åˆåŠ æ¬Š
   - å› å­æ¨™æº–åŒ–

2. **æ¨¡å‹å„ªåŒ–**
   - èª¿æ•´æ¨¡å‹åƒæ•¸ï¼ˆGBDT æ·±åº¦ã€å­¸ç¿’ç‡ï¼‰
   - ç‰¹å¾µå·¥ç¨‹ï¼ˆå› å­è¡ç”Ÿã€äº¤äº’é …ï¼‰
   - è¨“ç·´çª—å£èª¿æ•´

3. **é¢¨éšªæ§åˆ¶**
   - æœ€å¤§æŒå€‰é™åˆ¶
   - è¡Œæ¥­ä¸­æ€§
   - æ›æ‰‹ç‡æ§åˆ¶

## è¼¸å‡ºæ ¼å¼

è«‹æŒ‰ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼š

### 1. ç­–ç•¥åˆ†æ

ï¼ˆæè¿°ç•¶å‰ç­–ç•¥çš„å•é¡Œï¼‰

### 2. æ”¹é€²æ–¹æ¡ˆ

ï¼ˆåˆ—å‡ºå…·é«”çš„æ”¹é€²å»ºè­°ï¼‰

### 3. å„ªåŒ–å¾Œä»£ç¢¼

```python
# å®Œæ•´çš„ç­–ç•¥ä»£ç¢¼
```

### 4. é æœŸæ”¹é€²

- Sharpe Ratio: X.XX â†’ X.XX (+XX%)
- Annual Return: XX% â†’ XX% (+XX%)
- Max Drawdown: -XX% â†’ -XX% (æ”¹å–„ XX%)
"""
    return prompt


def _run_rdagent_optimization(
    self,
    strategy_id: int,
    prompt: str,
    max_iterations: int,
    llm_model: str
) -> str:
    """åŸ·è¡Œ RD-Agent å„ªåŒ–å¾ªç’°

    é€™æ˜¯æ ¸å¿ƒé‚è¼¯ï¼Œéœ€è¦æ•´åˆ RD-Agent çš„ CoSTEER æ©Ÿåˆ¶

    Args:
        strategy_id: ç­–ç•¥ ID
        prompt: å„ªåŒ– Prompt
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•¸
        llm_model: LLM æ¨¡å‹

    Returns:
        log_dir: æ—¥èªŒç›®éŒ„è·¯å¾‘
    """
    import os
    from pathlib import Path

    # TODO: æ•´åˆ RD-Agent æ ¸å¿ƒé‚è¼¯
    # åƒè€ƒï¼šhttps://github.com/microsoft/RD-Agent/blob/main/rdagent/scenarios/qlib/model/

    # æš«æ™‚è¿”å›æ¨¡æ“¬è·¯å¾‘
    log_dir = Path(f"/app/log/strategy_opt_{strategy_id}")
    log_dir.mkdir(parents=True, exist_ok=True)

    return str(log_dir)
```

#### 1.2 æ›´æ–° Celery ä»»å‹™

**æ–‡ä»¶**ï¼š`backend/app/tasks/rdagent_tasks.py`

ä¿®æ”¹ `run_strategy_optimization_task` å‡½æ•¸ï¼š

```python
@celery_app.task(bind=True, name="app.tasks.run_strategy_optimization_task")
def run_strategy_optimization_task(self: Task, task_id: int):
    """åŸ·è¡Œç­–ç•¥å„ªåŒ–ä»»å‹™"""
    db: Session = SessionLocal()

    try:
        service = RDAgentService(db)
        task = db.query(RDAgentTask).filter(RDAgentTask.id == task_id).first()

        if not task:
            logger.error(f"Task {task_id} not found")
            return {"status": "error", "message": "Task not found"}

        # æ›´æ–°ç‚ºåŸ·è¡Œä¸­
        service.update_task_status(task_id, TaskStatus.RUNNING)

        logger.info(f"Starting strategy optimization task {task_id}")
        logger.info(f"Task parameters: {task.input_params}")

        # æå–ä»»å‹™åƒæ•¸
        strategy_id = task.input_params.get("strategy_id")
        optimization_goal = task.input_params.get("optimization_goal")
        max_iterations = task.input_params.get("max_iterations", 5)
        llm_model = task.input_params.get("llm_model", "gpt-4-turbo")

        # ========== æ­¥é©Ÿ 1: åŸ·è¡Œç­–ç•¥å„ªåŒ– ==========
        logger.info(f"Step 1: Executing RD-Agent optimization with {max_iterations} iterations...")
        log_dir = service.execute_strategy_optimization(
            task_id=task_id,
            strategy_id=strategy_id,
            optimization_goal=optimization_goal,
            max_iterations=max_iterations,
            llm_model=llm_model
        )
        logger.info(f"RD-Agent optimization completed. Log directory: {log_dir}")

        # ========== æ­¥é©Ÿ 2: è§£æå„ªåŒ–çµæœ ==========
        logger.info("Step 2: Parsing optimization results...")
        optimized_strategies = service.parse_optimization_results(log_dir)
        logger.info(f"Parsed {len(optimized_strategies)} optimized versions")

        # ========== æ­¥é©Ÿ 3: å›æ¸¬æœ€ä½³ç‰ˆæœ¬ ==========
        logger.info("Step 3: Backtesting best optimized version...")
        best_strategy = optimized_strategies[0]  # å–ç¬¬ä¸€å€‹ï¼ˆæ‡‰è©²æ˜¯æœ€ä½³ï¼‰

        # ä¿å­˜å„ªåŒ–å¾Œçš„ç­–ç•¥åˆ°è³‡æ–™åº«
        from app.models.strategy import Strategy, StrategyStatus
        original_strategy = db.query(Strategy).filter(Strategy.id == strategy_id).first()

        optimized_strategy_obj = Strategy(
            user_id=original_strategy.user_id,
            name=f"{original_strategy.name} (Optimized v1)",
            description=best_strategy.get("description"),
            code=best_strategy.get("code"),
            engine_type=original_strategy.engine_type,
            status=StrategyStatus.DRAFT,
            parameters=best_strategy.get("parameters")
        )
        db.add(optimized_strategy_obj)
        db.commit()
        db.refresh(optimized_strategy_obj)

        # å›æ¸¬å„ªåŒ–å¾Œçš„ç­–ç•¥
        optimized_metrics = service._backtest_strategy(optimized_strategy_obj)

        # ========== æ­¥é©Ÿ 4: è¨ˆç®— LLM æˆæœ¬ ==========
        llm_calls, llm_cost = service.calculate_llm_costs(log_dir)

        # ========== æ­¥é©Ÿ 5: æ›´æ–°ä»»å‹™ç‚ºå®Œæˆ ==========
        service.update_task_status(
            task_id,
            TaskStatus.COMPLETED,
            result={
                "original_strategy_id": strategy_id,
                "optimized_strategy_id": optimized_strategy_obj.id,
                "baseline_metrics": service._backtest_strategy(original_strategy),
                "optimized_metrics": optimized_metrics,
                "improvements": {
                    "sharpe_ratio": optimized_metrics["sharpe_ratio"] - baseline["sharpe_ratio"],
                    "annual_return": optimized_metrics["annual_return"] - baseline["annual_return"],
                    "max_drawdown": optimized_metrics["max_drawdown"] - baseline["max_drawdown"]
                },
                "log_directory": log_dir,
                "message": "Strategy optimization completed successfully"
            },
            llm_calls=llm_calls,
            llm_cost=llm_cost
        )

        logger.info(f"Strategy optimization task {task_id} completed")
        return {"status": "success", "task_id": task_id}

    except Exception as e:
        logger.error(f"Strategy optimization task {task_id} failed: {str(e)}")
        service.update_task_status(task_id, TaskStatus.FAILED, error_message=str(e))
        return {"status": "error", "message": str(e)}

    finally:
        db.close()
```

---

### éšæ®µ 2ï¼šRD-Agent æ•´åˆï¼ˆ5-7 å¤©ï¼‰

é€™æ˜¯æœ€è¤‡é›œçš„éƒ¨åˆ†ï¼Œéœ€è¦æ·±å…¥ç ”ç©¶ RD-Agent æºç¢¼ã€‚

#### 2.1 ç ”ç©¶ RD-Agent å®˜æ–¹å¯¦ç¾

**åƒè€ƒ**ï¼š
- https://github.com/microsoft/RD-Agent/tree/main/rdagent/scenarios/qlib
- https://github.com/microsoft/RD-Agent/blob/main/rdagent/core/evolving_framework.py

**é—œéµæ¨¡çµ„**ï¼š
1. **Evolving Framework**ï¼šCoSTEER é€²åŒ–æ¡†æ¶
2. **Scenario**ï¼šå®šç¾©å ´æ™¯ï¼ˆQlib vs Backtraderï¼‰
3. **Hypothesis**ï¼šå‡è¨­ç”Ÿæˆ
4. **Experiment**ï¼šå¯¦é©—åŸ·è¡Œ
5. **Feedback**ï¼šåé¥‹åˆ†æ

#### 2.2 å‰µå»º Backtrader Scenario

RD-Agent é è¨­æ”¯æ´ Qlibï¼Œéœ€è¦ç‚º Backtrader å‰µå»ºè‡ªè¨‚ Scenarioã€‚

**æ–°å»ºæ–‡ä»¶**ï¼š`backend/app/rdagent/backtrader_scenario.py`

```python
"""RD-Agent Backtrader Scenario

å®šç¾© RD-Agent å¦‚ä½•å„ªåŒ– Backtrader ç­–ç•¥
"""

from rdagent.core.scenario import Scenario
from rdagent.core.evolving_framework import Hypothesis, Experiment, Feedback
from typing import Dict, Any, List


class BacktraderScenario(Scenario):
    """Backtrader ç­–ç•¥å„ªåŒ–å ´æ™¯"""

    def generate_hypothesis(
        self,
        baseline_code: str,
        baseline_metrics: Dict[str, float],
        optimization_goal: str,
        previous_feedback: List[Feedback] = None
    ) -> Hypothesis:
        """ç”Ÿæˆå„ªåŒ–å‡è¨­

        Args:
            baseline_code: åŸå§‹ç­–ç•¥ä»£ç¢¼
            baseline_metrics: åŸºæº–ç¸¾æ•ˆæŒ‡æ¨™
            optimization_goal: å„ªåŒ–ç›®æ¨™
            previous_feedback: ä¸Šä¸€è¼ªçš„åé¥‹

        Returns:
            hypothesis: å„ªåŒ–å‡è¨­
        """
        # TODO: æ§‹å»º Prompt ä¸¦èª¿ç”¨ LLM
        # ç”Ÿæˆæ”¹é€²å»ºè­°å’Œé æœŸæ•ˆæœ
        pass

    def create_experiment(self, hypothesis: Hypothesis) -> Experiment:
        """åŸºæ–¼å‡è¨­å‰µå»ºå¯¦é©—

        Args:
            hypothesis: å„ªåŒ–å‡è¨­

        Returns:
            experiment: å¯¦é©—ç‰©ä»¶ï¼ˆåŒ…å«å„ªåŒ–å¾Œçš„ç­–ç•¥ä»£ç¢¼ï¼‰
        """
        # TODO: å°‡å‡è¨­è½‰æ›ç‚ºå¯åŸ·è¡Œçš„ç­–ç•¥ä»£ç¢¼
        pass

    def run_experiment(self, experiment: Experiment) -> Dict[str, Any]:
        """åŸ·è¡Œå¯¦é©—ï¼ˆå›æ¸¬å„ªåŒ–å¾Œçš„ç­–ç•¥ï¼‰

        Args:
            experiment: å¯¦é©—ç‰©ä»¶

        Returns:
            results: å›æ¸¬çµæœ
        """
        # TODO: åŸ·è¡Œ Backtrader å›æ¸¬
        # è¿”å›ç¸¾æ•ˆæŒ‡æ¨™
        pass

    def analyze_feedback(
        self,
        experiment: Experiment,
        results: Dict[str, Any],
        baseline_metrics: Dict[str, float]
    ) -> Feedback:
        """åˆ†æå¯¦é©—åé¥‹

        Args:
            experiment: å¯¦é©—ç‰©ä»¶
            results: å¯¦é©—çµæœ
            baseline_metrics: åŸºæº–æŒ‡æ¨™

        Returns:
            feedback: åé¥‹ç‰©ä»¶ï¼ˆåŒ…å«æ”¹é€²å»ºè­°ï¼‰
        """
        # TODO: å°æ¯”å¯¦é©—çµæœèˆ‡åŸºæº–
        # åˆ†ææ”¹é€²æˆ–æƒ¡åŒ–çš„éƒ¨åˆ†
        # ç”Ÿæˆä¸‹ä¸€è¼ªå„ªåŒ–æ–¹å‘
        pass
```

#### 2.3 æ•´åˆ CoSTEER é€²åŒ–å¾ªç’°

**ä¿®æ”¹**ï¼š`backend/app/services/rdagent_service.py`

```python
def _run_rdagent_optimization(
    self,
    strategy_id: int,
    prompt: str,
    max_iterations: int,
    llm_model: str
) -> str:
    """åŸ·è¡Œ RD-Agent å„ªåŒ–å¾ªç’°"""

    from rdagent.core.evolving_framework import EvolvingFramework
    from app.rdagent.backtrader_scenario import BacktraderScenario

    # å‰µå»ºé€²åŒ–æ¡†æ¶
    framework = EvolvingFramework(
        scenario=BacktraderScenario(),
        max_iterations=max_iterations,
        llm_model=llm_model
    )

    # ç²å–åŸå§‹ç­–ç•¥
    strategy = self.db.query(Strategy).filter(Strategy.id == strategy_id).first()
    baseline_metrics = self._backtest_strategy(strategy)

    # åŸ·è¡Œé€²åŒ–å¾ªç’°
    results = framework.evolve(
        baseline_code=strategy.code,
        baseline_metrics=baseline_metrics,
        optimization_goal=prompt
    )

    # ä¿å­˜æ—¥èªŒ
    log_dir = self._save_optimization_logs(strategy_id, results)

    return log_dir
```

---

### éšæ®µ 3ï¼šçµæœè§£æèˆ‡å±•ç¤ºï¼ˆ2-3 å¤©ï¼‰

#### 3.1 è§£æå„ªåŒ–çµæœ

**æ–°å¢æ–¹æ³•**ï¼š`RDAgentService.parse_optimization_results()`

```python
def parse_optimization_results(self, log_dir: str) -> List[Dict[str, Any]]:
    """è§£æç­–ç•¥å„ªåŒ–çµæœ

    å¾æ—¥èªŒä¸­æå–æ‰€æœ‰å„ªåŒ–ç‰ˆæœ¬çš„ç­–ç•¥ä»£ç¢¼å’Œç¸¾æ•ˆæŒ‡æ¨™

    Args:
        log_dir: RD-Agent æ—¥èªŒç›®éŒ„

    Returns:
        strategies: å„ªåŒ–å¾Œçš„ç­–ç•¥åˆ—è¡¨ï¼ŒæŒ‰ç¸¾æ•ˆæ’åº
    """
    from pathlib import Path
    import pickle

    log_path = Path(log_dir)
    strategies = []

    # éæ­·æ‰€æœ‰è¿­ä»£ç›®éŒ„
    for loop_dir in sorted(log_path.glob("Loop_*")):
        # è®€å–å„ªåŒ–å¾Œçš„ç­–ç•¥ä»£ç¢¼
        strategy_file = loop_dir / "optimized_strategy.pkl"
        if strategy_file.exists():
            with open(strategy_file, "rb") as f:
                strategy_data = pickle.load(f)
                strategies.append(strategy_data)

    # æŒ‰ Sharpe Ratio æ’åº
    strategies.sort(
        key=lambda x: x.get("metrics", {}).get("sharpe_ratio", 0),
        reverse=True
    )

    return strategies
```

#### 3.2 å‰ç«¯å±•ç¤ºï¼ˆå‰ç«¯é–‹ç™¼ï¼‰

**æ–°å»ºé é¢**ï¼š`frontend/pages/rdagent/strategy-optimization.vue`

å±•ç¤ºå…§å®¹ï¼š
- åŸå§‹ç­–ç•¥ vs å„ªåŒ–å¾Œç­–ç•¥ï¼ˆä»£ç¢¼å°æ¯”ï¼‰
- ç¸¾æ•ˆæŒ‡æ¨™å°æ¯”ï¼ˆåœ–è¡¨ï¼‰
- æ”¹é€²èªªæ˜ï¼ˆæ–‡å­—ï¼‰
- ä¸€éµæ‡‰ç”¨å„ªåŒ–ï¼ˆæŒ‰éˆ•ï¼‰

---

### éšæ®µ 4ï¼šæ¸¬è©¦èˆ‡å„ªåŒ–ï¼ˆ3-5 å¤©ï¼‰

#### 4.1 å–®å…ƒæ¸¬è©¦

**æ–°å»ºæ–‡ä»¶**ï¼š`backend/tests/services/test_strategy_optimization.py`

```python
import pytest
from app.services.rdagent_service import RDAgentService
from app.models.strategy import Strategy

def test_backtest_strategy():
    """æ¸¬è©¦ç­–ç•¥å›æ¸¬åŠŸèƒ½"""
    # TODO: å‰µå»ºæ¸¬è©¦ç­–ç•¥
    # TODO: åŸ·è¡Œå›æ¸¬
    # TODO: é©—è­‰çµæœæ ¼å¼

def test_build_optimization_prompt():
    """æ¸¬è©¦å„ªåŒ– Prompt æ§‹å»º"""
    # TODO: å‰µå»ºæ¸¬è©¦æ•¸æ“š
    # TODO: ç”Ÿæˆ Prompt
    # TODO: é©—è­‰ Prompt å…§å®¹

def test_optimization_cycle():
    """æ¸¬è©¦å®Œæ•´å„ªåŒ–å¾ªç’°"""
    # TODO: å‰µå»ºç°¡å–®ç­–ç•¥
    # TODO: åŸ·è¡Œå„ªåŒ–
    # TODO: é©—è­‰æ”¹é€²æ•ˆæœ
```

#### 4.2 æ•´åˆæ¸¬è©¦

**æ¸¬è©¦æµç¨‹**ï¼š
1. å‰µå»ºç°¡å–®çš„å‡ç·šç­–ç•¥
2. åŸ·è¡Œå„ªåŒ–ï¼ˆmax_iterations=2ï¼‰
3. é©—è­‰ç”Ÿæˆæ–°ç­–ç•¥
4. é©—è­‰å›æ¸¬åŸ·è¡ŒæˆåŠŸ
5. é©—è­‰ç¸¾æ•ˆæŒ‡æ¨™æ”¹å–„

#### 4.3 æ€§èƒ½å„ªåŒ–

**é—œéµå•é¡Œ**ï¼š
- å›æ¸¬å¯èƒ½å¾ˆæ…¢ï¼ˆæ¯æ¬¡è¿­ä»£ 1-2 åˆ†é˜ï¼‰
- LLM èª¿ç”¨æˆæœ¬é«˜

**å„ªåŒ–æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨å¿«é€Ÿå›æ¸¬çª—å£ï¼ˆ6 å€‹æœˆè€Œé 1 å¹´ï¼‰
- é™åˆ¶è¿­ä»£æ¬¡æ•¸ï¼ˆ5-10 æ¬¡ï¼‰
- å¿«å–å›æ¸¬çµæœ
- ä½¿ç”¨ GPT-4-turboï¼ˆæ›´ä¾¿å®œï¼‰

---

## ğŸ“Š é æœŸæ•ˆæœ

### è¼¸å…¥ç¯„ä¾‹

```json
{
  "strategy_id": 2,
  "optimization_goal": "æå‡å¤æ™®æ¯”ç‡è‡³ 2.0 ä»¥ä¸Šï¼ŒåŒæ™‚é™ä½æœ€å¤§å›æ’¤è‡³ 15% ä»¥ä¸‹",
  "llm_model": "gpt-4-turbo",
  "max_iterations": 5
}
```

### è¼¸å‡ºç¯„ä¾‹

```json
{
  "task_id": 25,
  "status": "COMPLETED",
  "result": {
    "original_strategy_id": 2,
    "optimized_strategy_id": 156,
    "baseline_metrics": {
      "sharpe_ratio": 1.2,
      "annual_return": 0.15,
      "max_drawdown": -0.25,
      "win_rate": 0.52
    },
    "optimized_metrics": {
      "sharpe_ratio": 1.85,
      "annual_return": 0.22,
      "max_drawdown": -0.14,
      "win_rate": 0.58
    },
    "improvements": {
      "sharpe_ratio": +0.65,
      "annual_return": +0.07,
      "max_drawdown": +0.11,
      "win_rate": +0.06
    },
    "optimization_summary": "å„ªåŒ–é‡é»ï¼š1) å°‡çŸ­å‡ç·šé€±æœŸå¾ 5 èª¿æ•´ç‚º 8ï¼Œ2) å¢åŠ  RSI < 30 çš„ç¢ºèªæ¢ä»¶é¿å…å‡çªç ´ï¼Œ3) åŠ å…¥ ATR æ­¢æé™ä½æœ€å¤§å›æ’¤"
  },
  "llm_calls": 42,
  "llm_cost": 3.25
}
```

---

## ğŸš§ æŠ€è¡“æŒ‘æˆ°

### æŒ‘æˆ° 1ï¼šRD-Agent ä¸åŸç”Ÿæ”¯æ´ Backtrader

**å•é¡Œ**ï¼šRD-Agent é è¨­ç‚º Qlib è¨­è¨ˆ

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
1. ç ”ç©¶ RD-Agent çš„ Qlib Scenario å¯¦ç¾
2. æŠ½è±¡å‡ºé€šç”¨ä»‹é¢
3. å¯¦ç¾ Backtrader Scenario
4. æ¸¬è©¦å…¼å®¹æ€§

**é è¨ˆæ™‚é–“**ï¼š3-4 å¤©

### æŒ‘æˆ° 2ï¼šå›æ¸¬è€—æ™‚

**å•é¡Œ**ï¼šæ¯æ¬¡è¿­ä»£éœ€è¦å®Œæ•´å›æ¸¬ï¼ˆ1-2 åˆ†é˜ï¼‰

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨è¼ƒçŸ­çš„å›æ¸¬çª—å£ï¼ˆ6 å€‹æœˆï¼‰
2. å¹³è¡ŒåŸ·è¡Œå¤šå€‹å€™é¸ç­–ç•¥
3. å¿«å–ä¸è®Šçš„éƒ¨åˆ†ï¼ˆæ•¸æ“šè¼‰å…¥ï¼‰

**é è¨ˆæ™‚é–“**ï¼š1-2 å¤©

### æŒ‘æˆ° 3ï¼šLLM ç”Ÿæˆä»£ç¢¼å“è³ª

**å•é¡Œ**ï¼šLLM å¯èƒ½ç”Ÿæˆèªæ³•éŒ¯èª¤æˆ–é‚è¼¯éŒ¯èª¤çš„ä»£ç¢¼

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
1. åœ¨ Prompt ä¸­æä¾›å®Œæ•´çš„ç­–ç•¥æ¨¡æ¿
2. å¢åŠ ä»£ç¢¼é©—è­‰æ­¥é©Ÿï¼ˆèªæ³•æª¢æŸ¥ï¼‰
3. æä¾›éŒ¯èª¤åé¥‹çµ¦ LLM è®“å…¶ä¿®æ­£
4. é™åˆ¶å…è¨±ä¿®æ”¹çš„éƒ¨åˆ†ï¼ˆåªæ”¹åƒæ•¸æˆ–é‚è¼¯ï¼‰

**é è¨ˆæ™‚é–“**ï¼š2-3 å¤©

### æŒ‘æˆ° 4ï¼šå„ªåŒ–ç›®æ¨™å¤šæ¨£åŒ–

**å•é¡Œ**ï¼šä¸åŒç”¨æˆ¶æœ‰ä¸åŒå„ªåŒ–ç›®æ¨™

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
1. æ”¯æ´å¤šç›®æ¨™å„ªåŒ–ï¼ˆPareto å‰æ²¿ï¼‰
2. å…è¨±ç”¨æˆ¶æŒ‡å®šæ¬Šé‡ï¼ˆä¾‹å¦‚ Sharpe 60%, Drawdown 40%ï¼‰
3. æä¾›é è¨­å„ªåŒ–æ¨¡æ¿ï¼ˆç©©å¥å‹ã€æ¿€é€²å‹ï¼‰

**é è¨ˆæ™‚é–“**ï¼š2 å¤©

---

## ğŸ“ å¯¦ç¾æª¢æŸ¥æ¸…å–®

### ç¬¬ 1 é€±

- [ ] ç ”ç©¶ RD-Agent å®˜æ–¹æ–‡æª”å’Œæºç¢¼
- [ ] å¯¦ç¾ `_backtest_strategy()` æ–¹æ³•
- [ ] å¯¦ç¾ `_build_optimization_prompt()` æ–¹æ³•
- [ ] å¯¦ç¾åŸºç¤çš„ `execute_strategy_optimization()` æ¡†æ¶
- [ ] æ›´æ–° Celery ä»»å‹™ï¼ˆ`run_strategy_optimization_task`ï¼‰

### ç¬¬ 2 é€±

- [ ] å¯¦ç¾ `BacktraderScenario` é¡
- [ ] æ•´åˆ RD-Agent CoSTEER é€²åŒ–æ¡†æ¶
- [ ] å¯¦ç¾ `_run_rdagent_optimization()` æ ¸å¿ƒé‚è¼¯
- [ ] å¯¦ç¾ `parse_optimization_results()` æ–¹æ³•
- [ ] æ¸¬è©¦å–®è¼ªå„ªåŒ–å¾ªç’°

### ç¬¬ 3 é€±

- [ ] ç·¨å¯«å–®å…ƒæ¸¬è©¦
- [ ] åŸ·è¡Œæ•´åˆæ¸¬è©¦
- [ ] æ€§èƒ½å„ªåŒ–ï¼ˆå¿«å–ã€å¹³è¡ŒåŒ–ï¼‰
- [ ] å‰ç«¯é é¢é–‹ç™¼
- [ ] æ–‡æª”æ’°å¯«
- [ ] ä¸Šç·šéƒ¨ç½²

---

## ğŸ’° æˆæœ¬ä¼°ç®—

### é–‹ç™¼æˆæœ¬

- **é–‹ç™¼æ™‚é–“**ï¼š80-120 å°æ™‚ï¼ˆ2-3 é€±ï¼‰
- **äººåŠ›æˆæœ¬**ï¼šå‡è¨­æ™‚è–ª $50ï¼Œç¸½è¨ˆ $4,000-$6,000

### é‹ç‡Ÿæˆæœ¬ï¼ˆæ¯æ¬¡å„ªåŒ–ï¼‰

- **LLM æˆæœ¬**ï¼š$2-5 USDï¼ˆ5-10 æ¬¡è¿­ä»£ï¼‰
- **é‹ç®—æˆæœ¬**ï¼šå¿½ç•¥ä¸è¨ˆï¼ˆå›æ¸¬åœ¨æœ¬åœ°åŸ·è¡Œï¼‰
- **ç¸½è¨ˆ**ï¼šç´„ $3-5 USD/æ¬¡

### ROI åˆ†æ

**å‡è¨­**ï¼š
- æœˆæ´»ç”¨æˆ¶ 100 äºº
- å¹³å‡æ¯äººæ¯æœˆå„ªåŒ– 2 æ¬¡ç­–ç•¥
- æ¯æ¬¡æ”¶è²» $10 USDï¼ˆLevel 4+ æœƒå“¡ï¼‰

**æ”¶å…¥**ï¼š100 * 2 * $10 = $2,000/æœˆ

**æˆæœ¬**ï¼š100 * 2 * $3 = $600/æœˆï¼ˆLLMï¼‰

**æ·¨åˆ©**ï¼š$1,400/æœˆ

**æŠ•è³‡å›æ”¶æœŸ**ï¼š$5,000 / $1,400 â‰ˆ 3.6 å€‹æœˆ

---

## ğŸ¯ ç¸½çµ

### å¯è¡Œæ€§

âœ… **æŠ€è¡“å¯è¡Œ**ï¼šRD-Agent æä¾›å®Œæ•´æ¡†æ¶ï¼Œä¸»è¦å·¥ä½œæ˜¯é©é… Backtrader

âœ… **æˆæœ¬å¯æ§**ï¼šLLM æˆæœ¬ $3-5/æ¬¡ï¼Œå¯è½‰å«çµ¦ç”¨æˆ¶

âš ï¸ **é–‹ç™¼è¤‡é›œ**ï¼šéœ€ 2-3 é€±å…¨è·é–‹ç™¼ï¼Œéœ€ç†Ÿæ‚‰ RD-Agent æºç¢¼

### å„ªå…ˆç´šå»ºè­°

**å¦‚æœè¦å¯¦ç¾ç­–ç•¥å„ªåŒ–ï¼Œå»ºè­°é †åº**ï¼š

1. **å„ªå…ˆå¯¦ç¾å› å­æŒ–æ˜çš„è‡ªå‹•è©•ä¼°**ï¼ˆ1 é€±ï¼‰
   - ç”Ÿæˆå› å­å¾Œè‡ªå‹•è¨ˆç®— IC
   - è‡ªå‹•å›æ¸¬ä¸¦æ’åº
   - ROI æ›´é«˜ï¼Œé¢¨éšªæ›´ä½

2. **å†å¯¦ç¾ç°¡åŒ–ç‰ˆç­–ç•¥å„ªåŒ–**ï¼ˆ2 é€±ï¼‰
   - åƒ…æ”¯æ´åƒæ•¸å„ªåŒ–ï¼ˆä¸æ”¹é‚è¼¯ï¼‰
   - ä½¿ç”¨çª®èˆ‰æ³•è€Œé RD-Agent
   - é™ä½è¤‡é›œåº¦

3. **æœ€å¾Œå¯¦ç¾å®Œæ•´ç‰ˆç­–ç•¥å„ªåŒ–**ï¼ˆ3 é€±ï¼‰
   - æ•´åˆ RD-Agent CoSTEER
   - æ”¯æ´é‚è¼¯å„ªåŒ–
   - å®Œæ•´åŠŸèƒ½

### ç«‹å³å¯åšçš„äº‹

**ç„¡éœ€ç­‰å¾…å®Œæ•´å¯¦ç¾ï¼Œç¾åœ¨å°±å¯ä»¥åš**ï¼š

1. **æ‰‹å‹•ç­–ç•¥å„ªåŒ–æœå‹™**
   - ç”¨æˆ¶æäº¤ç­–ç•¥å’Œå„ªåŒ–ç›®æ¨™
   - äººå·¥åˆ†æä¸¦å„ªåŒ–
   - æ¸¬è©¦å¸‚å ´éœ€æ±‚

2. **ç°¡å–®çš„ A/B æ¸¬è©¦åŠŸèƒ½**
   - å…è¨±ç”¨æˆ¶å‰µå»ºç­–ç•¥è®Šé«”
   - å¹³è¡Œå›æ¸¬å°æ¯”
   - é¸æ“‡æœ€ä½³ç‰ˆæœ¬

---

**æ–‡æª”ç‰ˆæœ¬**ï¼šv1.0
**å‰µå»ºæ™‚é–“**ï¼š2025-12-25 21:30
**é è¨ˆå¯¦ç¾æ™‚é–“**ï¼š2-3 é€±ï¼ˆ80-120 å°æ™‚ï¼‰
