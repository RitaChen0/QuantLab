"""
Redis caching utilities with HMAC-signed pickle protection
"""

import json
import pickle
import hmac
import hashlib
from typing import Optional, Any, Callable
from functools import wraps
import redis
from loguru import logger
from app.core.config import settings


class RedisCache:
    """Redis cache manager"""

    def __init__(self):
        """Initialize Redis connection"""
        try:
            self.redis_client = redis.from_url(
                settings.REDIS_URL,
                decode_responses=False,  # Keep binary for pickle
            )
            self.redis_client.ping()
            logger.info("Redis cache initialized successfully")
        except Exception as e:
            logger.error(f"Failed to connect to Redis: {str(e)}")
            self.redis_client = None

    def is_available(self) -> bool:
        """Check if Redis is available"""
        return self.redis_client is not None

    def _get_signing_key(self) -> bytes:
        """
        å–å¾—å¿«å–ç°½ç« é‡‘é‘°

        å¦‚æœæœªè¨­å®š CACHE_SIGNING_KEYï¼Œä½¿ç”¨ JWT_SECRET ä½œç‚ºå‚™ç”¨

        Returns:
            ç°½ç« é‡‘é‘°ï¼ˆbytesï¼‰
        """
        key = settings.CACHE_SIGNING_KEY or settings.JWT_SECRET
        return key.encode('utf-8')

    def _sign_data(self, data: bytes) -> bytes:
        """
        ä½¿ç”¨ HMAC-SHA256 ç°½ç« è³‡æ–™

        æ ¼å¼: [32 bytes signature][data]

        Args:
            data: è¦ç°½ç« çš„è³‡æ–™

        Returns:
            ç°½ç« å¾Œçš„è³‡æ–™
        """
        signature = hmac.new(
            self._get_signing_key(),
            data,
            hashlib.sha256
        ).digest()

        return signature + data

    def _verify_and_extract(self, signed_data: bytes) -> Optional[bytes]:
        """
        é©—è­‰ç°½ç« ä¸¦æå–åŸå§‹è³‡æ–™

        Args:
            signed_data: ç°½ç« å¾Œçš„è³‡æ–™

        Returns:
            åŸå§‹è³‡æ–™ï¼Œå¦‚æœç°½ç« é©—è­‰å¤±æ•—å‰‡è¿”å› None
        """
        if len(signed_data) < 32:
            logger.warning("ç°½ç« è³‡æ–™å¤ªçŸ­ï¼Œç„¡æ•ˆ")
            return None

        signature = signed_data[:32]  # SHA256 = 32 bytes
        data = signed_data[32:]

        expected_signature = hmac.new(
            self._get_signing_key(),
            data,
            hashlib.sha256
        ).digest()

        # ä½¿ç”¨ compare_digest é˜²æ­¢æ™‚åºæ”»æ“Š
        if not hmac.compare_digest(signature, expected_signature):
            logger.warning("ç°½ç« é©—è­‰å¤±æ•—ï¼Œå¯èƒ½è³‡æ–™å·²è¢«ç¯¡æ”¹")
            return None

        return data

    def get(self, key: str) -> Optional[Any]:
        """
        Get value from cache with signature verification

        Args:
            key: Cache key

        Returns:
            Cached value or None
        """
        if not self.is_available():
            return None

        try:
            value = self.redis_client.get(key)
            if value is None:
                return None

            # å…ˆå˜—è©¦ JSON è§£ç¢¼ï¼ˆç°¡å–®é¡å‹ï¼Œç„¡éœ€ç°½ç« ï¼‰
            try:
                return json.loads(value.decode())
            except (json.JSONDecodeError, UnicodeDecodeError):
                pass  # ä¸æ˜¯ JSONï¼Œå¯èƒ½æ˜¯ç°½ç« çš„ pickle

            # å˜—è©¦é©—è­‰ç°½ç« ä¸¦ unpickleï¼ˆè¤‡é›œç‰©ä»¶å¦‚ DataFrameï¼‰
            try:
                # é©—è­‰ç°½ç« 
                verified_data = self._verify_and_extract(value)
                if verified_data is None:
                    logger.warning(f"ç°½ç« é©—è­‰å¤±æ•—ï¼Œæ‹’çµ•è¼‰å…¥å¿«å– {key}")
                    # åˆªé™¤è¢«ç¯¡æ”¹çš„å¿«å–
                    self.delete(key)
                    return None

                # ç°½ç« é©—è­‰é€šéï¼Œå®‰å…¨ unpickle
                return pickle.loads(verified_data)

            except (pickle.UnpicklingError, TypeError, AttributeError) as e:
                logger.warning(f"Failed to unpickle cache value for key {key}: {str(e)}")
                return None

        except redis.ConnectionError as e:
            logger.error(f"Redis connection error when getting key {key}: {str(e)}")
            return None
        except redis.TimeoutError as e:
            logger.error(f"Redis timeout when getting key {key}: {str(e)}")
            return None
        except Exception as e:
            logger.error(f"Unexpected error getting cache key {key}: {str(e)}")
            return None

    def set(
        self,
        key: str,
        value: Any,
        expiry: int = 3600,
    ) -> bool:
        """
        Set value in cache with signature protection

        Args:
            key: Cache key
            value: Value to cache
            expiry: Expiry time in seconds (default: 1 hour)

        Returns:
            True if successful, False otherwise
        """
        if not self.is_available():
            return False

        try:
            # å…ˆå˜—è©¦ JSON åºåˆ—åŒ–ï¼ˆç°¡å–®é¡å‹ï¼Œç„¡éœ€ç°½ç« ï¼‰
            try:
                serialized = json.dumps(value).encode()
            except (TypeError, ValueError):
                # Fallback: Pickle + HMAC ç°½ç« ï¼ˆè¤‡é›œç‰©ä»¶å¦‚ DataFrameï¼‰
                try:
                    pickled = pickle.dumps(value)
                    # ğŸ”’ ä½¿ç”¨ HMAC ç°½ç« ä¿è­· pickle è³‡æ–™
                    serialized = self._sign_data(pickled)
                    logger.debug(f"å¿«å– {key} ä½¿ç”¨ç°½ç« ä¿è­·çš„ pickle åºåˆ—åŒ–")
                except (pickle.PicklingError, TypeError, AttributeError) as e:
                    logger.warning(f"Failed to serialize value for key {key}: {str(e)}")
                    return False

            self.redis_client.setex(key, expiry, serialized)
            return True

        except redis.ConnectionError as e:
            logger.error(f"Redis connection error when setting key {key}: {str(e)}")
            return False
        except redis.TimeoutError as e:
            logger.error(f"Redis timeout when setting key {key}: {str(e)}")
            return False
        except Exception as e:
            logger.error(f"Unexpected error setting cache key {key}: {str(e)}")
            return False

    def delete(self, key: str) -> bool:
        """
        Delete key from cache

        Args:
            key: Cache key

        Returns:
            True if successful, False otherwise
        """
        if not self.is_available():
            return False

        try:
            self.redis_client.delete(key)
            return True
        except Exception as e:
            logger.error(f"Failed to delete cache key {key}: {str(e)}")
            return False

    def clear_pattern(self, pattern: str) -> int:
        """
        Clear all keys matching pattern

        Args:
            pattern: Key pattern (e.g., "stock:*")

        Returns:
            Number of keys deleted
        """
        if not self.is_available():
            return 0

        try:
            keys = self.redis_client.keys(pattern)
            if keys:
                return self.redis_client.delete(*keys)
            return 0
        except Exception as e:
            logger.error(f"Failed to clear pattern {pattern}: {str(e)}")
            return 0


# Global cache instance
cache = RedisCache()


def cached(
    key_prefix: str,
    expiry: int = 3600,
    key_func: Optional[Callable] = None,
):
    """
    Decorator to cache function results

    Args:
        key_prefix: Prefix for cache key
        expiry: Cache expiry in seconds
        key_func: Optional function to generate cache key from args

    Example:
        @cached(key_prefix="stock_price", expiry=600)
        def get_stock_price(stock_id: str):
            return expensive_api_call(stock_id)
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # Generate cache key
            if key_func:
                cache_key = f"{key_prefix}:{key_func(*args, **kwargs)}"
            else:
                # Default: use function args as key
                key_parts = [str(arg) for arg in args]
                key_parts.extend([f"{k}={v}" for k, v in sorted(kwargs.items())])
                cache_key = f"{key_prefix}:{'_'.join(key_parts)}"

            # Try to get from cache
            cached_value = cache.get(cache_key)
            if cached_value is not None:
                logger.debug(f"Cache hit: {cache_key}")
                return cached_value

            # Execute function
            logger.debug(f"Cache miss: {cache_key}")
            result = func(*args, **kwargs)

            # Store in cache
            cache.set(cache_key, result, expiry)

            return result

        return wrapper
    return decorator


def cached_method(
    key_prefix: str,
    expiry: int = 3600,
    key_func: Optional[Callable] = None,
):
    """
    Decorator to cache class method results (handles 'self' argument)

    Args:
        key_prefix: Prefix for cache key
        expiry: Cache expiry in seconds
        key_func: Optional function to generate cache key from args (excluding self)

    Example:
        class MyService:
            @cached_method(key_prefix="user_strategies", expiry=300)
            def get_user_strategies(self, user_id: int):
                return expensive_query(user_id)
    """
    def decorator(func):
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            # Generate cache key (skip 'self' argument)
            if key_func:
                cache_key = f"{key_prefix}:{key_func(*args, **kwargs)}"
            else:
                # Default: use function args as key (excluding self)
                key_parts = [str(arg) for arg in args]
                key_parts.extend([f"{k}={v}" for k, v in sorted(kwargs.items())])
                cache_key = f"{key_prefix}:{'_'.join(key_parts)}"

            # Try to get from cache
            cached_value = cache.get(cache_key)
            if cached_value is not None:
                logger.debug(f"Cache hit: {cache_key}")
                return cached_value

            # Execute function
            logger.debug(f"Cache miss: {cache_key}")
            result = func(self, *args, **kwargs)

            # Store in cache
            cache.set(cache_key, result, expiry)

            return result

        # Add cache invalidation method
        wrapper.invalidate_cache = lambda *args, **kwargs: _invalidate_cache(key_prefix, key_func, *args, **kwargs)

        return wrapper
    return decorator


def _invalidate_cache(key_prefix: str, key_func: Optional[Callable], *args, **kwargs):
    """Helper to invalidate cache for specific key"""
    if key_func:
        cache_key = f"{key_prefix}:{key_func(*args, **kwargs)}"
    else:
        key_parts = [str(arg) for arg in args]
        key_parts.extend([f"{k}={v}" for k, v in sorted(kwargs.items())])
        cache_key = f"{key_prefix}:{'_'.join(key_parts)}"

    cache.delete(cache_key)
    logger.debug(f"Cache invalidated: {cache_key}")
