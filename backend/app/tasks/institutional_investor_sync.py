"""
Celery tasks for institutional investor data synchronization
æ³•äººè²·è³£è¶…æ•¸æ“šåŒæ­¥ä»»å‹™
"""

from celery import Task
from app.core.celery_app import celery_app
from app.db.session import SessionLocal
from app.services.institutional_investor_service import InstitutionalInvestorService
from app.repositories.stock import StockRepository
from app.utils.task_history import record_task_history
from app.utils.task_deduplication import skip_if_recently_executed
from app.utils.cache import cache
from loguru import logger
from datetime import datetime, timedelta, timezone
from typing import List, Optional


@celery_app.task(bind=True, name="app.tasks.sync_institutional_investors")
@record_task_history
def sync_institutional_investors(
    self: Task,
    stock_ids: Optional[List[str]] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    days: int = 7
) -> dict:
    """
    åŒæ­¥æ³•äººè²·è³£è¶…æ•¸æ“š

    Args:
        stock_ids: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨ï¼Œå¦‚æœç‚º None å‰‡åŒæ­¥æ‰€æœ‰è‚¡ç¥¨
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
        days: å¦‚æœæœªæŒ‡å®šæ—¥æœŸç¯„åœï¼ŒåŒæ­¥æœ€è¿‘ N å¤©ï¼ˆé»˜èª 7 å¤©ï¼‰

    Returns:
        åŒæ­¥çµæœçµ±è¨ˆ
    """
    # ğŸ”’ Distributed lock - prevent concurrent execution
    redis_client = cache.redis_client
    lock_key = f"task_lock:{self.name}"
    # 60 åˆ†é˜è¶…æ™‚ï¼ˆä»»å‹™é è¨ˆåŸ·è¡Œæ™‚é–“ï¼š20-30 åˆ†é˜ï¼Œå–æ±ºæ–¼è‚¡ç¥¨æ•¸é‡ï¼‰
    lock = redis_client.lock(lock_key, timeout=3600)

    # å˜—è©¦ç²å–é–ï¼ˆéé˜»å¡ï¼‰
    if not lock.acquire(blocking=False):
        logger.warning(f"âš ï¸  ä»»å‹™ {self.name} å·²åœ¨åŸ·è¡Œä¸­ï¼Œè·³éæ­¤æ¬¡è§¸ç™¼")
        logger.info(f"   é–å®š Key: {lock_key}")
        return {
            "status": "skipped",
            "reason": "task_already_running",
            "message": f"Task {self.name} is already running, skipped duplicate execution",
            "timestamp": datetime.now(timezone.utc).isoformat()
        }

    logger.info(f"ğŸ” å·²ç²å–ä»»å‹™é–: {lock_key}")

    db = SessionLocal()

    try:
        logger.info("Starting institutional investor data synchronization...")

        # å¦‚æœæ²’æœ‰æŒ‡å®šè‚¡ç¥¨ï¼Œç²å–æ‰€æœ‰æ´»èºè‚¡ç¥¨
        if not stock_ids:
            stocks = StockRepository.get_all(db, is_active='active')
            stock_ids = [stock.stock_id for stock in stocks]
            logger.info(f"Syncing all {len(stock_ids)} active stocks")
        else:
            logger.info(f"Syncing {len(stock_ids)} specified stocks")

        # å¦‚æœæ²’æœ‰æŒ‡å®šæ—¥æœŸç¯„åœï¼Œä½¿ç”¨æœ€è¿‘ N å¤©
        if not start_date:
            start_date = (datetime.now(timezone.utc) - timedelta(days=days)).strftime('%Y-%m-%d')
        if not end_date:
            end_date = datetime.now(timezone.utc).strftime('%Y-%m-%d')

        logger.info(f"Date range: {start_date} ~ {end_date}")

        # åˆå§‹åŒ–æœå‹™
        service = InstitutionalInvestorService(db)

        # æ‰¹é‡åŒæ­¥
        result = service.sync_multiple_stocks(
            stock_ids=stock_ids,
            start_date=start_date,
            end_date=end_date,
            force=False  # ä¸å¼·åˆ¶è¦†è“‹ç¾æœ‰æ•¸æ“š
        )

        logger.info(
            f"Sync completed: "
            f"stocks={result['total_stocks']}, "
            f"inserted={result['total_inserted']}, "
            f"updated={result['total_updated']}, "
            f"errors={result['total_errors']}"
        )

        return {
            "status": "success",
            "period": f"{start_date} ~ {end_date}",
            **result
        }

    except Exception as e:
        logger.error(f"Failed to sync institutional investor data: {str(e)}")
        return {
            "status": "error",
            "message": str(e)
        }

    finally:
        db.close()
        # ç¢ºä¿é‡‹æ”¾é–
        try:
            lock.release()
            logger.info("ğŸ”“ ä»»å‹™é–å·²é‡‹æ”¾")
        except Exception as e:
            logger.error(f"Failed to release lock: {e}")


@celery_app.task(bind=True, name="app.tasks.sync_single_stock_institutional")
@record_task_history
def sync_single_stock_institutional(
    self: Task,
    stock_id: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    force: bool = False
) -> dict:
    """
    åŒæ­¥å–®ä¸€è‚¡ç¥¨çš„æ³•äººè²·è³£è¶…æ•¸æ“š

    Args:
        stock_id: è‚¡ç¥¨ä»£ç¢¼
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
        force: æ˜¯å¦å¼·åˆ¶è¦†è“‹ç¾æœ‰æ•¸æ“š

    Returns:
        åŒæ­¥çµæœ
    """
    db = SessionLocal()

    try:
        logger.info(f"Starting institutional investor sync for {stock_id}")

        service = InstitutionalInvestorService(db)

        result = service.sync_stock_data(
            stock_id=stock_id,
            start_date=start_date,
            end_date=end_date,
            force=force
        )

        logger.info(f"Sync completed for {stock_id}: {result}")

        return result

    except Exception as e:
        logger.error(f"Failed to sync {stock_id}: {str(e)}")
        return {
            "stock_id": stock_id,
            "status": "error",
            "message": str(e)
        }

    finally:
        db.close()


@celery_app.task(bind=True, name="app.tasks.sync_top_stocks_institutional")
@skip_if_recently_executed(min_interval_hours=24)
@record_task_history
def sync_top_stocks_institutional(
    self: Task,
    limit: Optional[int] = None,
    days: int = 7
) -> dict:
    """
    åŒæ­¥è‚¡ç¥¨çš„æ³•äººè²·è³£è¶…æ•¸æ“š

    Args:
        limit: è‚¡ç¥¨æ•¸é‡é™åˆ¶ï¼ˆNone = å…¨éƒ¨è‚¡ç¥¨ï¼‰
        days: åŒæ­¥æœ€è¿‘ N å¤©

    Returns:
        åŒæ­¥çµæœçµ±è¨ˆ
    """
    db = SessionLocal()

    try:
        if limit is None:
            logger.info("Starting institutional investor sync for ALL active stocks")
        else:
            logger.info(f"Starting institutional investor sync for top {limit} stocks")

        # ç²å–è‚¡ç¥¨åˆ—è¡¨
        stocks = StockRepository.get_all(db, is_active='active', limit=limit)
        stock_ids = [stock.stock_id for stock in stocks]

        if limit is None:
            logger.info(f"Selected ALL {len(stock_ids)} active stocks for sync")
        else:
            logger.info(f"Selected {len(stock_ids)} stocks for sync")

        # ç›´æ¥èª¿ç”¨åŒæ­¥é‚è¼¯ï¼ˆé¿å…åœ¨ä»»å‹™å…§éƒ¨ç­‰å¾…å…¶ä»–ä»»å‹™ï¼‰
        service = InstitutionalInvestorService(db)

        # è¨ˆç®—æ—¥æœŸç¯„åœ
        start_date = (datetime.now(timezone.utc) - timedelta(days=days)).strftime('%Y-%m-%d')
        end_date = datetime.now(timezone.utc).strftime('%Y-%m-%d')

        logger.info(f"Date range: {start_date} ~ {end_date}")

        # æ‰¹é‡åŒæ­¥
        result = service.sync_multiple_stocks(
            stock_ids=stock_ids,
            start_date=start_date,
            end_date=end_date,
            force=False
        )

        logger.info(
            f"Sync completed: "
            f"stocks={result['total_stocks']}, "
            f"inserted={result['total_inserted']}, "
            f"updated={result['total_updated']}, "
            f"errors={result['total_errors']}"
        )

        return {
            "status": "success",
            "period": f"{start_date} ~ {end_date}",
            **result
        }

    except Exception as e:
        logger.error(f"Failed to sync top stocks: {str(e)}")
        return {
            "status": "error",
            "message": str(e)
        }

    finally:
        db.close()


@celery_app.task(bind=True, name="app.tasks.cleanup_old_institutional_data")
@skip_if_recently_executed(min_interval_hours=168)  # é€±ä»»å‹™ï¼š7 å¤© = 168 å°æ™‚
@record_task_history
def cleanup_old_institutional_data(
    self: Task,
    days_to_keep: int = 365
) -> dict:
    """
    æ¸…ç†èˆŠçš„æ³•äººè²·è³£è¶…æ•¸æ“š

    Args:
        days_to_keep: ä¿ç•™æœ€è¿‘ N å¤©çš„æ•¸æ“šï¼ˆé»˜èª 365 å¤©ï¼‰

    Returns:
        æ¸…ç†çµæœ
    """
    db = SessionLocal()

    try:
        logger.info(f"Starting cleanup of institutional data older than {days_to_keep} days")

        service = InstitutionalInvestorService(db)
        deleted_count = service.delete_old_data(days_to_keep)

        logger.info(f"Cleanup completed: deleted {deleted_count} records")

        return {
            "status": "success",
            "deleted_count": deleted_count,
            "days_kept": days_to_keep
        }

    except Exception as e:
        logger.error(f"Failed to cleanup old data: {str(e)}")
        return {
            "status": "error",
            "message": str(e)
        }

    finally:
        db.close()
