"""
ç³»çµ±ç¶­è­·ç›¸é—œçš„ Celery ä»»å‹™

åŒ…å«æ¸…ç†éæœŸè³‡æ–™ã€revoked tasks ç­‰ç³»çµ±ç¶­è­·åŠŸèƒ½
"""

import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, Any

from celery import Task
from redis.exceptions import RedisError

from app.core.celery_app import celery_app
from app.core.config import settings
from app.utils.cache import cache
from app.utils.task_history import record_task_history
from app.utils.task_deduplication import skip_if_recently_executed

logger = logging.getLogger(__name__)


@celery_app.task(bind=True, name="app.tasks.cleanup_celery_metadata")
@skip_if_recently_executed(min_interval_hours=24)
@record_task_history
def cleanup_celery_metadata(
    self: Task,
    max_age_hours: int = 24,
    dry_run: bool = False
) -> Dict[str, Any]:
    """
    æ¸…ç† Celery å…ƒæ•¸æ“šï¼ˆéæœŸçµæœã€revoked tasks ç­‰ï¼‰

    æ­¤ä»»å‹™å®šæœŸæ¸…ç† Redis ä¸­çš„ Celery å…ƒæ•¸æ“šï¼Œé˜²æ­¢ï¼š
    1. revoked task IDs ç„¡é™ç©ç´¯å°è‡´ Worker æ‹’çµ•æ–°ä»»å‹™
    2. éæœŸçš„ä»»å‹™çµæœä½”ç”¨ Redis å…§å­˜
    3. èˆŠçš„ä»»å‹™ç‹€æ…‹è¨˜éŒ„é€ æˆæ··äº‚

    Args:
        max_age_hours: ä¿ç•™å¤šå°‘å°æ™‚å…§çš„çµæœï¼ˆé è¨­ 24 å°æ™‚ï¼‰
        dry_run: åƒ…æª¢æŸ¥ä¸å¯¦éš›åˆªé™¤ï¼ˆé è¨­ Falseï¼‰

    Returns:
        Dict åŒ…å«æ¸…ç†çµ±è¨ˆè³‡è¨Š
    """
    logger.info("ğŸ§¹ é–‹å§‹æ¸…ç† Celery å…ƒæ•¸æ“š...")

    stats = {
        "revoked_tasks_cleared": 0,
        "expired_results_deleted": 0,
        "task_states_cleaned": 0,
        "errors": []
    }

    if not cache.is_available():
        logger.warning("âš ï¸  Redis ä¸å¯ç”¨ï¼Œè·³éæ¸…ç†")
        stats["errors"].append("Redis unavailable")
        return stats

    try:
        redis_client = cache.redis_client
        if not redis_client:
            logger.warning("âš ï¸  Redis å®¢æˆ¶ç«¯ä¸å¯ç”¨ï¼Œè·³éæ¸…ç†")
            stats["errors"].append("Redis client unavailable")
            return stats

        # 1. æ™ºæ…§æ¸…ç† revoked task IDs
        # å•é¡Œï¼šéæœŸçš„ä»»å‹™ ID æœƒæ°¸ä¹…ç•™åœ¨ Worker å…§å­˜ä¸­ï¼Œæ“‹ä½æœªä¾†çš„ä»»å‹™
        # è§£æ±ºï¼šé€šéé‡å•Ÿ Worker é€²ç¨‹æ± ä¾†æ¸…ç©º revoked åˆ—è¡¨
        logger.info("ğŸ—‘ï¸  æ™ºæ…§æ¸…ç† revoked tasks...")

        from celery import current_app
        control = current_app.control

        # 1.1 æª¢æŸ¥ç•¶å‰ revoked åˆ—è¡¨
        try:
            inspect = control.inspect()
            revoked_info = inspect.revoked()

            if revoked_info:
                total_revoked = sum(len(tasks) for tasks in revoked_info.values())
                logger.info(f"ğŸ“Š ç•¶å‰ revoked ä»»å‹™æ•¸é‡: {total_revoked}")

                # å¦‚æœæœ‰ revoked ä»»å‹™ï¼Œé€šéé‡å•Ÿé€²ç¨‹æ± ä¾†æ¸…ç©º
                if total_revoked > 0 and not dry_run:
                    logger.info("ğŸ”„ æª¢æ¸¬åˆ° revoked ä»»å‹™ï¼Œé‡å•Ÿ Worker é€²ç¨‹æ± ä»¥æ¸…ç©º...")

                    # ä½¿ç”¨ pool_restart å‘½ä»¤é‡å•Ÿæ‰€æœ‰ Worker çš„é€²ç¨‹æ± 
                    # é€™æœƒæ¸…ç©ºå…§å­˜ä¸­çš„ revoked åˆ—è¡¨ï¼Œä½†ä¸å½±éŸ¿æ­£åœ¨åŸ·è¡Œçš„ä»»å‹™
                    control.broadcast('pool_restart', arguments={'reload': False})

                    logger.info("âœ… å·²é€šçŸ¥æ‰€æœ‰ Worker é‡å•Ÿé€²ç¨‹æ± ")
                    stats["revoked_tasks_cleared"] = total_revoked
                elif total_revoked > 0:
                    logger.info(f"ğŸ” [DRY RUN] å°‡é‡å•Ÿ Worker é€²ç¨‹æ± ä»¥æ¸…ç©º {total_revoked} å€‹ revoked ä»»å‹™")
                else:
                    logger.info("âœ… Revoked åˆ—è¡¨å·²ç©ºï¼Œç„¡éœ€æ¸…ç†")
            else:
                logger.warning("âš ï¸  ç„¡æ³•ç²å– revoked åˆ—è¡¨è³‡è¨Š")

        except Exception as e:
            logger.warning(f"âš ï¸  æ¸…ç† revoked åˆ—è¡¨æ™‚å‡ºéŒ¯: {e}")
            stats["errors"].append(f"Revoked cleanup error: {str(e)}")

        # 1.2 æ¸…ç©ºéšŠåˆ—ä¸­æœªåŸ·è¡Œçš„éæœŸä»»å‹™ï¼ˆå¯é¸ï¼‰
        if not dry_run:
            try:
                purged = control.purge()  # æ¸…ç©ºæ‰€æœ‰éšŠåˆ—ä¸­æœªåŸ·è¡Œçš„ä»»å‹™
                if purged:
                    logger.info(f"ğŸ—‘ï¸  å·²æ¸…ç©º {purged} å€‹éšŠåˆ—ä¸­çš„æœªåŸ·è¡Œä»»å‹™")
            except Exception as e:
                logger.warning(f"âš ï¸  æ¸…ç©ºéšŠåˆ—æ™‚å‡ºéŒ¯: {e}")

        # 2. æ¸…ç†éæœŸçš„ä»»å‹™çµæœ
        # Celery çµæœå­˜å„²åœ¨ Redis ä¸­ï¼Œkey pattern: celery-task-meta-<task_id>
        logger.info(f"ğŸ—‘ï¸  æ¸…ç† {max_age_hours} å°æ™‚å‰çš„ä»»å‹™çµæœ...")

        cutoff_time = datetime.now(timezone.utc) - timedelta(hours=max_age_hours)
        result_pattern = "celery-task-meta-*"

        cursor = 0
        deleted_count = 0

        while True:
            cursor, keys = redis_client.scan(
                cursor=cursor,
                match=result_pattern,
                count=100
            )

            for key in keys:
                try:
                    # æª¢æŸ¥ TTLï¼Œå¦‚æœå·²æœ‰éæœŸæ™‚é–“å‰‡è·³é
                    ttl = redis_client.ttl(key)
                    if ttl > 0:
                        continue  # å·²è¨­ç½® TTLï¼ŒRedis æœƒè‡ªå‹•æ¸…ç†

                    # ç²å–ä»»å‹™çµæœä¸¦æª¢æŸ¥æ™‚é–“
                    result_data = redis_client.get(key)
                    if result_data:
                        # ç°¡å–®æ–¹å¼ï¼šç›´æ¥åˆªé™¤æ²’æœ‰ TTL çš„èˆŠçµæœ
                        if not dry_run:
                            redis_client.delete(key)
                            deleted_count += 1
                except Exception as e:
                    logger.warning(f"âš ï¸  è™•ç† key {key} æ™‚å‡ºéŒ¯: {e}")
                    stats["errors"].append(f"Key {key}: {str(e)}")

            if cursor == 0:
                break

        stats["expired_results_deleted"] = deleted_count
        logger.info(f"âœ… å·²åˆªé™¤ {deleted_count} å€‹éæœŸçµæœ")

        # 3. æ¸…ç†éæœŸçš„ä»»å‹™ç‹€æ…‹ï¼ˆå¦‚æœæœ‰è‡ªå®šç¾©ç‹€æ…‹å­˜å„²ï¼‰
        state_pattern = "celery-task-state-*"
        cursor = 0
        state_deleted = 0

        while True:
            cursor, keys = redis_client.scan(
                cursor=cursor,
                match=state_pattern,
                count=100
            )

            for key in keys:
                try:
                    ttl = redis_client.ttl(key)
                    if ttl == -1:  # æ²’æœ‰éæœŸæ™‚é–“
                        if not dry_run:
                            redis_client.expire(key, max_age_hours * 3600)
                            state_deleted += 1
                except Exception as e:
                    logger.warning(f"âš ï¸  è™•ç†ç‹€æ…‹ key {key} æ™‚å‡ºéŒ¯: {e}")

            if cursor == 0:
                break

        stats["task_states_cleaned"] = state_deleted
        logger.info(f"âœ… å·²è¨­ç½® {state_deleted} å€‹ç‹€æ…‹ key éæœŸæ™‚é–“")

    except RedisError as e:
        logger.error(f"âŒ Redis éŒ¯èª¤: {e}")
        stats["errors"].append(f"Redis error: {str(e)}")
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        stats["errors"].append(f"Cleanup error: {str(e)}")

    # è¨˜éŒ„çµ±è¨ˆçµæœ
    logger.info(f"ğŸ“Š æ¸…ç†å®Œæˆçµ±è¨ˆ:")
    logger.info(f"  - Revoked tasks æ¸…ç†: {stats['revoked_tasks_cleared']}")
    logger.info(f"  - éæœŸçµæœåˆªé™¤: {stats['expired_results_deleted']}")
    logger.info(f"  - ç‹€æ…‹ key æ¸…ç†: {stats['task_states_cleaned']}")

    if stats["errors"]:
        logger.warning(f"  - éŒ¯èª¤æ•¸é‡: {len(stats['errors'])}")

    return stats
