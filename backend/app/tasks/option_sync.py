"""
Celery tasks for option data synchronization

é¸æ“‡æ¬Šè³‡æ–™åŒæ­¥ä»»å‹™ï¼Œæ”¯æ´ä¸‰éšæ®µæ¼”é€²å¼æ¶æ§‹ï¼š
- éšæ®µä¸€ï¼šæ¯æ—¥èšåˆå› å­åŒæ­¥ï¼ˆPCR, ATM IVï¼‰
- éšæ®µäºŒï¼šåˆ†é˜ç·šåŒæ­¥
- éšæ®µä¸‰ï¼šGreeks è¨ˆç®—
"""

from celery import Task
from app.core.celery_app import celery_app
from app.utils.task_history import record_task_history
from app.utils.task_deduplication import skip_if_recently_executed
from app.db.session import get_db
from loguru import logger
from datetime import datetime, timezone, date, timedelta
from typing import List, Optional

from app.services.shioaji_client import ShioajiClient
from app.services.option_data_source import ShioajiOptionDataSource
from app.services.option_calculator import OptionFactorCalculator
from app.repositories.option import (
    OptionDailyFactorRepository,
    OptionSyncConfigRepository,
    OptionContractRepository
)
from app.schemas.option import OptionDailyFactorCreate


@celery_app.task(
    bind=True,
    name="app.tasks.sync_option_daily_factors",
    max_retries=3,
    default_retry_delay=300  # 5 minutes
)
@skip_if_recently_executed(min_interval_hours=24)
@record_task_history
def sync_option_daily_factors(
    self: Task,
    underlying_ids: Optional[List[str]] = None,
    target_date: Optional[str] = None
) -> dict:
    """
    åŒæ­¥é¸æ“‡æ¬Šæ¯æ—¥èšåˆå› å­ï¼ˆéšæ®µä¸€ä¸»ä»»å‹™ï¼‰

    åŸ·è¡Œæµç¨‹ï¼š
    1. æª¢æŸ¥ç•¶å‰éšæ®µé…ç½®
    2. ç²å–å•Ÿç”¨çš„æ¨™çš„ç‰©åˆ—è¡¨
    3. ä½¿ç”¨ Shioaji API ç²å–é¸æ“‡æ¬Šéˆæ•¸æ“š
    4. è¨ˆç®—æ¯æ—¥å› å­
    5. å„²å­˜åˆ° option_daily_factors è¡¨

    Args:
        underlying_ids: æ¨™çš„ä»£ç¢¼åˆ—è¡¨ï¼ˆNone è¡¨ç¤ºä½¿ç”¨é…ç½®ï¼‰
        target_date: ç›®æ¨™æ—¥æœŸï¼ˆYYYY-MM-DDï¼Œé è¨­ç‚ºä»Šå¤©ï¼‰

    Returns:
        Task result with sync statistics
    """
    start_time = datetime.now(timezone.utc)

    try:
        logger.info(
            f"[OPTION] ğŸš€ Starting option daily factors synchronization "
            f"(task_id: {self.request.id})"
        )

        # è§£æç›®æ¨™æ—¥æœŸ
        try:
            if target_date:
                sync_date = datetime.strptime(target_date, "%Y-%m-%d").date()
            else:
                from app.utils.timezone_helpers import today_taiwan
                sync_date = today_taiwan()
        except ValueError as e:
            logger.error(f"[OPTION] âŒ Invalid date format: {target_date}. Expected YYYY-MM-DD")
            return {
                "status": "error",
                "message": f"Invalid date format: {target_date}",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

        logger.info(f"[OPTION] ğŸ“… Sync date: {sync_date}")

        # ç²å–è³‡æ–™åº«é€£æ¥
        try:
            db = next(get_db())
        except Exception as e:
            logger.error(
                f"[OPTION] âŒ Failed to get database connection: {type(e).__name__}: {str(e)}",
                exc_info=True
            )
            raise self.retry(exc=e, countdown=60)

        # ç²å–ç•¶å‰éšæ®µé…ç½®
        try:
            stage = OptionSyncConfigRepository.get_current_stage(db)
            logger.info(f"[OPTION] ğŸ“ˆ Current stage: {stage}")
        except Exception as e:
            logger.warning(
                f"[OPTION] âš ï¸  Failed to get stage config, defaulting to stage 1: {str(e)}"
            )
            stage = 1

        # ç²å–å•Ÿç”¨çš„æ¨™çš„ç‰©åˆ—è¡¨
        if not underlying_ids:
            try:
                underlying_ids = OptionSyncConfigRepository.get_enabled_underlyings(db)
            except Exception as e:
                logger.warning(
                    f"[OPTION] âš ï¸  Failed to get enabled underlyings: {str(e)}"
                )
                underlying_ids = []

        if not underlying_ids:
            logger.warning("[OPTION] âš ï¸  No underlyings configured. Using default: TX only (MTX has no options)")
            underlying_ids = ['TX']  # MTX (å°å°æœŸè²¨) æ²’æœ‰é¸æ“‡æ¬Šç”¢å“

        logger.info(f"[OPTION] ğŸ¯ Target underlyings: {underlying_ids}")

        # åˆå§‹åŒ– Shioaji å®¢æˆ¶ç«¯
        try:
            with ShioajiClient() as shioaji:
                if not shioaji.is_available():
                    error_msg = (
                        "Shioaji client not available. Please check: "
                        "1) API credentials, 2) Network connection, 3) API service status"
                    )
                    logger.error(f"[OPTION] âŒ {error_msg}")

                    # Retry if not available
                    if self.request.retries < self.max_retries:
                        raise self.retry(exc=Exception(error_msg), countdown=300)

                    return {
                        "status": "error",
                        "message": error_msg,
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    }

                # å‰µå»ºè³‡æ–™æºå’Œè¨ˆç®—å™¨
                data_source = ShioajiOptionDataSource(shioaji)
                calculator = OptionFactorCalculator(data_source, db)

                # åŒæ­¥çµ±è¨ˆ
                stats = {
                    "total_underlyings": len(underlying_ids),
                    "success_count": 0,
                    "error_count": 0,
                    "factors_saved": 0,
                    "low_quality_count": 0,
                    "errors": [],
                    "warnings": []
                }

                # é€å€‹æ¨™çš„åŒæ­¥
                for index, underlying_id in enumerate(underlying_ids, 1):
                    try:
                        logger.info(
                            f"[OPTION] ğŸ“Š Processing {underlying_id} "
                            f"({index}/{len(underlying_ids)})..."
                        )

                        # è¨ˆç®—æ¯æ—¥å› å­
                        try:
                            factors = calculator.calculate_daily_factors(
                                underlying_id,
                                sync_date
                            )
                        except Exception as e:
                            logger.error(
                                f"[OPTION] âŒ Factor calculation failed for {underlying_id}: "
                                f"{type(e).__name__}: {str(e)}",
                                exc_info=True
                            )
                            stats["error_count"] += 1
                            stats["errors"].append(f"{underlying_id}: Calculation failed - {str(e)}")
                            continue

                        # æª¢æŸ¥è³‡æ–™å“è³ª
                        quality_score = factors.get('data_quality_score')
                        if quality_score:
                            quality_float = float(quality_score)
                            if quality_float < 0.3:
                                logger.error(
                                    f"[OPTION] âŒ Very low quality data for {underlying_id}: "
                                    f"score={quality_score} (<0.3). Skipping save."
                                )
                                stats["error_count"] += 1
                                stats["errors"].append(
                                    f"{underlying_id}: Very low quality (score={quality_score})"
                                )
                                continue
                            elif quality_float < 0.7:
                                logger.warning(
                                    f"[OPTION] âš ï¸  Low quality data for {underlying_id}: "
                                    f"score={quality_score}"
                                )
                                stats["low_quality_count"] += 1
                                stats["warnings"].append(
                                    f"{underlying_id}: Low quality (score={quality_score})"
                                )

                        # å„²å­˜åˆ°è³‡æ–™åº«ï¼ˆupsertï¼‰
                        try:
                            factor_data = OptionDailyFactorCreate(
                                underlying_id=underlying_id,
                                date=sync_date,
                                **factors
                            )

                            saved_factor = OptionDailyFactorRepository.upsert(db, factor_data)

                            if saved_factor:
                                stats["success_count"] += 1
                                stats["factors_saved"] += 1

                                # æ§‹å»ºå› å­æ‘˜è¦
                                factor_summary = []
                                if factors.get('pcr_volume'):
                                    factor_summary.append(f"PCR={factors['pcr_volume']}")
                                if factors.get('atm_iv'):
                                    factor_summary.append(f"ATM_IV={factors['atm_iv']}")
                                if quality_score:
                                    factor_summary.append(f"Quality={quality_score}")

                                logger.info(
                                    f"[OPTION] âœ… Saved factors for {underlying_id}: "
                                    f"{', '.join(factor_summary)}"
                                )
                            else:
                                stats["error_count"] += 1
                                stats["errors"].append(f"{underlying_id}: Database save returned None")
                                logger.error(
                                    f"[OPTION] âŒ Failed to save factors for {underlying_id}: "
                                    "Database operation returned None"
                                )

                        except Exception as e:
                            logger.error(
                                f"[OPTION] âŒ Database save failed for {underlying_id}: "
                                f"{type(e).__name__}: {str(e)}",
                                exc_info=True
                            )
                            stats["error_count"] += 1
                            stats["errors"].append(f"{underlying_id}: DB save failed - {str(e)}")

                    except Exception as e:
                        logger.error(
                            f"[OPTION] âŒ Unexpected error processing {underlying_id}: "
                            f"{type(e).__name__}: {str(e)}",
                            exc_info=True
                        )
                        stats["error_count"] += 1
                        stats["errors"].append(f"{underlying_id}: Unexpected error - {str(e)}")

        except Exception as e:
            logger.error(
                f"[OPTION] âŒ Failed to initialize Shioaji client: "
                f"{type(e).__name__}: {str(e)}",
                exc_info=True
            )
            # Retry on client initialization failure
            if self.request.retries < self.max_retries:
                raise self.retry(exc=e, countdown=300)

            return {
                "status": "error",
                "message": f"Shioaji client error: {str(e)}",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

        # è¨ˆç®—åŸ·è¡Œæ™‚é–“
        duration = (datetime.now(timezone.utc) - start_time).total_seconds()

        # è¨˜éŒ„æœ€çµ‚çµ±è¨ˆ
        logger.info(
            f"[OPTION] ğŸ Sync completed in {duration:.1f}s. "
            f"Success: {stats['success_count']}/{stats['total_underlyings']}, "
            f"Errors: {stats['error_count']}, "
            f"Low quality: {stats['low_quality_count']}"
        )

        # é¡¯ç¤ºéŒ¯èª¤æ‘˜è¦
        if stats['errors']:
            logger.error(
                f"[OPTION] âŒ Errors encountered:\n" +
                "\n".join(f"  - {error}" for error in stats['errors'][:10])
            )
            if len(stats['errors']) > 10:
                logger.error(f"  ... and {len(stats['errors']) - 10} more errors")

        # é¡¯ç¤ºè­¦å‘Šæ‘˜è¦
        if stats['warnings']:
            logger.warning(
                f"[OPTION] âš ï¸  Warnings:\n" +
                "\n".join(f"  - {warning}" for warning in stats['warnings'][:5])
            )

        # æ·»åŠ åŸ·è¡Œæ™‚é–“åˆ°çµ±è¨ˆ
        stats['duration_seconds'] = duration

        # è¿”å›çµæœ
        if stats["error_count"] == 0:
            logger.info(f"[OPTION] âœ… All underlyings synced successfully!")
            return {
                "status": "success",
                "message": f"Successfully synced {stats['success_count']} underlyings",
                "statistics": stats,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        elif stats["success_count"] > 0:
            success_rate = (stats['success_count'] / stats['total_underlyings']) * 100
            logger.warning(
                f"[OPTION] âš ï¸  Partial success: {success_rate:.1f}% success rate"
            )
            return {
                "status": "partial_success",
                "message": (
                    f"Synced {stats['success_count']}/{stats['total_underlyings']} underlyings "
                    f"({success_rate:.1f}% success rate)"
                ),
                "statistics": stats,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        else:
            logger.error(f"[OPTION] âŒ All underlyings failed to sync!")
            return {
                "status": "error",
                "message": "All underlyings failed to sync",
                "statistics": stats,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

    except self.retry as retry_exc:
        # Retry exceptions should propagate
        raise retry_exc
    except Exception as e:
        duration = (datetime.now(timezone.utc) - start_time).total_seconds()
        logger.error(
            f"[OPTION] âŒ Fatal error in sync_option_daily_factors after {duration:.1f}s: "
            f"{type(e).__name__}: {str(e)}",
            exc_info=True
        )

        # Retry on unexpected errors if within retry limit
        if self.request.retries < self.max_retries:
            logger.info(
                f"[OPTION] ğŸ”„ Retrying task (attempt {self.request.retries + 1}/{self.max_retries})..."
            )
            raise self.retry(exc=e, countdown=300)

        return {
            "status": "error",
            "message": f"Fatal error: {type(e).__name__}: {str(e)}",
            "duration_seconds": duration,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }


@celery_app.task(bind=True, name="app.tasks.register_option_contracts")
@skip_if_recently_executed(min_interval_hours=168)  # é€±ä»»å‹™ï¼š7 å¤© = 168 å°æ™‚
@record_task_history
def register_option_contracts(
    self: Task,
    underlying_ids: Optional[List[str]] = None
) -> dict:
    """
    è¨»å†Šé¸æ“‡æ¬Šåˆç´„åˆ°è³‡æ–™åº«ï¼ˆéšæ®µä¸€è¼”åŠ©ä»»å‹™ï¼‰

    åŸ·è¡Œæµç¨‹ï¼š
    1. ä½¿ç”¨ Shioaji API ç²å–é¸æ“‡æ¬Šåˆç´„åˆ—è¡¨
    2. è¨»å†Šåˆ° option_contracts è¡¨
    3. è¨­å®šåˆ°æœŸæ—¥å’Œåˆç´„è¦æ ¼

    Args:
        underlying_ids: æ¨™çš„ä»£ç¢¼åˆ—è¡¨ï¼ˆNone è¡¨ç¤ºä½¿ç”¨é…ç½®ï¼‰

    Returns:
        Task result with registration statistics
    """
    try:
        logger.info("[OPTION] Starting option contracts registration...")

        # ç²å–è³‡æ–™åº«é€£æ¥
        db = next(get_db())

        # ç²å–æ¨™çš„ç‰©åˆ—è¡¨
        if not underlying_ids:
            underlying_ids = OptionSyncConfigRepository.get_enabled_underlyings(db)

        if not underlying_ids:
            underlying_ids = ['TX', 'MTX']

        logger.info(f"[OPTION] Registering contracts for: {underlying_ids}")

        # åˆå§‹åŒ– Shioaji å®¢æˆ¶ç«¯
        with ShioajiClient() as shioaji:
            if not shioaji.is_available():
                logger.error("[OPTION] Shioaji client not available")
                return {
                    "status": "error",
                    "message": "Shioaji client not available",
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }

            # å‰µå»ºè³‡æ–™æº
            data_source = ShioajiOptionDataSource(shioaji)

            # è¨»å†Šçµ±è¨ˆ
            stats = {
                "total_underlyings": len(underlying_ids),
                "total_contracts_registered": 0,
                "total_contracts_updated": 0,
                "errors": []
            }

            # é€å€‹æ¨™çš„è¨»å†Šåˆç´„
            for underlying_id in underlying_ids:
                try:
                    logger.info(f"[OPTION] Registering contracts for {underlying_id}...")

                    # ç²å–åˆç´„åˆ—è¡¨ï¼ˆä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼‰
                    from app.utils.timezone_helpers import today_taiwan
                    option_chain = data_source.get_option_chain(
                        underlying_id,
                        today_taiwan()
                    )

                    if option_chain.empty:
                        logger.warning(f"[OPTION] No contracts found for {underlying_id}")
                        continue

                    # æ‰¹æ¬¡è¨»å†Šåˆç´„ï¼ˆæ¯ 50 å€‹åˆç´„æäº¤ä¸€æ¬¡ï¼‰
                    batch_size = 50
                    total_contracts = len(option_chain)

                    for idx, (_, row) in enumerate(option_chain.iterrows(), 1):
                        try:
                            from app.schemas.option import OptionContractCreate

                            contract_data = OptionContractCreate(
                                contract_id=row['contract_id'],
                                underlying_id=row['underlying_id'],
                                underlying_type=row['underlying_type'],
                                option_type=row['option_type'],
                                strike_price=row['strike_price'],
                                expiry_date=row['expiry_date'],
                                is_active='active'
                            )

                            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
                            existing = OptionContractRepository.get_by_id(
                                db,
                                row['contract_id']
                            )

                            if existing:
                                # æ›´æ–°ç¾æœ‰åˆç´„
                                stats["total_contracts_updated"] += 1
                            else:
                                # å‰µå»ºæ–°åˆç´„
                                OptionContractRepository.create(db, contract_data)
                                stats["total_contracts_registered"] += 1

                            # æ‰¹æ¬¡æäº¤ï¼ˆæ¯ batch_size å€‹åˆç´„æˆ–æœ€å¾Œä¸€å€‹åˆç´„ï¼‰
                            if idx % batch_size == 0 or idx == total_contracts:
                                db.commit()
                                logger.debug(
                                    f"[OPTION] Progress: {idx}/{total_contracts} contracts processed, "
                                    f"committed to database"
                                )

                        except Exception as e:
                            logger.warning(
                                f"[OPTION] Failed to register contract "
                                f"{row['contract_id']}: {str(e)}"
                            )
                            # å›æ»¾ç•¶å‰æ‰¹æ¬¡ä¸­çš„éŒ¯èª¤
                            db.rollback()
                            continue

                    logger.info(
                        f"[OPTION] âœ… Registered {stats['total_contracts_registered']} contracts "
                        f"for {underlying_id} (updated: {stats['total_contracts_updated']})"
                    )

                except Exception as e:
                    logger.error(
                        f"[OPTION] Error registering contracts for "
                        f"{underlying_id}: {str(e)}"
                    )
                    stats["errors"].append(f"{underlying_id}: {str(e)}")

        # è¿”å›çµæœ
        logger.info(
            f"[OPTION] Registration completed. "
            f"New: {stats['total_contracts_registered']}, "
            f"Updated: {stats['total_contracts_updated']}"
        )

        return {
            "status": "success",
            "message": f"Registered {stats['total_contracts_registered']} new contracts",
            "statistics": stats,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }

    except Exception as e:
        logger.error(f"[OPTION] Fatal error in register_option_contracts: {str(e)}")
        return {
            "status": "error",
            "message": f"Fatal error: {str(e)}",
            "timestamp": datetime.now(timezone.utc).isoformat()
        }


@celery_app.task(bind=True, name="app.tasks.sync_option_minute_data")
@record_task_history
def sync_option_minute_data(
    self: Task,
    underlying_ids: Optional[List[str]] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
) -> dict:
    """
    åŒæ­¥é¸æ“‡æ¬Šåˆ†é˜ç·šæ•¸æ“šï¼ˆéšæ®µäºŒï¼‰

    æ³¨æ„ï¼šéšæ®µä¸€ä¸å¯¦ä½œï¼Œåƒ…é ç•™æ¥å£

    Args:
        underlying_ids: æ¨™çš„ä»£ç¢¼åˆ—è¡¨
        start_date: é–‹å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
        end_date: çµæŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰

    Returns:
        Task result
    """
    logger.warning("[OPTION] Minute data sync not implemented in Stage 1")
    return {
        "status": "skipped",
        "message": "Minute data sync not implemented in Stage 1",
        "timestamp": datetime.now(timezone.utc).isoformat()
    }


@celery_app.task(bind=True, name="app.tasks.calculate_option_greeks")
@record_task_history
def calculate_option_greeks(
    self: Task,
    underlying_ids: Optional[List[str]] = None,
    target_date: Optional[str] = None
) -> dict:
    """
    è¨ˆç®—é¸æ“‡æ¬Š Greeksï¼ˆéšæ®µä¸‰ï¼‰

    åŸ·è¡Œæµç¨‹ï¼š
    1. ç²å–é¸æ“‡æ¬Šåˆç´„åˆ—è¡¨
    2. ä½¿ç”¨ Black-Scholes æ¨¡å‹è¨ˆç®— Greeks
    3. å„²å­˜åˆ° option_greeks è¡¨

    Args:
        underlying_ids: æ¨™çš„ä»£ç¢¼åˆ—è¡¨ï¼ˆNone è¡¨ç¤ºä½¿ç”¨é…ç½®ï¼‰
        target_date: ç›®æ¨™æ—¥æœŸï¼ˆYYYY-MM-DDï¼Œé è¨­ç‚ºä»Šå¤©ï¼‰

    Returns:
        Task result with calculation statistics
    """
    start_time = datetime.now(timezone.utc)

    try:
        logger.info(
            f"[GREEKS] ğŸš€ Starting Greeks calculation (task_id: {self.request.id})"
        )

        # è§£æç›®æ¨™æ—¥æœŸ
        try:
            if target_date:
                calc_date = datetime.strptime(target_date, "%Y-%m-%d").date()
            else:
                from app.utils.timezone_helpers import today_taiwan
                calc_date = today_taiwan()
        except ValueError as e:
            logger.error(f"[GREEKS] âŒ Invalid date format: {target_date}")
            return {
                "status": "error",
                "message": f"Invalid date format: {target_date}",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

        logger.info(f"[GREEKS] ğŸ“… Calculation date: {calc_date}")

        # ç²å–è³‡æ–™åº«é€£æ¥
        try:
            db = next(get_db())
        except Exception as e:
            logger.error(f"[GREEKS] âŒ Failed to get database connection: {str(e)}")
            raise self.retry(exc=e, countdown=60)

        # ç²å–ç•¶å‰éšæ®µé…ç½®
        try:
            stage = OptionSyncConfigRepository.get_current_stage(db)
            logger.info(f"[GREEKS] ğŸ“ˆ Current stage: {stage}")

            if stage < 3:
                logger.warning(
                    f"[GREEKS] âš ï¸  Greeks calculation requires stage 3, current: {stage}"
                )
                return {
                    "status": "skipped",
                    "message": f"Greeks calculation requires stage 3 (current: {stage})",
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }
        except Exception as e:
            logger.warning(f"[GREEKS] âš ï¸  Failed to get stage config: {str(e)}")

        # ç²å–å•Ÿç”¨çš„æ¨™çš„ç‰©åˆ—è¡¨
        if not underlying_ids:
            try:
                underlying_ids = OptionSyncConfigRepository.get_enabled_underlyings(db)
            except Exception as e:
                logger.warning(f"[GREEKS] âš ï¸  Failed to get enabled underlyings: {str(e)}")
                underlying_ids = []

        if not underlying_ids:
            logger.warning("[GREEKS] âš ï¸  No underlyings configured. Using default: TX, MTX")
            underlying_ids = ['TX', 'MTX']

        logger.info(f"[GREEKS] ğŸ¯ Target underlyings: {underlying_ids}")

        # åˆå§‹åŒ– Shioaji å®¢æˆ¶ç«¯å’Œè¨ˆç®—å™¨
        try:
            from app.services.greeks_calculator import (
                BlackScholesGreeksCalculator,
                calculate_time_to_expiry
            )
            from app.schemas.option import OptionGreeksCreate
            from app.repositories.option import OptionGreeksRepository

            with ShioajiClient() as shioaji:
                if not shioaji.is_available():
                    error_msg = "Shioaji client not available"
                    logger.error(f"[GREEKS] âŒ {error_msg}")
                    if self.request.retries < self.max_retries:
                        raise self.retry(exc=Exception(error_msg), countdown=300)
                    return {
                        "status": "error",
                        "message": error_msg,
                        "timestamp": datetime.now(timezone.utc).isoformat()
                    }

                # å‰µå»ºè³‡æ–™æºå’Œè¨ˆç®—å™¨
                data_source = ShioajiOptionDataSource(shioaji)
                bs_calculator = BlackScholesGreeksCalculator()

                # çµ±è¨ˆ
                stats = {
                    "total_underlyings": len(underlying_ids),
                    "total_contracts_processed": 0,
                    "greeks_calculated": 0,
                    "errors": []
                }

                # é€å€‹æ¨™çš„è¨ˆç®— Greeks
                for index, underlying_id in enumerate(underlying_ids, 1):
                    try:
                        logger.info(
                            f"[GREEKS] ğŸ“Š Processing {underlying_id} "
                            f"({index}/{len(underlying_ids)})..."
                        )

                        # ç²å–é¸æ“‡æ¬Šéˆæ•¸æ“š
                        option_chain = data_source.get_option_chain(underlying_id, calc_date)

                        if option_chain.empty:
                            logger.warning(f"[GREEKS] No option chain data for {underlying_id}")
                            continue

                        # éæ¿¾æœ‰æ•ˆåˆç´„
                        valid_contracts = option_chain[
                            option_chain['close'].notna() &
                            (option_chain['close'] > 0) &
                            option_chain['strike_price'].notna() &
                            option_chain['expiry_date'].notna()
                        ]

                        if valid_contracts.empty:
                            logger.warning(f"[GREEKS] No valid contracts for {underlying_id}")
                            continue

                        # ä¼°ç®—æ¨™çš„ç¾åƒ¹
                        calls = valid_contracts[valid_contracts['option_type'] == 'CALL']
                        if not calls.empty and 'volume' in calls.columns and calls['volume'].sum() > 0:
                            atm_call = calls.loc[calls['volume'].idxmax()]
                            spot_price = float(atm_call['strike_price'])
                        else:
                            spot_price = float(valid_contracts['strike_price'].median())

                        logger.debug(f"[GREEKS] Spot price: {spot_price}")

                        # é€å€‹åˆç´„è¨ˆç®— Greeks
                        for _, row in valid_contracts.iterrows():
                            try:
                                contract_id = row['contract_id']
                                strike_price = float(row['strike_price'])
                                expiry_date = row['expiry_date']
                                option_type = row['option_type']
                                option_price = float(row['close'])

                                # è¨ˆç®—åˆ°æœŸæ™‚é–“
                                time_to_expiry = calculate_time_to_expiry(expiry_date, calc_date)
                                if time_to_expiry <= 0:
                                    continue

                                # ä¼°ç®—éš±å«æ³¢å‹•ç‡
                                volatility = (option_price / strike_price) * np.sqrt(2 * np.pi / time_to_expiry)
                                volatility = max(0.05, min(volatility, 1.0))

                                # è¨ˆç®— Greeks
                                greeks = bs_calculator.calculate_greeks(
                                    spot_price=spot_price,
                                    strike_price=strike_price,
                                    time_to_expiry=time_to_expiry,
                                    volatility=volatility,
                                    option_type=option_type
                                )

                                if greeks['delta'] is None:
                                    continue

                                # å‰µå»º Greeks è¨˜éŒ„
                                greeks_data = OptionGreeksCreate(
                                    contract_id=contract_id,
                                    datetime=datetime.combine(calc_date, datetime.min.time()),
                                    delta=Decimal(str(greeks['delta'])),
                                    gamma=Decimal(str(greeks['gamma'])) if greeks['gamma'] else None,
                                    theta=Decimal(str(greeks['theta'])) if greeks['theta'] else None,
                                    vega=Decimal(str(greeks['vega'])) if greeks['vega'] else None,
                                    rho=Decimal(str(greeks['rho'])) if greeks['rho'] else None,
                                    vanna=Decimal(str(greeks['vanna'])) if greeks['vanna'] else None,
                                    spot_price=Decimal(str(spot_price)),
                                    volatility=Decimal(str(volatility)),
                                    risk_free_rate=Decimal('0.01')
                                )

                                # å„²å­˜åˆ°è³‡æ–™åº«ï¼ˆupsertï¼‰
                                OptionGreeksRepository.upsert(db, greeks_data)
                                stats["greeks_calculated"] += 1

                            except Exception as e:
                                logger.debug(
                                    f"[GREEKS] Failed to calculate for contract {row.get('contract_id', 'unknown')}: {str(e)}"
                                )
                                continue

                        stats["total_contracts_processed"] += len(valid_contracts)
                        logger.info(
                            f"[GREEKS] âœ… Processed {len(valid_contracts)} contracts for {underlying_id}"
                        )

                    except Exception as e:
                        logger.error(
                            f"[GREEKS] âŒ Error processing {underlying_id}: {str(e)}"
                        )
                        stats["errors"].append(f"{underlying_id}: {str(e)}")

        except Exception as e:
            logger.error(f"[GREEKS] âŒ Failed to initialize: {str(e)}")
            if self.request.retries < self.max_retries:
                raise self.retry(exc=e, countdown=300)
            return {
                "status": "error",
                "message": f"Initialization error: {str(e)}",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

        # è¨ˆç®—åŸ·è¡Œæ™‚é–“
        duration = (datetime.now(timezone.utc) - start_time).total_seconds()
        stats['duration_seconds'] = duration

        # è¨˜éŒ„æœ€çµ‚çµ±è¨ˆ
        logger.info(
            f"[GREEKS] ğŸ Calculation completed in {duration:.1f}s. "
            f"Processed: {stats['total_contracts_processed']}, "
            f"Greeks calculated: {stats['greeks_calculated']}"
        )

        if stats['errors']:
            logger.error(
                f"[GREEKS] âŒ Errors:\n" +
                "\n".join(f"  - {error}" for error in stats['errors'][:10])
            )

        # è¿”å›çµæœ
        if stats["greeks_calculated"] > 0:
            return {
                "status": "success",
                "message": f"Calculated Greeks for {stats['greeks_calculated']} contracts",
                "statistics": stats,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        else:
            return {
                "status": "error",
                "message": "No Greeks were calculated",
                "statistics": stats,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

    except Exception as e:
        duration = (datetime.now(timezone.utc) - start_time).total_seconds()
        logger.error(
            f"[GREEKS] âŒ Fatal error after {duration:.1f}s: {type(e).__name__}: {str(e)}",
            exc_info=True
        )
        return {
            "status": "error",
            "message": f"Fatal error: {str(e)}",
            "duration_seconds": duration,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
