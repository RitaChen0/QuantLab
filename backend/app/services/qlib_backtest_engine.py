"""
Qlib å›æ¸¬å¼•æ“

æ­¤æ¨¡çµ„è² è²¬ä½¿ç”¨ Qlib åŸ·è¡Œé‡åŒ–ç­–ç•¥å›æ¸¬ã€‚
æ”¯æ´æ©Ÿå™¨å­¸ç¿’æ¨¡å‹å’Œå‚³çµ±ç­–ç•¥ã€‚
"""
from datetime import date, datetime
from typing import Dict, List, Optional, Any
import pandas as pd
from loguru import logger
from sqlalchemy.orm import Session

from app.services.qlib_data_adapter import QlibDataAdapter
from app.core.qlib_config import qlib_config
from app.services.alpha158_factors import alpha158_calculator


class QlibBacktestEngine:
    """
    Qlib å›æ¸¬å¼•æ“

    æ”¯æ´ï¼š
    - æ©Ÿå™¨å­¸ç¿’ç­–ç•¥
    - å› å­ç­–ç•¥
    - çµ„åˆå„ªåŒ–ç­–ç•¥
    """

    def __init__(self, db: Session):
        self.db = db
        self.data_adapter = QlibDataAdapter()

        # ç¢ºä¿ Qlib å·²åˆå§‹åŒ–
        if not qlib_config.is_qlib_available():
            logger.warning("Qlib is not available")
            self.qlib_available = False
        else:
            self.qlib_available = True
            qlib_config.init_qlib()

    def _compute_qlib_expressions(
        self,
        df: pd.DataFrame,
        fields: List[str]
    ) -> pd.DataFrame:
        """
        è¨ˆç®— Qlib è¡¨é”å¼ï¼ˆä½¿ç”¨ pandas å¯¦ä½œï¼‰- å·²æ£„ç”¨

        âš ï¸ DEPRECATED: æ­¤æ–¹æ³•ä½¿ç”¨ pandas æ‰‹å‹•æ¨¡æ“¬ Qlib è¡¨é”å¼è¨ˆç®—ã€‚
        ç¾å·²æ”¹ç”¨ QlibDataAdapter.get_qlib_features() ç›´æ¥ä½¿ç”¨ Qlib å¼•æ“ã€‚

        æ­¤æ–¹æ³•ä¿ç•™ä½œç‚º fallbackï¼Œç•¶ Qlib æœ¬åœ°æ•¸æ“šä¸å¯ç”¨æ™‚ä½¿ç”¨ã€‚

        Args:
            df: åŸå§‹ OHLCV DataFrameï¼ˆå¿…é ˆåŒ…å« $open, $high, $low, $close, $volume æ¬„ä½ï¼‰
            fields: Qlib è¡¨é”å¼åˆ—è¡¨

        Returns:
            DataFrame: åŒ…å«è¨ˆç®—çµæœçš„æ•¸æ“š
        """
        logger.warning(
            "_compute_qlib_expressions() is deprecated. "
            "Using Qlib native engine instead (via QlibDataAdapter.get_qlib_features())."
        )
        import re
        import numpy as np

        result_df = df.copy()

        for field in fields:
            try:
                # è·³éåŸºç¤å­—æ®µï¼ˆå·²ç¶“å­˜åœ¨ï¼‰
                if field in ['$open', '$high', '$low', '$close', '$volume']:
                    continue

                # Mean($close, N) - N æ—¥ç§»å‹•å¹³å‡
                match = re.match(r'Mean\(\$(\w+),\s*(\d+)\)', field)
                if match:
                    col_name, window = match.groups()
                    window = int(window)
                    result_df[field] = df[f'${col_name}'].rolling(window=window, min_periods=1).mean()
                    continue

                # Std($close, N) - N æ—¥æ¨™æº–å·®
                match = re.match(r'Std\(\$(\w+),\s*(\d+)\)', field)
                if match:
                    col_name, window = match.groups()
                    window = int(window)
                    result_df[field] = df[f'${col_name}'].rolling(window=window, min_periods=1).std()
                    continue

                # Ref($close, N) - N æ—¥å‰çš„å€¼
                match = re.match(r'Ref\(\$(\w+),\s*(\d+)\)', field)
                if match:
                    col_name, periods = match.groups()
                    periods = int(periods)
                    result_df[field] = df[f'${col_name}'].shift(periods)
                    continue

                # Max($high, N) - N æ—¥æœ€å¤§å€¼
                match = re.match(r'Max\(\$(\w+),\s*(\d+)\)', field)
                if match:
                    col_name, window = match.groups()
                    window = int(window)
                    result_df[field] = df[f'${col_name}'].rolling(window=window, min_periods=1).max()
                    continue

                # Min($low, N) - N æ—¥æœ€å°å€¼
                match = re.match(r'Min\(\$(\w+),\s*(\d+)\)', field)
                if match:
                    col_name, window = match.groups()
                    window = int(window)
                    result_df[field] = df[f'${col_name}'].rolling(window=window, min_periods=1).min()
                    continue

                # Corr($close, $volume, N) - N æ—¥ç›¸é—œä¿‚æ•¸
                match = re.match(r'Corr\(\$(\w+),\s*\$(\w+),\s*(\d+)\)', field)
                if match:
                    col1, col2, window = match.groups()
                    window = int(window)
                    result_df[field] = df[f'${col1}'].rolling(window=window, min_periods=1).corr(df[f'${col2}'])
                    continue

                # è¤‡é›œè¡¨é”å¼ï¼š($close - Mean($close, N)) / Std($close, N)
                match = re.match(r'\(\$(\w+)\s*-\s*Mean\(\$\w+,\s*(\d+)\)\)\s*/\s*Std\(\$\w+,\s*(\d+)\)', field)
                if match:
                    col_name, mean_window, std_window = match.groups()
                    mean_window = int(mean_window)
                    std_window = int(std_window)
                    mean_val = df[f'${col_name}'].rolling(window=mean_window, min_periods=1).mean()
                    std_val = df[f'${col_name}'].rolling(window=std_window, min_periods=1).std()
                    result_df[field] = (df[f'${col_name}'] - mean_val) / (std_val + 1e-8)
                    continue

                # è¤‡é›œè¡¨é”å¼ï¼šRef($close, N) / $close - 1
                match = re.match(r'Ref\(\$(\w+),\s*(\d+)\)\s*/\s*\$\w+\s*-\s*1', field)
                if match:
                    col_name, periods = match.groups()
                    periods = int(periods)
                    result_df[field] = df[f'${col_name}'].shift(periods) / df[f'${col_name}'] - 1
                    continue

                # è¤‡é›œè¡¨é”å¼ï¼šMean($close, N1) / Mean($close, N2)
                match = re.match(r'Mean\(\$(\w+),\s*(\d+)\)\s*/\s*Mean\(\$\w+,\s*(\d+)\)', field)
                if match:
                    col_name, window1, window2 = match.groups()
                    window1 = int(window1)
                    window2 = int(window2)
                    ma1 = df[f'${col_name}'].rolling(window=window1, min_periods=1).mean()
                    ma2 = df[f'${col_name}'].rolling(window=window2, min_periods=1).mean()
                    result_df[field] = ma1 / (ma2 + 1e-8)
                    continue

                # è¤‡é›œè¡¨é”å¼ï¼šMax($high, N) - Min($low, N)
                match = re.match(r'Max\(\$(\w+),\s*(\d+)\)\s*-\s*Min\(\$(\w+),\s*(\d+)\)', field)
                if match:
                    high_col, high_window, low_col, low_window = match.groups()
                    high_window = int(high_window)
                    low_window = int(low_window)
                    max_high = df[f'${high_col}'].rolling(window=high_window, min_periods=1).max()
                    min_low = df[f'${low_col}'].rolling(window=low_window, min_periods=1).min()
                    result_df[field] = max_high - min_low
                    continue

                logger.warning(f"Unsupported Qlib expression: {field}")

            except Exception as e:
                logger.error(f"Failed to compute expression '{field}': {str(e)}")

        return result_df

    def _get_alpha158_data(
        self,
        symbol: str,
        start_date: date,
        end_date: date,
        config: Optional[Dict] = None
    ) -> Optional[pd.DataFrame]:
        """
        ä½¿ç”¨ Alpha158 å› å­åº«ç²å–æ•¸æ“š

        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            config: Alpha158 é…ç½®ï¼ˆå¯é¸ï¼‰

        Returns:
            DataFrame: åŒ…å« Alpha158 å› å­çš„æ•¸æ“š
        """
        try:
            logger.info(f"Computing Alpha158 factors for {symbol}")

            # 1. ç²å–åŸºç¤ OHLCV æ•¸æ“š
            base_df = self.data_adapter.get_qlib_ohlcv(symbol, start_date, end_date)

            if base_df is None or base_df.empty:
                logger.warning(f"No base data available for {symbol}")
                return None

            # 2. è¨ˆç®— Alpha158 å› å­
            result_df, factor_names = alpha158_calculator.compute_all_factors(base_df, config)

            logger.info(f"Computed {len(factor_names)} Alpha158 factors with {len(result_df)} rows")
            logger.debug(f"Sample factors: {factor_names[:10]}")

            return result_df

        except Exception as e:
            logger.error(f"Failed to compute Alpha158 factors: {str(e)}")
            import traceback
            logger.debug(traceback.format_exc())
            return None

    def _get_qlib_data_with_expressions(
        self,
        symbol: str,
        start_date: date,
        end_date: date,
        fields: Optional[List[str]] = None
    ) -> Optional[pd.DataFrame]:
        """
        ä½¿ç”¨ Qlib è¡¨é”å¼ç²å–æ•¸æ“šï¼ˆç›´æ¥ä½¿ç”¨ D.features() APIï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            fields: Qlib è¡¨é”å¼å­—æ®µåˆ—è¡¨ï¼ˆå¦‚ ['$close', 'Mean($close, 5)']ï¼‰

        Returns:
            DataFrame: åŒ…å«è¨ˆç®—çµæœçš„æ•¸æ“š
        """
        try:
            logger.info(f"Using Qlib expressions engine for {symbol}")

            # ç›´æ¥ä½¿ç”¨ QlibDataAdapter çš„ get_qlib_features() æ–¹æ³•
            # é€™æœƒå„ªå…ˆå¾æœ¬åœ° qlib æ•¸æ“šè®€å–ï¼Œä¸¦ä½¿ç”¨ qlib è¡¨é”å¼å¼•æ“è¨ˆç®—æŒ‡æ¨™
            result_df = self.data_adapter.get_qlib_features(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date,
                fields=fields
            )

            if result_df is None or result_df.empty:
                logger.warning(f"No data available for {symbol}")
                return None

            logger.info(f"âœ… Got {len(result_df)} rows with {len(result_df.columns)} fields from Qlib")
            logger.debug(f"Fields: {list(result_df.columns)[:10]}")

            return result_df

        except Exception as e:
            logger.error(f"Failed to get Qlib expressions data: {str(e)}")
            import traceback
            logger.debug(traceback.format_exc())
            return None

    async def run_backtest(
        self,
        strategy_code: str,
        symbol: str,
        start_date: date,
        end_date: date,
        initial_capital: float,
        parameters: dict
    ) -> dict:
        """
        åŸ·è¡Œ Qlib å›æ¸¬

        Args:
            strategy_code: ç­–ç•¥ä»£ç¢¼æˆ–é…ç½®
            symbol: è‚¡ç¥¨ä»£ç¢¼
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            initial_capital: åˆå§‹è³‡é‡‘
            parameters: ç­–ç•¥åƒæ•¸

        Returns:
            dict: å›æ¸¬çµæœï¼ˆæ¨™æº–æ ¼å¼ï¼‰
        """
        if not self.qlib_available:
            raise RuntimeError("Qlib is not available. Please install it first.")

        try:
            logger.info(f"Starting Qlib backtest for {symbol} from {start_date} to {end_date}")

            # 1. æº–å‚™æ•¸æ“š
            logger.info("Preparing data...")

            # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨ Qlib è¡¨é”å¼
            use_qlib_expressions = parameters.get('use_qlib_expressions', False)
            qlib_fields = parameters.get('qlib_fields', None)

            # å˜—è©¦å¾ç­–ç•¥ä»£ç¢¼ä¸­æå– QLIB_FIELDSï¼ˆä½¿ç”¨æ­£å‰‡è¡¨é”å¼ï¼Œä¸åŸ·è¡Œä»£ç¢¼ï¼‰
            if not qlib_fields and 'QLIB_FIELDS' in strategy_code:
                try:
                    import re
                    import ast

                    # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå– QLIB_FIELDS = [...] å®šç¾©
                    # æ”¯æ´å¤šè¡Œåˆ—è¡¨å®šç¾©
                    pattern = r'QLIB_FIELDS\s*=\s*\[(.*?)\]'
                    match = re.search(pattern, strategy_code, re.DOTALL)

                    if match:
                        # æå–åˆ—è¡¨å…§å®¹ä¸¦ä½¿ç”¨ ast.literal_eval å®‰å…¨è§£æ
                        list_content = '[' + match.group(1) + ']'
                        qlib_fields = ast.literal_eval(list_content)
                        logger.info(f"Extracted QLIB_FIELDS from strategy code: {qlib_fields}")
                        use_qlib_expressions = True
                    else:
                        logger.warning("QLIB_FIELDS pattern not found in strategy code")
                except Exception as e:
                    logger.warning(f"Failed to extract QLIB_FIELDS from strategy code: {e}")

            # å„ªå…ˆä½¿ç”¨ Qlib è¡¨é”å¼ï¼ˆå¾æœ¬åœ° qlib æ•¸æ“šè®€å– + è‡ªå‹•è¨ˆç®—æŒ‡æ¨™ï¼‰
            if use_qlib_expressions or qlib_fields:
                logger.info("Using Qlib expressions engine...")

                # âš ï¸ é‡è¦ï¼šç¢ºä¿åŒ…å«åŸºç¤ OHLCV æ¬„ä½ï¼Œç”¨æ–¼äº¤æ˜“æ¨¡æ“¬
                # å› ç‚º _simulate_trading éœ€è¦ $close ä¾†è¨ˆç®—æ¬Šç›Šå’ŒåŸ·è¡Œäº¤æ˜“
                base_fields = ['$open', '$high', '$low', '$close', '$volume', '$factor']

                if qlib_fields:
                    # åˆä½µåŸºç¤æ¬„ä½å’Œè‡ªå®šç¾©å› å­æ¬„ä½ï¼Œé¿å…é‡è¤‡
                    all_fields = base_fields + [f for f in qlib_fields if f not in base_fields]
                else:
                    all_fields = base_fields

                dataset = self._get_qlib_data_with_expressions(
                    symbol, start_date, end_date, fields=all_fields
                )
            else:
                # Fallback: ä½¿ç”¨ get_qlib_features()ï¼Œå®ƒæœƒå„ªå…ˆå¾æœ¬åœ°è®€å–
                logger.info("Using Qlib features with default technical indicators...")
                dataset = self.data_adapter.get_qlib_features(
                    symbol, start_date, end_date
                )

            if dataset is None or dataset.empty:
                raise ValueError(f"No data available for {symbol}")

            # 2. è§£æç­–ç•¥
            logger.info("Parsing strategy...")
            strategy_type = parameters.get('strategy_type', 'simple')

            if strategy_type == 'ml_model':
                # æ©Ÿå™¨å­¸ç¿’ç­–ç•¥
                result = await self._run_ml_backtest(
                    strategy_code, dataset, symbol, start_date, end_date,
                    initial_capital, parameters
                )
            else:
                # ç°¡å–®ç­–ç•¥ï¼ˆåŸºæ–¼ä¿¡è™Ÿï¼‰
                result = await self._run_simple_backtest(
                    strategy_code, dataset, symbol, start_date, end_date,
                    initial_capital, parameters
                )

            logger.info(f"Qlib backtest completed for {symbol}")
            return result

        except Exception as e:
            logger.error(f"Qlib backtest failed: {str(e)}")
            raise

    async def _run_simple_backtest(
        self,
        strategy_code: str,
        dataset: pd.DataFrame,
        symbol: str,
        start_date: date,
        end_date: date,
        initial_capital: float,
        parameters: dict
    ) -> dict:
        """
        åŸ·è¡Œç°¡å–®ç­–ç•¥å›æ¸¬ï¼ˆåŸºæ–¼æŠ€è¡“æŒ‡æ¨™ä¿¡è™Ÿï¼‰

        Args:
            strategy_code: ç­–ç•¥ä»£ç¢¼
            dataset: æ•¸æ“š DataFrame
            symbol: è‚¡ç¥¨ä»£ç¢¼
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            initial_capital: åˆå§‹è³‡é‡‘
            parameters: ç­–ç•¥åƒæ•¸

        Returns:
            dict: å›æ¸¬çµæœ
        """
        try:
            # åŸ·è¡Œç­–ç•¥ä»£ç¢¼ç”Ÿæˆä¿¡è™Ÿ
            signals = self._execute_strategy_code(strategy_code, dataset, parameters)

            # æ¨¡æ“¬äº¤æ˜“
            trades, equity_curve = self._simulate_trading(
                signals, dataset, initial_capital, symbol
            )

            # è¨ˆç®—ç¸¾æ•ˆæŒ‡æ¨™
            metrics = self._calculate_metrics(
                equity_curve, trades, initial_capital
            )

            return {
                'trades': trades,
                'equity_curve': equity_curve,
                'metrics': metrics,
                'engine': 'qlib',
                'strategy_type': 'simple'
            }

        except Exception as e:
            logger.error(f"Simple backtest failed: {str(e)}")
            raise

    async def _run_ml_backtest(
        self,
        strategy_code: str,
        dataset: pd.DataFrame,
        symbol: str,
        start_date: date,
        end_date: date,
        initial_capital: float,
        parameters: dict
    ) -> dict:
        """
        åŸ·è¡Œæ©Ÿå™¨å­¸ç¿’ç­–ç•¥å›æ¸¬

        ä½¿ç”¨ LightGBM é æ¸¬æœªä¾†æ”¶ç›Šç‡ï¼Œæ ¹æ“šé æ¸¬çµæœç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ

        Args:
            strategy_code: æ¨¡å‹é…ç½®æˆ–è¨“ç·´ä»£ç¢¼
            dataset: æ•¸æ“š DataFrameï¼ˆå«æŠ€è¡“æŒ‡æ¨™ï¼‰
            symbol: è‚¡ç¥¨ä»£ç¢¼
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            initial_capital: åˆå§‹è³‡é‡‘
            parameters: ç­–ç•¥åƒæ•¸

        Returns:
            dict: å›æ¸¬çµæœ
        """
        try:
            logger.info("Starting ML model backtest...")

            # 1. ç‰¹å¾µå·¥ç¨‹ï¼šå‰µå»ºç›®æ¨™è®Šæ•¸ï¼ˆæœªä¾† N æ—¥æ”¶ç›Šç‡ï¼‰
            prediction_days = parameters.get('prediction_days', 5)
            dataset = dataset.copy()  # é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
            dataset['target'] = dataset['$close'].shift(-prediction_days) / dataset['$close'] - 1

            # 2. æº–å‚™è¨“ç·´/æ¸¬è©¦æ•¸æ“š
            train_ratio = parameters.get('train_ratio', 0.7)
            split_index = int(len(dataset) * train_ratio)

            train_data = dataset.iloc[:split_index]
            test_data = dataset.iloc[split_index:]

            logger.info(f"Train: {len(train_data)} days, Test: {len(test_data)} days")

            # 3. é¸æ“‡ç‰¹å¾µï¼ˆæ’é™¤åŸºç¤åƒ¹æ ¼æ¬„ä½å’Œç›®æ¨™ï¼‰
            feature_cols = [col for col in dataset.columns
                          if col not in ['$open', '$high', '$low', '$close', '$volume', '$factor', 'target']
                          and not dataset[col].isna().all()]

            if len(feature_cols) == 0:
                raise ValueError("No valid features found for ML model")

            logger.info(f"Using {len(feature_cols)} features: {feature_cols[:5]}...")

            # 4. è¨“ç·´ LightGBM æ¨¡å‹
            try:
                import lightgbm as lgb
            except ImportError:
                logger.error("LightGBM not installed, using simple linear model")
                # ä½¿ç”¨ç°¡å–®ç·šæ€§æ¨¡å‹ä½œç‚ºæ›¿ä»£
                signals = self._simple_ml_predict(dataset, test_data, feature_cols)
                return await self._run_simple_backtest(
                    "",  # ç„¡éœ€ç­–ç•¥ä»£ç¢¼
                    dataset,
                    symbol,
                    start_date,
                    end_date,
                    initial_capital,
                    parameters,
                    signals  # ä½¿ç”¨é æ¸¬ä¿¡è™Ÿ
                )

            # æº–å‚™è¨“ç·´æ•¸æ“š
            X_train = train_data[feature_cols].fillna(0)
            y_train = train_data['target'].fillna(0)

            # ç§»é™¤ç„¡æ•ˆæ•¸æ“š
            valid_mask = ~y_train.isna()
            X_train = X_train[valid_mask]
            y_train = y_train[valid_mask]

            # è¨“ç·´æ¨¡å‹
            model = lgb.LGBMRegressor(
                n_estimators=parameters.get('n_estimators', 100),
                learning_rate=parameters.get('learning_rate', 0.05),
                max_depth=parameters.get('max_depth', 5),
                num_leaves=parameters.get('num_leaves', 31),
                random_state=42,
                verbose=-1
            )

            logger.info("Training LightGBM model...")
            model.fit(X_train, y_train)

            # 5. ç”Ÿæˆé æ¸¬å’Œäº¤æ˜“ä¿¡è™Ÿ
            X_test = test_data[feature_cols].fillna(0)
            predictions = model.predict(X_test)

            # æ ¹æ“šé æ¸¬æ”¶ç›Šç‡ç”Ÿæˆä¿¡è™Ÿ
            threshold = parameters.get('signal_threshold', 0.02)  # 2% é–¾å€¼

            signals = pd.Series(0, index=dataset.index)
            test_indices = test_data.index

            for i, (idx, pred) in enumerate(zip(test_indices, predictions)):
                if pred > threshold:
                    signals.loc[idx] = 1  # è²·å…¥
                elif pred < -threshold:
                    signals.loc[idx] = -1  # è³£å‡º

            logger.info(f"Generated {(signals == 1).sum()} buy and {(signals == -1).sum()} sell signals")

            # 6. åŸ·è¡Œå›æ¸¬
            trades, equity_curve = self._simulate_trading(
                signals,
                dataset,
                initial_capital,
                parameters
            )

            # 7. è¨ˆç®—ç¸¾æ•ˆ
            metrics = self._calculate_metrics(
                equity_curve,
                trades,
                initial_capital
            )

            # æ·»åŠ  ML æ¨¡å‹ç‰¹å®šæŒ‡æ¨™
            metrics['model_type'] = 'LightGBM'
            metrics['train_samples'] = len(X_train)
            metrics['test_samples'] = len(X_test)
            metrics['feature_count'] = len(feature_cols)
            metrics['prediction_days'] = prediction_days

            logger.info(f"ML backtest completed: {len(trades)} trades, Return: {metrics.get('total_return', 0):.2%}")

            return {
                'trades': trades,
                'equity_curve': equity_curve,
                'metrics': metrics,
                'engine': 'qlib',
                'strategy_type': 'ml_model',
                'model_info': {
                    'type': 'LightGBM',
                    'features': feature_cols[:10],  # å‰ 10 å€‹ç‰¹å¾µ
                    'train_size': len(X_train),
                    'test_size': len(X_test)
                }
            }

        except Exception as e:
            logger.error(f"ML backtest failed: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            raise

    def _simple_ml_predict(
        self,
        dataset: pd.DataFrame,
        test_data: pd.DataFrame,
        feature_cols: list
    ) -> pd.Series:
        """
        ç°¡å–® ML é æ¸¬ï¼ˆç•¶ LightGBM ä¸å¯ç”¨æ™‚ä½¿ç”¨ï¼‰
        ä½¿ç”¨å‹•é‡å’Œå‡å€¼å›æ­¸çš„çµ„åˆ
        """
        signals = pd.Series(0, index=dataset.index)

        # ä½¿ç”¨ç°¡å–®è¦å‰‡ï¼šå‹•é‡ + å‡å€¼å›æ­¸
        if '$return' in dataset.columns and '$ma_20' in dataset.columns:
            momentum = dataset['$return'].rolling(5).mean()
            ma_ratio = dataset['$close'] / dataset['$ma_20'] - 1

            for idx in test_data.index:
                if momentum.loc[idx] > 0.01 and ma_ratio.loc[idx] > -0.05:
                    signals.loc[idx] = 1
                elif momentum.loc[idx] < -0.01 and ma_ratio.loc[idx] < 0.05:
                    signals.loc[idx] = -1

        return signals

    def _execute_strategy_code(
        self,
        code: str,
        dataset: pd.DataFrame,
        parameters: dict
    ) -> pd.Series:
        """
        åŸ·è¡Œç­–ç•¥ä»£ç¢¼ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ

        Args:
            code: ç­–ç•¥ä»£ç¢¼
            dataset: æ•¸æ“š DataFrame
            parameters: ç­–ç•¥åƒæ•¸

        Returns:
            pd.Series: äº¤æ˜“ä¿¡è™Ÿï¼ˆ1=è²·å…¥, -1=è³£å‡º, 0=æŒæœ‰ï¼‰
        """
        try:
            # å°å…¥ Qlib æ¨¡çµ„ï¼ˆé å…ˆå°å…¥ä»¥é¿å…åœ¨ç­–ç•¥ä»£ç¢¼ä¸­éœ€è¦ __import__ï¼‰
            try:
                from qlib.data import D
                import numpy as np
                import lightgbm as lgb
            except ImportError as e:
                logger.warning(f"Import error: {e}, using pandas only")
                D = None
                import numpy as np
                lgb = None

            # å‰µå»ºå—é™çš„å®‰å…¨å‘½åç©ºé–“ï¼ˆå®Œå…¨éš”é›¢ __builtins__ï¼‰
            # èˆ‡ backtest_engine.py ä¿æŒä¸€è‡´çš„å®‰å…¨ç­–ç•¥
            safe_builtins = {
                # åªå…è¨±å®‰å…¨çš„å…§å»ºå‡½æ•¸
                'len': len,
                'range': range,
                'enumerate': enumerate,
                'zip': zip,
                'map': map,
                'filter': filter,
                'sum': sum,
                'min': min,
                'max': max,
                'abs': abs,
                'round': round,
                'int': int,
                'float': float,
                'str': str,
                'bool': bool,
                'list': list,
                'dict': dict,
                'tuple': tuple,
                'set': set,
                'print': print,  # å…è¨± print() ç”¨æ–¼èª¿è©¦
                'True': True,
                'False': False,
                'None': None,
            }

            # å‰µå»ºåŸ·è¡Œç’°å¢ƒï¼ˆä½¿ç”¨å—é™çš„ __builtins__ï¼‰
            env = {
                '__builtins__': safe_builtins,  # ğŸ”’ å®‰å…¨é™åˆ¶ï¼šé˜²æ­¢ä»£ç¢¼æ³¨å…¥æ”»æ“Š
                'pd': pd,
                'np': np,
                'D': D,  # Qlib data API
                'lgb': lgb,  # LightGBM for ML strategies
                'df': dataset,
                'params': parameters,
                'signals': pd.Series(0, index=dataset.index)
            }

            # ç§»é™¤ç­–ç•¥ä»£ç¢¼ä¸­çš„ import èªå¥ï¼ˆå› ç‚ºæˆ‘å€‘å·²é å…ˆå°å…¥æ‰€éœ€æ¨¡çµ„ï¼‰
            import re
            cleaned_code = re.sub(r'^\s*from\s+[\w.]+\s+import\s+.*$', '', code, flags=re.MULTILINE)
            cleaned_code = re.sub(r'^\s*import\s+[\w., ]+\s*$', '', cleaned_code, flags=re.MULTILINE)

            logger.info(f"ğŸ“Š Executing strategy code...")
            logger.info(f"   Dataset shape: {dataset.shape}")
            logger.info(f"   Date range: {dataset.index[0]} to {dataset.index[-1]}")
            logger.info(f"   Parameters: {parameters}")

            # åŸ·è¡Œç­–ç•¥ä»£ç¢¼
            exec(cleaned_code, env)

            signals = env.get('signals', pd.Series(0, index=dataset.index))

            # è©³ç´°ä¿¡è™Ÿçµ±è¨ˆ
            buy_signals = len(signals[signals == 1])
            sell_signals = len(signals[signals == -1])
            hold_signals = len(signals[signals == 0])
            total_signals = len(signals)

            logger.info(f"âœ… Signal generation completed:")
            logger.info(f"   ğŸ“ˆ BUY signals:  {buy_signals} ({buy_signals/total_signals*100:.1f}%)")
            logger.info(f"   ğŸ“‰ SELL signals: {sell_signals} ({sell_signals/total_signals*100:.1f}%)")
            logger.info(f"   â¸ï¸  HOLD signals: {hold_signals} ({hold_signals/total_signals*100:.1f}%)")
            logger.info(f"   ğŸ“Š Total days:   {total_signals}")

            return signals

        except Exception as e:
            logger.error(f"Failed to execute strategy code: {str(e)}")
            raise

    def _simulate_trading(
        self,
        signals: pd.Series,
        dataset: pd.DataFrame,
        initial_capital: float,
        symbol: str
    ) -> tuple[List[dict], List[dict]]:
        """
        æ¨¡æ“¬äº¤æ˜“åŸ·è¡Œ

        Args:
            signals: äº¤æ˜“ä¿¡è™Ÿ
            dataset: åƒ¹æ ¼æ•¸æ“š
            initial_capital: åˆå§‹è³‡é‡‘
            symbol: è‚¡ç¥¨ä»£ç¢¼

        Returns:
            tuple: (äº¤æ˜“è¨˜éŒ„åˆ—è¡¨, è³‡é‡‘æ›²ç·šåˆ—è¡¨)
        """
        logger.info(f"ğŸ’° Starting trade simulation...")
        logger.info(f"   Initial capital: ${initial_capital:,.2f}")
        logger.info(f"   Symbol: {symbol}")

        trades = []
        equity_curve = []

        cash = initial_capital
        position = 0
        entry_price = 0
        buy_count = 0
        sell_count = 0

        for idx in dataset.index:
            signal = signals.get(idx, 0)
            price = dataset.loc[idx, '$close']

            # è¨ˆç®—ç•¶å‰æ¬Šç›Š
            equity = cash + position * price
            equity_curve.append({
                'date': idx.strftime('%Y-%m-%d'),
                'equity': float(equity)
            })

            # åŸ·è¡Œäº¤æ˜“
            if signal == 1 and position == 0:  # è²·å…¥ä¿¡è™Ÿ
                shares = int(cash / price)
                if shares > 0:
                    position = shares
                    entry_price = price
                    cash -= shares * price
                    buy_count += 1

                    trade_value = shares * price
                    logger.debug(f"   ğŸ“ˆ BUY  {idx.strftime('%Y-%m-%d')}: {shares} shares @ ${price:.2f} = ${trade_value:,.2f}")

                    trades.append({
                        'date': idx.strftime('%Y-%m-%d'),
                        'action': 'BUY',
                        'price': float(price),
                        'shares': shares,
                        'symbol': symbol
                    })

            elif signal == -1 and position > 0:  # è³£å‡ºä¿¡è™Ÿ
                cash += position * price
                pnl = (price - entry_price) * position
                sell_count += 1

                trade_value = position * price
                pnl_pct = (price / entry_price - 1) * 100
                logger.debug(f"   ğŸ“‰ SELL {idx.strftime('%Y-%m-%d')}: {position} shares @ ${price:.2f} = ${trade_value:,.2f} (PnL: ${pnl:+,.2f} / {pnl_pct:+.2f}%)")

                trades.append({
                    'date': idx.strftime('%Y-%m-%d'),
                    'action': 'SELL',
                    'price': float(price),
                    'shares': position,
                    'symbol': symbol,
                    'pnl': float(pnl)
                })

                position = 0
                entry_price = 0

        # æœ€çµ‚çµç®—
        if position > 0:
            final_price = dataset.iloc[-1]['$close']
            final_pnl = (final_price - entry_price) * position
            cash += position * final_price
            sell_count += 1

            logger.info(f"   ğŸ”š Final settlement: Selling {position} shares @ ${final_price:.2f} (PnL: ${final_pnl:+,.2f})")

            trades.append({
                'date': dataset.index[-1].strftime('%Y-%m-%d'),
                'action': 'SELL',
                'price': float(final_price),
                'shares': position,
                'symbol': symbol,
                'pnl': float(final_pnl)
            })

        # è¨ˆç®—ç¸½é«”çµ±è¨ˆ
        final_equity = cash
        total_return = (final_equity / initial_capital - 1) * 100
        total_trades = len(trades)

        logger.info(f"âœ… Trade simulation completed:")
        logger.info(f"   ğŸ“Š Total trades:    {total_trades} ({buy_count} BUY + {sell_count} SELL)")
        logger.info(f"   ğŸ’µ Initial capital: ${initial_capital:,.2f}")
        logger.info(f"   ğŸ’° Final equity:    ${final_equity:,.2f}")
        logger.info(f"   ğŸ“ˆ Total return:    {total_return:+.2f}%")

        return trades, equity_curve

    def _calculate_metrics(
        self,
        equity_curve: List[dict],
        trades: List[dict],
        initial_capital: float
    ) -> dict:
        """
        è¨ˆç®—ç¸¾æ•ˆæŒ‡æ¨™

        Args:
            equity_curve: è³‡é‡‘æ›²ç·š
            trades: äº¤æ˜“è¨˜éŒ„
            initial_capital: åˆå§‹è³‡é‡‘

        Returns:
            dict: ç¸¾æ•ˆæŒ‡æ¨™
        """
        if not equity_curve:
            return {}

        equities = [item['equity'] for item in equity_curve]
        final_equity = equities[-1]
        num_days = len(equity_curve)

        # è¨ˆç®—å ±é…¬
        total_return = (final_equity - initial_capital) / initial_capital

        # è¨ˆç®—å¹´åŒ–å ±é…¬ç‡
        # å…¬å¼ï¼š(1 + total_return) ^ (365 / days) - 1
        if num_days > 0:
            annual_return = (1 + total_return) ** (365.0 / num_days) - 1
        else:
            annual_return = 0

        # è¨ˆç®—æ¯æ—¥å ±é…¬ç‡
        daily_returns = []
        for i in range(1, len(equities)):
            daily_return = (equities[i] - equities[i-1]) / equities[i-1] if equities[i-1] != 0 else 0
            daily_returns.append(daily_return)

        # è¨ˆç®—æ³¢å‹•ç‡ï¼ˆæ—¥å ±é…¬ç‡æ¨™æº–å·®çš„å¹´åŒ–å€¼ï¼‰
        if len(daily_returns) > 1:
            import numpy as np
            volatility = float(np.std(daily_returns) * np.sqrt(252))  # å¹´åŒ–æ³¢å‹•ç‡
        else:
            volatility = 0

        # è¨ˆç®—å¤æ™®æ¯”ç‡
        # å…¬å¼ï¼š(å¹´åŒ–å ±é…¬ç‡ - ç„¡é¢¨éšªåˆ©ç‡) / å¹´åŒ–æ³¢å‹•ç‡
        risk_free_rate = 0.02  # å‡è¨­ç„¡é¢¨éšªåˆ©ç‡ 2%
        if volatility != 0:
            sharpe_ratio = (annual_return - risk_free_rate) / volatility
        else:
            sharpe_ratio = 0

        # è¨ˆç®—æœ€å¤§å›æ’¤
        peak = equities[0]
        max_drawdown = 0
        for equity in equities:
            if equity > peak:
                peak = equity
            drawdown = (peak - equity) / peak
            if drawdown > max_drawdown:
                max_drawdown = drawdown

        # è¨ˆç®—å‹ç‡
        winning_trades = [t for t in trades if t.get('pnl', 0) > 0]
        win_rate = len(winning_trades) / len(trades) if trades else 0

        # è¨ˆç®—å¹³å‡ç²åˆ©/è™§æ
        profits = [t['pnl'] for t in trades if t.get('pnl', 0) > 0]
        losses = [t['pnl'] for t in trades if t.get('pnl', 0) < 0]

        avg_profit = sum(profits) / len(profits) if profits else 0
        avg_loss = sum(losses) / len(losses) if losses else 0

        return {
            'total_return': float(total_return),
            'annual_return': float(annual_return),
            'final_equity': float(final_equity),
            'max_drawdown': float(max_drawdown),
            'volatility': float(volatility),
            'sharpe_ratio': float(sharpe_ratio),
            'win_rate': float(win_rate),
            'total_trades': len(trades),
            'winning_trades': len(winning_trades),
            'losing_trades': len(losses),  # ä¿®å¾©ï¼šä½¿ç”¨å¯¦éš›è™§æäº¤æ˜“æ•¸
            'avg_profit': float(avg_profit),
            'avg_loss': float(avg_loss),
            'profit_factor': abs(avg_profit / avg_loss) if avg_loss != 0 else 0
        }

    def convert_to_standard_result(
        self,
        qlib_result: dict
    ) -> dict:
        """
        å°‡ Qlib çµæœè½‰æ›ç‚ºæ¨™æº–æ ¼å¼ï¼ˆèˆ‡ Backtrader å…¼å®¹ï¼‰

        Args:
            qlib_result: Qlib å›æ¸¬çµæœ

        Returns:
            dict: æ¨™æº–æ ¼å¼çš„çµæœï¼ˆåŒ…å« metrics å’Œ tradesï¼‰
        """
        metrics = qlib_result.get('metrics', {})

        return {
            'metrics': {
                'final_value': metrics.get('final_equity', 0),
                'total_return': metrics.get('total_return', 0),
                'annual_return': metrics.get('annual_return', 0),  # æ–°å¢ï¼šå¹´åŒ–å ±é…¬ç‡
                'max_drawdown_pct': metrics.get('max_drawdown', 0),  # ç™¾åˆ†æ¯”æ ¼å¼
                'volatility': metrics.get('volatility', 0),  # æ–°å¢ï¼šæ³¢å‹•ç‡
                'sharpe_ratio': metrics.get('sharpe_ratio', 0),
                'win_rate': metrics.get('win_rate', 0),
                'total_trades': metrics.get('total_trades', 0),
                'winning_trades': metrics.get('winning_trades', 0),
                'losing_trades': metrics.get('losing_trades', 0),
                'avg_win': metrics.get('avg_profit', 0),  # ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„éµå
                'avg_loss': metrics.get('avg_loss', 0),
                'profit_factor': metrics.get('profit_factor', 0),
            },
            'trades': qlib_result.get('trades', []),
            'engine': 'qlib',
            'strategy_type': qlib_result.get('strategy_type', 'unknown')
        }
