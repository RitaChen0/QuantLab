from typing import List, Optional, Dict
import pandas as pd
from sqlalchemy.orm import Session
from app.repositories.fundamental_data import FundamentalDataRepository
from app.services.finlab_client import FinLabClient
from app.schemas.fundamental import FundamentalDataPoint
from loguru import logger


class FundamentalService:
    """
    è²¡å‹™æŒ‡æ¨™æœå‹™å±¤

    å¯¦ç¾é›™å±¤ç·©å­˜ç­–ç•¥:
    1. PostgreSQL (L2 ç·©å­˜) - æ°¸ä¹…å­˜å„²
    2. FinLab API - æ•¸æ“šæº

    æ³¨æ„: Redis (L1 ç·©å­˜) åœ¨ API å±¤è™•ç†
    """

    def __init__(self, db: Session):
        self.db = db
        self.repo = FundamentalDataRepository(db)
        self.finlab_client = FinLabClient()

    def get_indicator_data(
        self,
        stock_id: str,
        indicator: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        force_refresh: bool = False
    ) -> List[FundamentalDataPoint]:
        """
        ç²å–è²¡å‹™æŒ‡æ¨™æ•¸æ“šï¼ˆé›™å±¤ç·©å­˜ï¼‰

        æµç¨‹:
        1. æŸ¥è©¢ PostgreSQL (å¦‚æœ force_refresh=False)
        2. å¦‚æœ DB ç„¡æ•¸æ“šï¼Œå¾ FinLab API ç²å–
        3. å­˜å…¥ PostgreSQL ä¾›å¾ŒçºŒä½¿ç”¨

        Args:
            stock_id: è‚¡ç¥¨ä»£è™Ÿ
            indicator: æŒ‡æ¨™åç¨±
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            force_refresh: æ˜¯å¦å¼·åˆ¶å¾ API é‡æ–°ç²å–

        Returns:
            List of FundamentalDataPoint
        """
        # Step 1: Try PostgreSQL first (if not forcing refresh)
        if not force_refresh:
            db_data = self.repo.get_by_stock_indicator(
                stock_id=stock_id,
                indicator=indicator,
                start_date=start_date,
                end_date=end_date
            )

            if db_data:
                logger.info(f"âœ… L2 Cache HIT: {stock_id} - {indicator} ({len(db_data)} points from DB)")
                return [
                    FundamentalDataPoint(
                        date=str(d.date),
                        value=float(d.value) if d.value is not None else None
                    )
                    for d in db_data
                ]
            else:
                logger.info(f"âŒ L2 Cache MISS: {stock_id} - {indicator}")

        # Step 2: Fetch from FinLab API
        logger.info(f"ğŸ“¡ Fetching from FinLab API: {stock_id} - {indicator}")
        data_df = self.finlab_client.get_fundamental_indicator(
            indicator=indicator,
            stock_id=stock_id,
            start_date=start_date,
            end_date=end_date,
        )

        # Step 3: Store in PostgreSQL for future use
        data_points = []
        for date, value in data_df[stock_id].items():
            data_points.append({
                'stock_id': stock_id,
                'indicator': indicator,
                'date': str(date),
                'value': float(value) if pd.notna(value) else None
            })

        if data_points:
            self.repo.bulk_upsert(data_points)
            logger.info(f"ğŸ’¾ Stored {len(data_points)} points in DB: {stock_id} - {indicator}")

        # Return formatted response
        return [
            FundamentalDataPoint(
                date=point['date'],
                value=point['value']
            )
            for point in data_points
        ]

    def get_indicators_batch(
        self,
        stock_id: str,
        indicators: List[str],
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        force_refresh: bool = False
    ) -> Dict[str, List[FundamentalDataPoint]]:
        """
        æ‰¹é‡ç²å–å¤šå€‹è²¡å‹™æŒ‡æ¨™æ•¸æ“š

        Args:
            stock_id: è‚¡ç¥¨ä»£è™Ÿ
            indicators: æŒ‡æ¨™åç¨±åˆ—è¡¨
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            force_refresh: æ˜¯å¦å¼·åˆ¶åˆ·æ–°

        Returns:
            Dict mapping indicator names to data points
        """
        result = {}

        for indicator in indicators:
            try:
                data = self.get_indicator_data(
                    stock_id=stock_id,
                    indicator=indicator,
                    start_date=start_date,
                    end_date=end_date,
                    force_refresh=force_refresh
                )
                result[indicator] = data
            except Exception as e:
                logger.warning(f"Failed to get {indicator} for {stock_id}: {str(e)}")
                result[indicator] = []  # Return empty list on error

        return result

    def sync_indicator_data(
        self,
        stock_id: str,
        indicator: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> int:
        """
        åŒæ­¥è²¡å‹™æŒ‡æ¨™æ•¸æ“šåˆ°æ•¸æ“šåº«

        ç”¨æ–¼ Celery å®šæ™‚ä»»å‹™

        Returns:
            Number of data points synced
        """
        logger.info(f"Syncing {stock_id} - {indicator}")

        try:
            # Force refresh from API
            data_points = self.get_indicator_data(
                stock_id=stock_id,
                indicator=indicator,
                start_date=start_date,
                end_date=end_date,
                force_refresh=True  # Always fetch from API for sync
            )

            logger.info(f"âœ… Synced {len(data_points)} points for {stock_id} - {indicator}")
            return len(data_points)

        except ValueError as e:
            # Handle missing data gracefully (stock not found, no data available, etc.)
            error_msg = str(e).lower()
            if "not found" in error_msg or "no data" in error_msg:
                logger.warning(f"âš ï¸  Skipping {stock_id} - {indicator}: {str(e)}")
                return 0  # Return 0 to indicate no data synced, but don't fail
            else:
                # Re-raise other ValueError types
                logger.error(f"âŒ Failed to sync {stock_id} - {indicator}: {str(e)}")
                raise
        except Exception as e:
            logger.error(f"âŒ Failed to sync {stock_id} - {indicator}: {str(e)}")
            raise

    def get_coverage_stats(self) -> Dict[str, any]:
        """
        ç²å–æ•¸æ“šåº«ä¸­è²¡å‹™æ•¸æ“šçš„è¦†è“‹çµ±è¨ˆ

        Returns:
            Dict with statistics about stored data
        """
        stats = {
            'total_stocks': len(self.repo.get_distinct_stock_ids()),
            'total_indicators': len(self.repo.get_distinct_indicators()),
            'indicators_by_stock': {}
        }

        for stock_id in self.repo.get_distinct_stock_ids()[:10]:  # Sample first 10
            indicators = self.repo.get_distinct_indicators(stock_id=stock_id)
            stats['indicators_by_stock'][stock_id] = len(indicators)

        return stats
