"""RD-Agent Service Layer"""

from typing import List, Dict, Any, Optional, Tuple
from sqlalchemy.orm import Session
from datetime import datetime, timezone
from loguru import logger
import os
import pickle
import re
from pathlib import Path

from app.models.rdagent import RDAgentTask, GeneratedFactor, GeneratedModel, FactorEvaluation, TaskStatus, TaskType
from app.schemas.rdagent import FactorMiningRequest, ModelGenerationRequest, StrategyOptimizationRequest
from app.utils.model_code_generator import ModelCodeGenerator
from app.repositories.rdagent_task import RDAgentTaskRepository
from app.repositories.generated_factor import GeneratedFactorRepository
from app.repositories.generated_model import GeneratedModelRepository


class RDAgentService:
    """RD-Agent æœå‹™é¡"""

    def __init__(self, db: Session):
        self.db = db

    def create_factor_mining_task(
        self, user_id: int, request: FactorMiningRequest
    ) -> RDAgentTask:
        """å»ºç«‹å› å­æŒ–æ˜ä»»å‹™"""
        task = RDAgentTask(
            user_id=user_id,
            task_type=TaskType.FACTOR_MINING,
            status=TaskStatus.PENDING,
            input_params={
                "research_goal": request.research_goal,
                "stock_pool": request.stock_pool,
                "max_factors": request.max_factors,
                "llm_model": request.llm_model,
                "max_iterations": request.max_iterations,
            }
        )
        self.db.add(task)
        self.db.commit()
        self.db.refresh(task)

        logger.info(f"Created factor mining task {task.id} for user {user_id}")
        return task

    def create_strategy_optimization_task(
        self, user_id: int, request: StrategyOptimizationRequest
    ) -> RDAgentTask:
        """å»ºç«‹ç­–ç•¥å„ªåŒ–ä»»å‹™"""
        task = RDAgentTask(
            user_id=user_id,
            task_type=TaskType.STRATEGY_OPTIMIZATION,
            status=TaskStatus.PENDING,
            input_params={
                "strategy_id": request.strategy_id,
                "optimization_goal": request.optimization_goal,
                "llm_model": request.llm_model,
                "max_iterations": request.max_iterations,
            }
        )
        self.db.add(task)
        self.db.commit()
        self.db.refresh(task)

        logger.info(f"Created strategy optimization task {task.id} for user {user_id}")
        return task

    def get_task(self, task_id: int, user_id: int) -> Optional[RDAgentTask]:
        """ç²å–ä»»å‹™"""
        return RDAgentTaskRepository.get_by_id_and_user(self.db, task_id, user_id)

    def get_user_tasks(
        self, user_id: int, task_type: Optional[TaskType] = None, limit: int = 50
    ) -> List[RDAgentTask]:
        """ç²å–ä½¿ç”¨è€…ä»»å‹™åˆ—è¡¨"""
        return RDAgentTaskRepository.get_by_user(
            self.db,
            user_id,
            task_type=task_type,
            skip=0,
            limit=limit
        )

    def delete_task(self, task_id: int, user_id: int) -> bool:
        """åˆªé™¤ä»»å‹™

        Args:
            task_id: ä»»å‹™ ID
            user_id: ä½¿ç”¨è€… IDï¼ˆç”¨æ–¼æ¬Šé™æª¢æŸ¥ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆªé™¤

        Raises:
            ValueError: ä»»å‹™ä¸å­˜åœ¨æˆ–ç„¡æ¬Šé™åˆªé™¤
        """
        task = RDAgentTaskRepository.get_by_id_and_user(self.db, task_id, user_id)

        if not task:
            raise ValueError(f"Task {task_id} not found or access denied")

        # åˆªé™¤ç›¸é—œçš„ç”Ÿæˆå› å­
        GeneratedFactorRepository.delete_by_task(self.db, task_id)

        # åˆªé™¤ä»»å‹™
        RDAgentTaskRepository.delete(self.db, task)

        logger.info(f"Deleted task {task_id} for user {user_id}")
        return True

    def get_generated_factors(
        self, user_id: int, limit: int = 100
    ) -> List[GeneratedFactor]:
        """ç²å–ç”Ÿæˆçš„å› å­åˆ—è¡¨ï¼ˆåŒ…å«ç”¨æˆ¶è‡ªå·±çš„å› å­ + å…¬å…±å› å­ï¼‰"""
        return GeneratedFactorRepository.get_by_user_including_public(
            self.db,
            user_id,
            skip=0,
            limit=limit
        )

    def update_factor(
        self, factor_id: int, user_id: int, name: Optional[str] = None, description: Optional[str] = None
    ) -> Optional[GeneratedFactor]:
        """æ›´æ–°ç”Ÿæˆçš„å› å­

        Args:
            factor_id: å› å­ ID
            user_id: ä½¿ç”¨è€… IDï¼ˆç”¨æ–¼æ¬Šé™æª¢æŸ¥ï¼‰
            name: æ–°çš„å› å­åç¨±
            description: æ–°çš„å› å­æè¿°

        Returns:
            GeneratedFactor: æ›´æ–°å¾Œçš„å› å­ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–ç„¡æ¬Šé™å‰‡è¿”å› None
        """
        factor = GeneratedFactorRepository.get_by_id_and_user(self.db, factor_id, user_id)

        if not factor:
            return None

        # æ›´æ–°æ¬„ä½
        if name is not None:
            factor.name = name
        if description is not None:
            factor.description = description

        factor = GeneratedFactorRepository.update(self.db, factor)
        logger.info(f"Updated factor {factor_id}: name={name}, description={description}")
        return factor

    def save_generated_factor(
        self,
        task_id: int,
        user_id: int,
        name: str,
        formula: str,
        description: Optional[str] = None,
        category: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> GeneratedFactor:
        """ä¿å­˜ç”Ÿæˆçš„å› å­"""
        factor = GeneratedFactor(
            task_id=task_id,
            user_id=user_id,
            name=name,
            formula=formula,
            description=description,
            category=category,
            metadata=metadata
        )
        self.db.add(factor)
        self.db.commit()
        self.db.refresh(factor)

        logger.info(f"Saved generated factor {factor.id}: {name}")
        return factor

    def update_task_status(
        self,
        task_id: int,
        status: TaskStatus,
        result: Optional[Dict[str, Any]] = None,
        error_message: Optional[str] = None,
        llm_calls: Optional[int] = None,
        llm_cost: Optional[float] = None
    ):
        """æ›´æ–°ä»»å‹™ç‹€æ…‹"""
        task = RDAgentTaskRepository.get_by_id(self.db, task_id)
        if not task:
            raise ValueError(f"Task {task_id} not found")

        task.status = status

        if status == TaskStatus.RUNNING and not task.started_at:
            task.started_at = datetime.now(timezone.utc)

        if status in [TaskStatus.COMPLETED, TaskStatus.FAILED]:
            task.completed_at = datetime.now(timezone.utc)

        if result:
            task.result = result

        if error_message:
            task.error_message = error_message

        if llm_calls is not None:
            task.llm_calls = llm_calls

        if llm_cost is not None:
            task.llm_cost = llm_cost

        RDAgentTaskRepository.update(self.db, task)
        logger.info(f"Updated task {task_id} status to {status}")

    def execute_factor_mining(
        self,
        task_id: int,
        research_goal: str,
        max_iterations: int = 3,
        llm_model: str = "gpt-4-turbo",
    ) -> str:
        """åŸ·è¡Œ RD-Agent å› å­æŒ–æ˜

        Args:
            task_id: ä»»å‹™ ID
            research_goal: ç ”ç©¶ç›®æ¨™
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•¸
            llm_model: LLM æ¨¡å‹åç¨±

        Returns:
            log_dir: æ—¥èªŒç›®éŒ„è·¯å¾‘

        Raises:
            Exception: åŸ·è¡Œå¤±æ•—æ™‚æ‹‹å‡ºç•°å¸¸
        """
        logger.info(f"Starting factor mining for task {task_id}")
        logger.info(f"Research goal: {research_goal}")
        logger.info(f"Max iterations: {max_iterations}")
        logger.info(f"LLM model: {llm_model}")

        # è¨­å®šç’°å¢ƒè®Šæ•¸
        os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY", "")
        os.environ["QLIB_DATA_PATH"] = os.getenv("QLIB_DATA_PATH", "/data/qlib/tw_stock_v2")

        if not os.environ["OPENAI_API_KEY"]:
            raise ValueError("OPENAI_API_KEY not configured")

        try:
            # å°å…¥ RD-Agent
            from rdagent.app.qlib_rd_loop.factor import main

            # åŸ·è¡Œå› å­æŒ–æ˜
            logger.info(f"Executing RD-Agent with {max_iterations} iterations...")
            main(step_n=max_iterations)

            # æŸ¥æ‰¾æœ€æ–°çš„æ—¥èªŒç›®éŒ„
            log_base_dir = Path("/app/log")
            if not log_base_dir.exists():
                raise FileNotFoundError("Log directory /app/log not found")

            # ç²å–æœ€æ–°çš„æ™‚é–“æˆ³ç›®éŒ„
            log_dirs = sorted(log_base_dir.glob("*"), key=lambda p: p.stat().st_mtime, reverse=True)
            if not log_dirs:
                raise FileNotFoundError("No log directories found")

            log_dir = str(log_dirs[0])
            logger.info(f"RD-Agent execution completed. Log directory: {log_dir}")

            return log_dir

        except Exception as e:
            import traceback
            error_trace = traceback.format_exc()
            logger.error(f"Factor mining execution failed: {str(e)}")
            logger.error(f"Full traceback:\n{error_trace}")
            raise

    def parse_rdagent_results(self, log_dir: str) -> List[Dict[str, Any]]:
        """è§£æ RD-Agent åŸ·è¡Œçµæœ

        å¾ .pkl æ—¥èªŒæª”æ¡ˆä¸­æå–ç”Ÿæˆçš„å› å­å®šç¾©

        Args:
            log_dir: RD-Agent æ—¥èªŒç›®éŒ„è·¯å¾‘

        Returns:
            factors: å› å­åˆ—è¡¨ï¼Œæ¯å€‹å› å­åŒ…å« name, formula, description, variables, category
        """
        logger.info(f"Parsing RD-Agent results from {log_dir}")

        log_path = Path(log_dir)
        if not log_path.exists():
            raise FileNotFoundError(f"Log directory not found: {log_dir}")

        factors = []

        # éæ­·æ‰€æœ‰è¿­ä»£ç›®éŒ„ (Loop_0, Loop_1, ...)
        for loop_dir in sorted(log_path.glob("Loop_*")):
            loop_num = int(loop_dir.name.split("_")[1])
            logger.info(f"Processing {loop_dir.name}...")

            # æŸ¥æ‰¾ experiment generation çµæœ pickle æª”æ¡ˆ
            exp_gen_pattern = loop_dir / "direct_exp_gen" / "r" / "experiment generation" / "**" / "*.pkl"
            exp_pkl_files = sorted(log_path.glob(str(exp_gen_pattern.relative_to(log_path))))

            if not exp_pkl_files:
                logger.warning(f"No experiment pickle files found in {loop_dir}")
                continue

            # è®€å–æ‰€æœ‰å¯¦é©— pickle æª”æ¡ˆ
            for exp_file in exp_pkl_files:
                try:
                    with open(exp_file, "rb") as f:
                        experiment_data = pickle.load(f)

                    logger.info(f"Loaded experiment from {exp_file.name}")

                    # experiment_data æ‡‰è©²æ˜¯åŒ…å« FactorTask ç‰©ä»¶çš„åˆ—è¡¨
                    if isinstance(experiment_data, list):
                        for task in experiment_data:
                            factor = self._extract_factor_from_task(task, loop_num)
                            if factor:
                                factors.append(factor)
                                logger.info(f"Extracted factor: {factor['name']}")

                except Exception as e:
                    logger.error(f"Failed to load {exp_file}: {e}")

        logger.info(f"Parsed {len(factors)} factors from RD-Agent results")
        return factors

    def _extract_factor_from_task(self, task: Any, loop_num: int) -> Optional[Dict[str, Any]]:
        """å¾ FactorTask ç‰©ä»¶ä¸­æå–å› å­å®šç¾©

        Args:
            task: FactorTask ç‰©ä»¶
            loop_num: è¿­ä»£ç·¨è™Ÿ

        Returns:
            factor: å› å­å­—å…¸ï¼ŒåŒ…å« name, formula, description, variables
        """
        try:
            # æå–å› å­å±¬æ€§
            factor_name = getattr(task, 'factor_name', None) or str(task)
            factor_description = getattr(task, 'factor_description', '')
            factor_formulation = getattr(task, 'factor_formulation', '')
            variables = getattr(task, 'variables', {})

            # æ¸…ç†å› å­åç¨±ï¼ˆç§»é™¤ç‰¹æ®Šå­—å…ƒï¼‰
            if factor_name and '<' in factor_name:
                # è™•ç† <FactorTask[20DaySMA]> æ ¼å¼
                match = re.search(r'\[(.+?)\]', factor_name)
                if match:
                    factor_name = match.group(1)

            if not factor_name:
                logger.warning(f"No factor name found in task: {task}")
                return None

            factor = {
                "name": factor_name,
                "formula": factor_formulation or "N/A",
                "description": factor_description or f"Factor generated in Loop {loop_num}",
                "variables": variables if isinstance(variables, dict) else {},
                "category": "momentum",  # é è¨­åˆ†é¡
                "metadata": {
                    "loop_num": loop_num,
                    "task_type": type(task).__name__
                }
            }

            return factor

        except Exception as e:
            logger.error(f"Failed to extract factor from task: {e}")
            return None

    def _extract_factor_from_experiment(
        self,
        hypothesis_data: Any,
        experiment_data: Any,
        loop_num: int
    ) -> Optional[Dict[str, Any]]:
        """å¾å¯¦é©—æ•¸æ“šä¸­æå–å› å­å®šç¾©

        Args:
            hypothesis_data: å‡è¨­æ•¸æ“š (å¾ hypothesis.pkl)
            experiment_data: å¯¦é©—æ•¸æ“š (å¾ experiment.pkl)
            loop_num: è¿­ä»£ç·¨è™Ÿ

        Returns:
            factor: å› å­å­—å…¸ï¼ŒåŒ…å« name, formula, description, variables, category, metadata
        """
        try:
            # æå–å› å­åç¨±ï¼ˆå¾ hypothesis æˆ– experimentï¼‰
            factor_name = None
            if hasattr(hypothesis_data, "hypothesis") and hypothesis_data.hypothesis:
                # å¾å‡è¨­æ–‡æœ¬ä¸­æå–å› å­åç¨±
                match = re.search(r"Factor[:\s]+([A-Za-z0-9_]+)", str(hypothesis_data.hypothesis))
                if match:
                    factor_name = match.group(1)

            if not factor_name:
                factor_name = f"Factor_Loop{loop_num}"

            # æå–å› å­å…¬å¼ï¼ˆå¾å¯¦é©—ä»£ç¢¼ä¸­ï¼‰
            formula = None
            if hasattr(experiment_data, "code") and experiment_data.code:
                # æŸ¥æ‰¾ Qlib è¡¨é”å¼å®šç¾©
                code_str = str(experiment_data.code)
                # åŒ¹é…å¸¸è¦‹çš„å› å­å®šç¾©æ¨¡å¼
                patterns = [
                    r"'([^']+)':\s*'([^']+)'",  # 'factor_name': 'expression'
                    r"\"([^\"]+)\":\s*\"([^\"]+)\"",  # "factor_name": "expression"
                    r"(\w+)\s*=\s*\"([^\"]+)\"",  # factor_name = "expression"
                ]

                for pattern in patterns:
                    matches = re.findall(pattern, code_str)
                    if matches:
                        # å–ç¬¬ä¸€å€‹åŒ¹é…çš„è¡¨é”å¼
                        formula = matches[0][1] if len(matches[0]) > 1 else matches[0][0]
                        break

            if not formula:
                formula = f"Ref($close, 0)"  # é»˜èªå…¬å¼

            # æå–æè¿°
            description = None
            if hasattr(hypothesis_data, "hypothesis"):
                description = str(hypothesis_data.hypothesis)[:500]  # é™åˆ¶é•·åº¦

            # æå–è®Šæ•¸ï¼ˆå¾å…¬å¼ä¸­ï¼‰
            variables = self._extract_variables_from_formula(formula)

            # åˆ†é¡ï¼ˆåŸºæ–¼è®Šæ•¸æˆ–å…¬å¼é—œéµå­—ï¼‰
            category = self._categorize_factor(formula, variables)

            # æ§‹å»ºå› å­å­—å…¸
            factor = {
                "name": factor_name,
                "formula": formula,
                "description": description,
                "variables": variables,
                "category": category,
                "metadata": {
                    "loop": loop_num,
                    "hypothesis_type": type(hypothesis_data).__name__,
                    "experiment_type": type(experiment_data).__name__,
                }
            }

            return factor

        except Exception as e:
            logger.error(f"Failed to extract factor from experiment: {e}")
            return None

    def _extract_variables_from_formula(self, formula: str) -> List[str]:
        """å¾ Qlib è¡¨é”å¼ä¸­æå–è®Šæ•¸

        Args:
            formula: Qlib è¡¨é”å¼å…¬å¼

        Returns:
            variables: è®Šæ•¸åˆ—è¡¨ï¼ˆå¦‚ ['close', 'volume', 'open']ï¼‰
        """
        variables = set()

        # åŒ¹é… $variable æ ¼å¼
        dollar_vars = re.findall(r'\$(\w+)', formula)
        variables.update(dollar_vars)

        # åŒ¹é…å¸¸è¦‹çš„ OHLCV è®Šæ•¸
        common_vars = ['open', 'high', 'low', 'close', 'volume', 'vwap', 'factor']
        for var in common_vars:
            if var.lower() in formula.lower():
                variables.add(var.lower())

        return sorted(list(variables))

    def _categorize_factor(self, formula: str, variables: List[str]) -> str:
        """æ ¹æ“šå…¬å¼å’Œè®Šæ•¸å°å› å­åˆ†é¡

        Args:
            formula: Qlib è¡¨é”å¼å…¬å¼
            variables: è®Šæ•¸åˆ—è¡¨

        Returns:
            category: å› å­é¡åˆ¥ï¼ˆmomentum, value, quality, volatility, volume, technicalï¼‰
        """
        formula_lower = formula.lower()

        # å‹•é‡é¡
        if any(kw in formula_lower for kw in ['mean', 'ref', 'delta', 'rank']):
            return "momentum"

        # æ³¢å‹•ç‡é¡
        if any(kw in formula_lower for kw in ['std', 'var', 'volatility', 'atr']):
            return "volatility"

        # æˆäº¤é‡é¡
        if 'volume' in variables or 'vol' in formula_lower:
            return "volume"

        # æŠ€è¡“æŒ‡æ¨™é¡
        if any(kw in formula_lower for kw in ['ma', 'ema', 'rsi', 'macd', 'corr']):
            return "technical"

        # é»˜èªç‚ºåƒ¹å€¼é¡
        return "value"

    def calculate_llm_costs(self, log_dir: str) -> Tuple[int, float]:
        """è¨ˆç®— LLM API ä½¿ç”¨æˆæœ¬

        å¾ debug_llm.pkl ä¸­æå– API èª¿ç”¨çµ±è¨ˆï¼ŒåŸºæ–¼ GPT-4-turbo å®šåƒ¹è¨ˆç®—æˆæœ¬

        å®šåƒ¹åƒè€ƒ (2024-12)ï¼š
        - GPT-4-turbo: $0.01/1K input tokens, $0.03/1K output tokens

        Args:
            log_dir: RD-Agent æ—¥èªŒç›®éŒ„è·¯å¾‘

        Returns:
            (llm_calls, llm_cost): API èª¿ç”¨æ¬¡æ•¸å’Œä¼°è¨ˆæˆæœ¬ï¼ˆç¾å…ƒï¼‰
        """
        logger.info(f"Calculating LLM costs from {log_dir}")

        log_path = Path(log_dir)
        debug_llm_file = log_path / "debug_llm.pkl"

        llm_calls = 0
        total_input_tokens = 0
        total_output_tokens = 0

        if debug_llm_file.exists():
            try:
                with open(debug_llm_file, "rb") as f:
                    llm_debug_data = pickle.load(f)

                # æå–èª¿ç”¨è¨˜éŒ„
                if isinstance(llm_debug_data, list):
                    llm_calls = len(llm_debug_data)

                    for call in llm_debug_data:
                        if isinstance(call, dict):
                            # æå– token ä½¿ç”¨é‡
                            usage = call.get("usage", {})
                            total_input_tokens += usage.get("prompt_tokens", 0)
                            total_output_tokens += usage.get("completion_tokens", 0)

                logger.info(f"LLM API calls: {llm_calls}")
                logger.info(f"Total input tokens: {total_input_tokens}")
                logger.info(f"Total output tokens: {total_output_tokens}")

            except Exception as e:
                logger.error(f"Failed to parse debug_llm.pkl: {e}")
        else:
            logger.warning(f"debug_llm.pkl not found at {debug_llm_file}")
            # ä¼°ç®—ï¼šå‡è¨­æ¯æ¬¡è¿­ä»£èª¿ç”¨ 2 æ¬¡ LLM
            llm_calls = 2

        # è¨ˆç®—æˆæœ¬ï¼ˆGPT-4-turbo å®šåƒ¹ï¼‰
        input_cost = (total_input_tokens / 1000) * 0.01
        output_cost = (total_output_tokens / 1000) * 0.03
        llm_cost = input_cost + output_cost

        # å¦‚æœç„¡æ³•ç²å– token æ•¸æ“šï¼Œä½¿ç”¨ä¿å®ˆä¼°ç®—
        if total_input_tokens == 0 and total_output_tokens == 0:
            # å‡è¨­æ¯æ¬¡èª¿ç”¨å¹³å‡ä½¿ç”¨ 2000 tokens
            estimated_tokens = llm_calls * 2000
            llm_cost = (estimated_tokens / 1000) * 0.02  # å¹³å‡æˆæœ¬

        logger.info(f"Estimated LLM cost: ${llm_cost:.4f}")

        return llm_calls, round(llm_cost, 4)

    # ========== æ¨¡å‹ç”ŸæˆåŠŸèƒ½ ==========

    def create_model_generation_task(
        self, user_id: int, request: ModelGenerationRequest
    ) -> RDAgentTask:
        """å»ºç«‹æ¨¡å‹ç”Ÿæˆä»»å‹™"""
        task = RDAgentTask(
            user_id=user_id,
            task_type=TaskType.MODEL_GENERATION,
            status=TaskStatus.PENDING,
            input_params={
                "research_goal": request.research_goal,
                "model_type": request.model_type,
                "llm_model": request.llm_model,
                "max_iterations": request.max_iterations,
            }
        )
        self.db.add(task)
        self.db.commit()
        self.db.refresh(task)

        logger.info(f"Created model generation task {task.id} for user {user_id}")
        return task

    def execute_model_generation(
        self,
        task_id: int,
        research_goal: str,
        max_iterations: int = 5,
        llm_model: str = "gpt-4-turbo",
    ) -> str:
        """åŸ·è¡Œ RD-Agent æ¨¡å‹ç”Ÿæˆ

        Args:
            task_id: ä»»å‹™ ID
            research_goal: ç ”ç©¶ç›®æ¨™ï¼ˆç”¨æ–¼æ—¥èªŒï¼Œå¯¦éš› RD-Agent æœƒè‡ªå‹•æ±ºå®šï¼‰
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•¸
            llm_model: LLM æ¨¡å‹åç¨±

        Returns:
            log_dir: æ—¥èªŒç›®éŒ„è·¯å¾‘

        Raises:
            Exception: åŸ·è¡Œå¤±æ•—æ™‚æ‹‹å‡ºç•°å¸¸
        """
        logger.info(f"Starting model generation for task {task_id}")
        logger.info(f"Research goal: {research_goal}")
        logger.info(f"Max iterations: {max_iterations}")
        logger.info(f"LLM model: {llm_model}")

        # è¨­å®šç’°å¢ƒè®Šæ•¸
        os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY", "")
        os.environ["QLIB_DATA_PATH"] = os.getenv("QLIB_DATA_PATH", "/data/qlib/tw_stock_v2")

        if not os.environ["OPENAI_API_KEY"]:
            raise ValueError("OPENAI_API_KEY not configured")

        try:
            # å°å…¥ RD-Agent æ¨¡å‹ç”Ÿæˆæ¨¡çµ„
            from rdagent.app.qlib_rd_loop.model import main

            # åŸ·è¡Œæ¨¡å‹ç”Ÿæˆ
            logger.info(f"Executing RD-Agent model generation with {max_iterations} iterations...")
            main(step_n=max_iterations)

            # æŸ¥æ‰¾æœ€æ–°çš„æ—¥èªŒç›®éŒ„
            log_base_dir = Path("/app/log")
            if not log_base_dir.exists():
                raise FileNotFoundError("Log directory /app/log not found")

            # ç²å–æœ€æ–°çš„æ™‚é–“æˆ³ç›®éŒ„
            log_dirs = sorted(log_base_dir.glob("*"), key=lambda p: p.stat().st_mtime, reverse=True)
            if not log_dirs:
                raise FileNotFoundError("No log directories found")

            log_dir = str(log_dirs[0])
            logger.info(f"RD-Agent model generation completed. Log directory: {log_dir}")

            return log_dir

        except Exception as e:
            import traceback
            error_trace = traceback.format_exc()
            logger.error(f"Model generation execution failed: {str(e)}")
            logger.error(f"Full traceback:\n{error_trace}")
            raise

    def parse_model_generation_results(self, log_dir: str) -> List[Dict[str, Any]]:
        """è§£æ RD-Agent æ¨¡å‹ç”Ÿæˆçµæœ

        å¾ .pkl æ—¥èªŒæª”æ¡ˆä¸­æå–ç”Ÿæˆçš„æ¨¡å‹å®šç¾©

        Args:
            log_dir: RD-Agent æ—¥èªŒç›®éŒ„è·¯å¾‘

        Returns:
            models: æ¨¡å‹åˆ—è¡¨ï¼Œæ¯å€‹æ¨¡å‹åŒ…å« name, description, model_type, architecture, etc.
        """
        logger.info(f"Parsing RD-Agent model generation results from {log_dir}")

        log_path = Path(log_dir)
        if not log_path.exists():
            raise FileNotFoundError(f"Log directory not found: {log_dir}")

        models = []

        # éæ­·æ‰€æœ‰è¿­ä»£ç›®éŒ„ (Loop_0, Loop_1, ...)
        for loop_dir in sorted(log_path.glob("Loop_*")):
            loop_num = int(loop_dir.name.split("_")[1])
            logger.info(f"Processing {loop_dir.name}...")

            # æŸ¥æ‰¾ experiment generation çµæœ pickle æª”æ¡ˆ
            exp_gen_pattern = loop_dir / "direct_exp_gen" / "r" / "experiment generation" / "**" / "*.pkl"
            exp_pkl_files = sorted(log_path.glob(str(exp_gen_pattern.relative_to(log_path))))

            if not exp_pkl_files:
                logger.warning(f"No experiment pickle files found in {loop_dir}")
                continue

            # è®€å–æ‰€æœ‰å¯¦é©— pickle æª”æ¡ˆ
            for exp_file in exp_pkl_files:
                try:
                    with open(exp_file, "rb") as f:
                        experiment_data = pickle.load(f)

                    logger.info(f"Loaded experiment from {exp_file.name}")

                    # experiment_data æ‡‰è©²æ˜¯åŒ…å« ModelTask ç‰©ä»¶çš„åˆ—è¡¨
                    if isinstance(experiment_data, list):
                        for task in experiment_data:
                            model = self._extract_model_from_task(task, loop_num)
                            if model:
                                models.append(model)
                                logger.info(f"Extracted model: {model['name']}")

                except Exception as e:
                    logger.error(f"Failed to load {exp_file}: {e}")

        logger.info(f"Parsed {len(models)} models from RD-Agent results")
        return models

    def _extract_model_from_task(self, task: Any, loop_num: int) -> Optional[Dict[str, Any]]:
        """å¾ ModelTask ç‰©ä»¶ä¸­æå–æ¨¡å‹å®šç¾©ä¸¦ç”Ÿæˆä»£ç¢¼

        Args:
            task: ModelTask ç‰©ä»¶
            loop_num: è¿­ä»£ç·¨è™Ÿ

        Returns:
            model: æ¨¡å‹å­—å…¸ï¼ŒåŒ…å« name, description, architecture, code, qlib_config ç­‰
        """
        try:
            # æå–æ¨¡å‹å±¬æ€§
            model_name = getattr(task, 'name', None) or getattr(task, 'model_name', None) or f"Model_Loop{loop_num}"
            model_description = getattr(task, 'description', '') or getattr(task, 'model_description', '')
            model_type = getattr(task, 'model_type', 'TimeSeries')  # é»˜èªç‚ºæ™‚é–“åºåˆ—
            formulation = getattr(task, 'formulation', '') or getattr(task, 'model_formulation', '')
            architecture = getattr(task, 'architecture', '') or getattr(task, 'model_architecture', '')
            variables = getattr(task, 'variables', {})
            hyperparameters = getattr(task, 'hyperparameters', {})

            # æ¸…ç†æ¨¡å‹åç¨±ï¼ˆç§»é™¤ç‰¹æ®Šå­—å…ƒï¼‰
            if model_name and '<' in model_name:
                # è™•ç† <ModelTask[GRUFinancialModel]> æ ¼å¼
                match = re.search(r'\[(.+?)\]', model_name)
                if match:
                    model_name = match.group(1)

            # ========== æ–°å¢ï¼šç”Ÿæˆ PyTorch ä»£ç¢¼å’Œ Qlib é…ç½® ==========
            code = None
            qlib_config = None

            if architecture:  # åªæœ‰ç•¶æœ‰æ¶æ§‹æè¿°æ™‚æ‰ç”Ÿæˆä»£ç¢¼
                try:
                    logger.info(f"Generating PyTorch code for {model_name}...")
                    code, qlib_config = ModelCodeGenerator.generate_pytorch_code(
                        model_name=model_name,
                        model_type=model_type,
                        architecture=architecture,
                        hyperparameters=hyperparameters,
                        formulation=formulation
                    )
                    logger.info(f"âœ… Successfully generated code for {model_name}")
                    logger.info(f"   Code length: {len(code)} characters")
                    logger.info(f"   Qlib config keys: {list(qlib_config.keys())}")
                except Exception as e:
                    logger.error(f"âŒ Failed to generate code for {model_name}: {e}")
                    logger.warning(f"   Model will be saved without code")
            else:
                logger.warning(f"No architecture description for {model_name}, skipping code generation")

            model = {
                "name": model_name,
                "description": model_description or f"Model generated in Loop {loop_num}",
                "model_type": model_type,
                "formulation": formulation,
                "architecture": architecture,
                "variables": variables if isinstance(variables, dict) else {},
                "hyperparameters": hyperparameters if isinstance(hyperparameters, dict) else {},
                "code": code,  # æ–°å¢ï¼šç”Ÿæˆçš„ä»£ç¢¼
                "qlib_config": qlib_config,  # æ–°å¢ï¼šQlib é…ç½®
                "iteration": loop_num,
                "metadata": {
                    "loop_num": loop_num,
                    "task_type": type(task).__name__,
                    "code_generated": code is not None,  # æ¨™è¨˜æ˜¯å¦ç”Ÿæˆäº†ä»£ç¢¼
                }
            }

            return model

        except Exception as e:
            logger.error(f"Failed to extract model from task: {e}")
            return None

    def save_generated_model(
        self,
        task_id: int,
        user_id: int,
        name: str,
        model_type: str,
        description: Optional[str] = None,
        formulation: Optional[str] = None,
        architecture: Optional[str] = None,
        variables: Optional[Dict[str, Any]] = None,
        hyperparameters: Optional[Dict[str, Any]] = None,
        code: Optional[str] = None,  # æ–°å¢ï¼šæ¨¡å‹ä»£ç¢¼
        qlib_config: Optional[Dict[str, Any]] = None,  # æ–°å¢ï¼šQlib é…ç½®
        iteration: Optional[int] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> GeneratedModel:
        """ä¿å­˜ç”Ÿæˆçš„æ¨¡å‹"""
        model = GeneratedModel(
            task_id=task_id,
            user_id=user_id,
            name=name,
            model_type=model_type,
            description=description,
            formulation=formulation,
            architecture=architecture,
            variables=variables,
            hyperparameters=hyperparameters,
            code=code,  # æ–°å¢ï¼šä¿å­˜ä»£ç¢¼
            qlib_config=qlib_config,  # æ–°å¢ï¼šä¿å­˜ Qlib é…ç½®
            iteration=iteration,
            model_metadata=metadata
        )
        self.db.add(model)
        self.db.commit()
        self.db.refresh(model)

        logger.info(f"Saved generated model {model.id}: {name}")
        if code:
            logger.info(f"  âœ… Model includes generated code ({len(code)} characters)")
        if qlib_config:
            logger.info(f"  âœ… Model includes Qlib config")
        return model

    def get_generated_models(
        self, user_id: int, limit: int = 100
    ) -> List[GeneratedModel]:
        """ç²å–ç”Ÿæˆçš„æ¨¡å‹åˆ—è¡¨"""
        return GeneratedModelRepository.get_by_user(
            self.db,
            user_id,
            skip=0,
            limit=limit
        )

    def get_generated_model(
        self, model_id: int, user_id: int
    ) -> Optional[GeneratedModel]:
        """ç²å–å–®ä¸€æ¨¡å‹è©³æƒ…

        Args:
            model_id: æ¨¡å‹ ID
            user_id: ç”¨æˆ¶ IDï¼ˆç”¨æ–¼æ¬Šé™æª¢æŸ¥ï¼‰

        Returns:
            æ¨¡å‹å°è±¡ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–ç„¡æ¬Šé™å‰‡è¿”å› None
        """
        return GeneratedModelRepository.get_by_id_and_user(
            self.db, model_id, user_id
        )

    async def export_model_as_qlib_strategy(
        self,
        db: Session,
        user_id: int,
        model_id: int,
        model,
        training_job,
        strategy_name: str,
        buy_threshold: float,
        sell_threshold: float,
        description: Optional[str] = None
    ) -> int:
        """
        å°‡è¨“ç·´å¥½çš„æ¨¡å‹å°å‡ºç‚º Qlib ç­–ç•¥

        Args:
            db: è³‡æ–™åº« session
            user_id: ç”¨æˆ¶ ID
            model_id: æ¨¡å‹ ID
            model: GeneratedModel å°è±¡
            training_job: ModelTrainingJob å°è±¡
            strategy_name: ç­–ç•¥åç¨±
            buy_threshold: è²·å…¥é–¾å€¼
            sell_threshold: è³£å‡ºé–¾å€¼
            description: ç­–ç•¥æè¿°

        Returns:
            å‰µå»ºçš„ç­–ç•¥ ID
        """
        from app.repositories.strategy import StrategyRepository
        from app.schemas.strategy import StrategyCreate
        from app.models.strategy import StrategyStatus

        # ç”Ÿæˆ Qlib ç­–ç•¥ä»£ç¢¼
        strategy_code = self._generate_qlib_strategy_template(
            model_id=model_id,
            model_name=model.name,
            model_weight_path=training_job.model_weight_path,
            buy_threshold=buy_threshold,
            sell_threshold=sell_threshold,
        )

        # æº–å‚™ç­–ç•¥åƒæ•¸
        strategy_params = {
            "model_id": model_id,
            "model_name": model.name,
            "model_weight_path": training_job.model_weight_path,
            "buy_threshold": buy_threshold,
            "sell_threshold": sell_threshold,
            "test_ic": training_job.test_ic,
            "input_dim": 179,  # Alpha158+
        }

        # æº–å‚™ç­–ç•¥æè¿°
        if not description:
            # æ ¼å¼åŒ–æ¸¬è©¦ ICï¼ˆé¿å… f-string æ ¼å¼åŒ–éŒ¯èª¤ï¼‰
            test_ic_str = f"{training_job.test_ic:.4f}" if training_job.test_ic is not None else "N/A"

            description = f"""
åŸºæ–¼ RD-Agent è¨“ç·´çš„ AI æ¨¡å‹ç­–ç•¥

**æ¨¡å‹è³‡è¨Š**:
- æ¨¡å‹ ID: {model_id}
- æ¨¡å‹åç¨±: {model.name}
- æ¸¬è©¦é›† IC: {test_ic_str}

**äº¤æ˜“é‚è¼¯**:
- è²·å…¥é–¾å€¼: {buy_threshold} (é æ¸¬æ”¶ç›Šç‡ > {buy_threshold} æ™‚è²·å…¥)
- è³£å‡ºé–¾å€¼: {sell_threshold} (é æ¸¬æ”¶ç›Šç‡ < {sell_threshold} æ™‚è³£å‡º)

**ç‰¹å¾µå·¥ç¨‹**:
- ä½¿ç”¨ Alpha158+ å› å­é›†ï¼ˆ179 å€‹æŠ€è¡“å› å­ï¼‰
- è‡ªå‹•è™•ç†å› å­è¨ˆç®—å’Œæ•¸æ“šå°é½Š

**æ³¨æ„äº‹é …**:
- æ­¤ç­–ç•¥ä½¿ç”¨ Qlib å¼•æ“é‹è¡Œ
- ç¢ºä¿ Qlib æ•¸æ“šå·²åŒæ­¥
- å›æ¸¬æ™‚å»ºè­°ä½¿ç”¨è‡³å°‘ 1 å¹´çš„æ­·å²æ•¸æ“š
            """.strip()

        # å‰µå»ºç­–ç•¥
        strategy_create = StrategyCreate(
            name=strategy_name,
            description=description,
            code=strategy_code,
            parameters=strategy_params,
            engine_type="qlib",
            status=StrategyStatus.ACTIVE
        )

        strategy = StrategyRepository.create(db, user_id, strategy_create)
        logger.info(f"Created Qlib strategy {strategy.id} from model {model_id}")

        return strategy.id

    def _generate_qlib_strategy_template(
        self,
        model_id: int,
        model_name: str,
        model_weight_path: str,
        buy_threshold: float,
        sell_threshold: float,
    ) -> str:
        """
        ç”Ÿæˆ Qlib ç­–ç•¥æ¨¡æ¿ä»£ç¢¼

        Args:
            model_id: æ¨¡å‹ ID
            model_name: æ¨¡å‹åç¨±
            model_weight_path: æ¨¡å‹æ¬Šé‡è·¯å¾‘
            buy_threshold: è²·å…¥é–¾å€¼
            sell_threshold: è³£å‡ºé–¾å€¼

        Returns:
            ç­–ç•¥ Python ä»£ç¢¼
        """
        template = f'''"""
AI Model Strategy: {model_name}
Model ID: {model_id}
Auto-generated from RD-Agent trained model

æ­¤ç­–ç•¥ç›´æ¥æ“ä½œ signals è®Šé‡ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ

æ³¨æ„ï¼šä»¥ä¸‹æ¨¡çµ„å·²ç”±åŸ·è¡Œç’°å¢ƒæä¾›ï¼Œç„¡éœ€å°å…¥ï¼š
- np, pd, torch: æ•¸æ“šè™•ç†å’Œæ·±åº¦å­¸ç¿’
- alpha158_calculator: Alpha158+ å› å­è¨ˆç®—
- SimpleMLP: æ¨¡å‹é¡åˆ¥
- logger: æ—¥èªŒè¨˜éŒ„
- D: Qlib æ•¸æ“š API
"""

# ===== æ¨¡å‹é…ç½® =====
MODEL_WEIGHT_PATH = "{model_weight_path}"
BUY_THRESHOLD = {buy_threshold}
SELL_THRESHOLD = {sell_threshold}
INPUT_DIM = 179

# ===== åŠ è¼‰æ¨¡å‹ =====
try:
    model = SimpleMLP(input_dim=INPUT_DIM, hidden_dims=[128, 64])
    model.load_state_dict(torch.load(MODEL_WEIGHT_PATH, map_location='cpu'))
    model.eval()
    logger.info(f"âœ… Loaded AI model from {{MODEL_WEIGHT_PATH}}")
except Exception as e:
    logger.error(f"âŒ Failed to load model: {{e}}")
    raise

# ===== è¨ˆç®— Alpha158+ å› å­ =====
try:
    # df æ˜¯ç”±ç³»çµ±æä¾›çš„æ•¸æ“šï¼ˆå¯èƒ½æ˜¯æŠ€è¡“æŒ‡æ¨™ï¼Œä¸æ˜¯åŸå§‹ OHLCVï¼‰
    # æˆ‘å€‘éœ€è¦å¾ Qlib ç²å–åŸå§‹ OHLCV æ•¸æ“šä¾†è¨ˆç®— Alpha158+
    if df is None or df.empty:
        logger.warning("No data available")
    else:
        # D å°è±¡å·²ç”±åŸ·è¡Œç’°å¢ƒæä¾›ï¼Œç„¡éœ€å°å…¥

        # ç²å–è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¾ params æˆ–æ¨æ–·ï¼‰
        symbol = params.get('symbol', '2330')  # é»˜èªå°ç©é›»

        # ç²å–åŸå§‹ OHLCV æ•¸æ“šï¼ˆèˆ‡ df ç›¸åŒçš„æ—¥æœŸç¯„åœï¼‰
        # ä½¿ç”¨ .date().isoformat() ä»£æ›¿ strftimeï¼ˆé¿å… __import__ éŒ¯èª¤ï¼‰
        start_date = str(df.index[0].date())
        end_date = str(df.index[-1].date())

        logger.info(f"ğŸ“Š Fetching OHLCV data for {{symbol}} from {{start_date}} to {{end_date}}")

        # ç²å–åŸå§‹æ•¸æ“š
        raw_fields = ['$open', '$high', '$low', '$close', '$volume']
        df_raw = D.features(
            instruments=[symbol],
            fields=raw_fields,
            start_time=start_date,
            end_time=end_date,
            freq='day'
        )

        if df_raw is None or df_raw.empty:
            logger.error("Failed to fetch OHLCV data from Qlib")
            df_factors = None
        else:
            # æå–å–®ä¸€è‚¡ç¥¨æ•¸æ“šï¼ˆQlib è¿”å› MultiIndexï¼šdatetime, instrumentï¼‰
            if isinstance(df_raw.index, pd.MultiIndex):
                # ä½¿ç”¨ droplevel è€Œä¸æ˜¯ xsï¼Œé¿å…è‚¡ç¥¨ä»£ç¢¼è¢«èª¤è§£æç‚ºæ—¥æœŸ
                df_raw = df_raw.droplevel(level=1)

            # è¨ˆç®— Alpha158+ å› å­ï¼ˆç¾åœ¨è¼¸å…¥æ˜¯æ­£ç¢ºçš„ 5 åˆ— OHLCVï¼‰
            df_factors, _ = alpha158_calculator.compute_all_factors(df_raw)
            # æ’é™¤åŸå§‹ OHLCV åˆ—ï¼Œåªä¿ç•™è¨ˆç®—å‡ºçš„å› å­ï¼ˆ179 å€‹ï¼‰
            factor_columns = [col for col in df_factors.columns if not col.startswith('$')]
            df_factors = df_factors[factor_columns]
            logger.info(f"âœ… Computed Alpha158+ features: {{df_factors.shape}}")

        # ===== æ¨¡å‹é æ¸¬ =====
        if df_factors is None or df_factors.empty:
            logger.error("No Alpha158+ features available, cannot generate predictions")
            predictions = [0.0] * len(df)
        else:
            predictions = []
            for idx in range(len(df_factors)):
                try:
                    features = torch.FloatTensor(df_factors.iloc[idx].values).unsqueeze(0)
                    with torch.no_grad():
                        pred = model(features).item()
                    predictions.append(pred)
                except Exception as e:
                    logger.warning(f"Prediction failed at index {{idx}}: {{e}}")
                    predictions.append(0.0)

        # ===== ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ =====
        # signals æ˜¯é å…ˆå‰µå»ºçš„ pd.Seriesï¼Œåˆå§‹å€¼å…¨ç‚º 0ï¼ˆæŒæœ‰ï¼‰
        for i, pred in enumerate(predictions):
            if pred > BUY_THRESHOLD:
                signals.iloc[i] = 1  # è²·å…¥
            elif pred < SELL_THRESHOLD:
                signals.iloc[i] = -1  # è³£å‡º
            # å¦å‰‡ä¿æŒ 0ï¼ˆæŒæœ‰ï¼‰

        buy_count = (signals == 1).sum()
        sell_count = (signals == -1).sum()
        hold_count = (signals == 0).sum()

        logger.info(f"ğŸ“Š Generated signals:")
        logger.info(f"   Buy:  {{buy_count}} ({{buy_count/len(signals)*100:.1f}}%)")
        logger.info(f"   Sell: {{sell_count}} ({{sell_count/len(signals)*100:.1f}}%)")
        logger.info(f"   Hold: {{hold_count}} ({{hold_count/len(signals)*100:.1f}}%)")

except Exception as e:
    logger.error(f"âŒ Strategy execution failed: {{e}}")
    # traceback å·²ç”±åŸ·è¡Œç’°å¢ƒæä¾›
    logger.error(traceback.format_exc())
    # ä¿æŒ signals å…¨ç‚º 0ï¼ˆä¸äº¤æ˜“ï¼‰

'''
        return template

    # Legacy BaseStrategy class template (ä¿ç•™æ³¨é‡‹ä¾›åƒè€ƒ)
    def _generate_qlib_basestrategy_template_OLD(
        self,
        model_id: int,
        model_name: str,
        model_weight_path: str,
        buy_threshold: float,
        sell_threshold: float,
    ) -> str:
        """
        èˆŠç‰ˆ BaseStrategy é¡æ¨¡æ¿ï¼ˆå·²å»¢æ£„ï¼‰

        æ³¨æ„ï¼šæ­¤æ¨¡æ¿å®šç¾©äº†å®Œæ•´çš„ BaseStrategy é¡ï¼Œä½†ç•¶å‰ qlib_backtest_engine
        æœŸæœ›ç­–ç•¥ä»£ç¢¼ç›´æ¥æ“ä½œ signals è®Šé‡ï¼Œå› æ­¤å·²ä¸å†ä½¿ç”¨ã€‚
        """
        template = f'''"""
AI Model Strategy: {model_name}
Model ID: {model_id}
Auto-generated from RD-Agent trained model
"""

import numpy as np
import pandas as pd
import torch
from qlib.data import D
from qlib.strategy.base import BaseStrategy
from app.services.alpha158_factors import alpha158_calculator
from app.services.model_predictor import SimpleMLP
from loguru import logger


class AIModelStrategy(BaseStrategy):
    """
    åŸºæ–¼è¨“ç·´å¥½çš„ PyTorch æ¨¡å‹çš„äº¤æ˜“ç­–ç•¥

    æ¨¡å‹: {model_name}
    è²·å…¥é–¾å€¼: {buy_threshold}
    è³£å‡ºé–¾å€¼: {sell_threshold}
    """

    def __init__(
        self,
        model_weight_path: str = "{model_weight_path}",
        buy_threshold: float = {buy_threshold},
        sell_threshold: float = {sell_threshold},
        input_dim: int = 179,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.model_weight_path = model_weight_path
        self.buy_threshold = buy_threshold
        self.sell_threshold = sell_threshold

        # åŠ è¼‰æ¨¡å‹
        self.model = SimpleMLP(input_dim=input_dim, hidden_dims=[128, 64])
        self.model.load_state_dict(torch.load(model_weight_path, map_location='cpu'))
        self.model.eval()
        logger.info(f"âœ… Loaded AI model from {{self.model_weight_path}}")

    def generate_trade_decision(self, execute_result=None):
        """
        ç”Ÿæˆäº¤æ˜“æ±ºç­–

        Returns:
            dict: {{stock_id: weight}} - è‚¡ç¥¨æ¬Šé‡å­—å…¸
        """
        trade_date = self.trade_calendar[self.trade_step]

        # ç²å–å¯äº¤æ˜“è‚¡ç¥¨
        list_kwargs = {{
            "start_time": trade_date,
            "end_time": trade_date,
            "as_list": True,
        }}
        if self.level_infra is not None:
            list_kwargs["inst_list"] = self.level_infra.get(trade_date)
        inst_list = D.list_instruments(**list_kwargs)

        # ç‚ºæ¯æ”¯è‚¡ç¥¨è¨ˆç®—é æ¸¬å€¼
        predictions = {{}}
        for stock_id in inst_list:
            try:
                # ç²å– Alpha158+ å› å­
                df_factors = self._get_alpha158_features(stock_id, trade_date)
                if df_factors is None or df_factors.empty:
                    continue

                # æ¨¡å‹é æ¸¬
                features = torch.FloatTensor(df_factors.values)
                with torch.no_grad():
                    pred = self.model(features).item()

                predictions[stock_id] = pred
            except Exception as e:
                logger.warning(f"âŒ Failed to predict {{stock_id}}: {{e}}")
                continue

        # æ ¹æ“šé–¾å€¼ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ
        weights = {{}}
        for stock_id, pred in predictions.items():
            if pred > self.buy_threshold:
                weights[stock_id] = 1.0  # è²·å…¥
            elif pred < self.sell_threshold:
                weights[stock_id] = 0.0  # è³£å‡ºï¼ˆæ¬Šé‡ç‚º 0ï¼‰

        # æ­£è¦åŒ–æ¬Šé‡
        if weights:
            total_weight = sum(weights.values())
            if total_weight > 0:
                weights = {{k: v / total_weight for k, v in weights.items()}}

        logger.info(f"ğŸ“Š Trade date {{trade_date}}: {{len(predictions)}} predictions, {{len(weights)}} positions")
        return weights

    def _get_alpha158_features(self, stock_id: str, end_date) -> pd.DataFrame:
        """ç²å– Alpha158+ å› å­"""
        try:
            # ç²å–è¶³å¤ çš„æ­·å²æ•¸æ“šï¼ˆAlpha158 éœ€è¦ 60 å¤©ï¼‰
            start_date = pd.Timestamp(end_date) - pd.Timedelta(days=120)

            raw_fields = ['$open', '$high', '$low', '$close', '$volume']
            df_raw = D.features(
                instruments=[stock_id],
                fields=raw_fields,
                start_time=start_date.strftime('%Y-%m-%d'),
                end_time=end_date.strftime('%Y-%m-%d'),
                freq='day'
            )

            if df_raw is None or df_raw.empty:
                return None

            # æå–å–®ä¸€è‚¡ç¥¨æ•¸æ“š
            if isinstance(df_raw.index, pd.MultiIndex):
                df_raw = df_raw.xs(stock_id, level=1)

            # è¨ˆç®— Alpha158+ å› å­
            df_factors, _ = alpha158_calculator.compute_all_factors(df_raw)

            # åªè¿”å›ç•¶å¤©çš„å› å­
            return df_factors.iloc[[-1]]

        except Exception as e:
            logger.warning(f"âŒ Failed to get Alpha158+ for {{stock_id}}: {{e}}")
            return None
'''
        return template
