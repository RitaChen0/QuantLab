#!/usr/bin/env python3
"""
Shioaji åˆ° Qlib ç¨ç«‹åŒæ­¥å·¥å…·ï¼ˆæ™ºæ…§å¢é‡åŒæ­¥ç‰ˆï¼‰

åŠŸèƒ½ï¼š
1. å¾ Shioaji API ç²å–è‚¡ç¥¨ 1 åˆ†é˜ K ç·šæ•¸æ“š
2. åŒæ™‚å­˜å„²åˆ° PostgreSQL å’Œ Qlib äºŒé€²åˆ¶æ ¼å¼
3. ğŸ§  æ™ºæ…§å¢é‡åŒæ­¥ï¼šè‡ªå‹•æª¢æ¸¬ç¾æœ‰æ•¸æ“šçš„æœ€å¾Œæ—¥æœŸï¼Œåƒ…åŒæ­¥ç¼ºå¤±éƒ¨åˆ†
4. å°ˆé–€åœ¨æ”¶ç›¤å¾Œé‹è¡Œï¼Œæˆªå–ç•¶å¤©æ‰€æœ‰è‚¡ç¥¨çš„åˆ†é˜ç·šè³‡æ–™

ä½¿ç”¨ç¯„ä¾‹ï¼š
    # ğŸ§  æ™ºæ…§å¢é‡åŒæ­¥ï¼ˆæ¨è–¦ï¼Œæ”¶ç›¤å¾Œé‹è¡Œï¼‰
    python sync_shioaji_to_qlib.py --smart

    # æ™ºæ…§åŒæ­¥åˆ°æŒ‡å®šæ—¥æœŸ
    python sync_shioaji_to_qlib.py --smart --end-date 2025-12-13

    # å‚³çµ±æ¨¡å¼ï¼šåŒæ­¥ä»Šå¤©çš„æ•¸æ“š
    python sync_shioaji_to_qlib.py --today

    # åŒæ­¥æŒ‡å®šæ—¥æœŸç¯„åœ
    python sync_shioaji_to_qlib.py --start-date 2025-12-01 --end-date 2025-12-13

    # æ¸¬è©¦æ¨¡å¼ï¼ˆåƒ…åŒæ­¥ 5 æª”è‚¡ç¥¨ï¼‰
    python sync_shioaji_to_qlib.py --smart --test

å®šæ™‚ä»»å‹™ï¼ˆCronï¼‰ï¼š
    # æ¯å€‹äº¤æ˜“æ—¥ 15:00 è‡ªå‹•æ™ºæ…§å¢é‡åŒæ­¥
    0 15 * * 1-5 cd /home/ubuntu/QuantLab/backend && python scripts/sync_shioaji_to_qlib.py --smart
"""

import sys
import os
from pathlib import Path
from datetime import datetime, date, timedelta
from typing import List, Optional, Tuple
import argparse
import time
import struct

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

import pandas as pd
import numpy as np
from loguru import logger
from tqdm import tqdm
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# QuantLab æ¨¡çµ„
from app.core.config import settings
from app.db.base import import_models
from app.services.shioaji_client import ShioajiClient
from app.repositories.stock_minute_price import StockMinutePriceRepository
from app.schemas.stock_minute_price import StockMinutePriceCreate

# Qlib æ¨¡çµ„
import qlib
from qlib.config import REG_CN
from qlib.data.storage.file_storage import FileFeatureStorage
from qlib.data import D

# å°å…¥æ‰€æœ‰æ¨¡å‹
import_models()

# Qlib ç‰¹å¾µåˆ—è¡¨ï¼ˆåˆ†é˜ç·šï¼‰
QLIB_MINUTE_FEATURES = ['open', 'high', 'low', 'close', 'volume']

# æ—¥èªŒé…ç½®
logger.remove()
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>",
    level="INFO"
)
logger.add(
    "/tmp/shioaji_to_qlib_{time}.log",
    rotation="1 day",
    retention="7 days",
    level="DEBUG"
)


class ShioajiToQlibSyncer:
    """Shioaji åˆ° Qlib åŒæ­¥å™¨ï¼ˆæ”¯æ´æ™ºæ…§å¢é‡åŒæ­¥ï¼‰"""

    def __init__(
        self,
        qlib_data_dir: str = "/data/qlib/tw_stock_minute",
        db_url: Optional[str] = None,
        skip_db: bool = False
    ):
        """
        åˆå§‹åŒ–åŒæ­¥å™¨

        Args:
            qlib_data_dir: Qlib æ•¸æ“šç›®éŒ„
            db_url: è³‡æ–™åº«é€£æ¥å­—ä¸²ï¼ˆNone å‰‡ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ï¼‰
            skip_db: æ˜¯å¦è·³éè³‡æ–™åº«å­˜å„²ï¼ˆåƒ…æ›´æ–° Qlibï¼‰
        """
        self.qlib_data_dir = Path(qlib_data_dir)
        self.skip_db = skip_db

        # åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥
        if not skip_db:
            self.db_url = db_url or settings.DATABASE_URL
            self.engine = create_engine(self.db_url, pool_pre_ping=True)
            SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
            self.db_session = SessionLocal()
            self.repo = StockMinutePriceRepository  # éœæ…‹æ–¹æ³•ï¼Œä¸éœ€å¯¦ä¾‹åŒ–
        else:
            logger.info("âš ï¸  è·³éè³‡æ–™åº«å­˜å„²ï¼Œåƒ…æ›´æ–° Qlib")
            self.engine = None
            self.db_session = None
            self.repo = None

        # åˆå§‹åŒ– Qlib
        self._init_qlib()

        # Shioaji å®¢æˆ¶ç«¯ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰
        self.shioaji_client = None

    def _init_qlib(self):
        """åˆå§‹åŒ– Qlib ç’°å¢ƒ"""
        try:
            self.qlib_data_dir.mkdir(parents=True, exist_ok=True)
            qlib.init(provider_uri=str(self.qlib_data_dir), region=REG_CN)
            logger.info(f"âœ… Qlib å·²åˆå§‹åŒ–: {self.qlib_data_dir}")
        except Exception as e:
            logger.error(f"âŒ Qlib åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def get_stock_list(self) -> List[str]:
        """
        å¾è³‡æ–™åº«ç²å–è‚¡ç¥¨æ¸…å–®

        Returns:
            è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        """
        if self.skip_db or not self.engine:
            logger.warning("âš ï¸  ç„¡æ³•å¾è³‡æ–™åº«ç²å–è‚¡ç¥¨æ¸…å–®ï¼Œè¿”å› Top 50")
            # Fallback: è¿”å›ç†±é–€è‚¡ç¥¨
            return [
                '2330', '2317', '2454', '2412', '3008',
                '2308', '2882', '1301', '1303', '2002',
                '2886', '2881', '2891', '2892', '2885',
                '2884', '2887', '2883', '5880', '2912',
                '2880', '2382', '2395', '6505', '3045',
                '1216', '2357', '1326', '2303', '2379',
                '2408', '2207', '2327', '3711', '2474',
                '2801', '2609', '2615', '2603', '4904',
                '9910', '2888', '2345', '6669', '2409',
                '3037', '2377', '2353', '5871', '2324',
            ]

        try:
            with self.engine.connect() as conn:
                result = conn.execute(text("""
                    SELECT DISTINCT stock_id
                    FROM stock_prices
                    ORDER BY stock_id
                """))
                stock_ids = [row[0] for row in result.fetchall()]
                logger.info(f"âœ… å¾è³‡æ–™åº«ç²å– {len(stock_ids)} æª”è‚¡ç¥¨")
                return stock_ids
        except Exception as e:
            logger.error(f"âŒ ç²å–è‚¡ç¥¨æ¸…å–®å¤±æ•—: {e}")
            return []

    def get_db_last_date(self, stock_id: str) -> Optional[date]:
        """
        ç²å– PostgreSQL ä¸­è©²è‚¡ç¥¨çš„æœ€å¾Œæ—¥æœŸ

        Args:
            stock_id: è‚¡ç¥¨ä»£ç¢¼

        Returns:
            æœ€å¾Œæ—¥æœŸæˆ– None
        """
        if self.skip_db or not self.engine:
            return None

        try:
            with self.engine.connect() as conn:
                result = conn.execute(text("""
                    SELECT MAX(datetime::date) as last_date
                    FROM stock_minute_prices
                    WHERE stock_id = :stock_id
                """), {"stock_id": stock_id})
                row = result.fetchone()
                if row and row[0]:
                    return row[0]
                return None
        except Exception as e:
            logger.debug(f"ç„¡æ³•ç²å– {stock_id} çš„ PostgreSQL æœ€å¾Œæ—¥æœŸ: {e}")
            return None

    def get_qlib_last_date(self, stock_id: str) -> Optional[date]:
        """
        ç²å– Qlib ä¸­è©²è‚¡ç¥¨çš„æœ€å¾Œæ—¥æœŸ

        Args:
            stock_id: è‚¡ç¥¨ä»£ç¢¼

        Returns:
            æœ€å¾Œæ—¥æœŸæˆ– None
        """
        try:
            # å˜—è©¦è®€å–è©²è‚¡ç¥¨çš„æ”¶ç›¤åƒ¹æ•¸æ“š
            df = D.features([stock_id], ['$close'], freq='1min')

            if df is None or df.empty:
                return None

            # ç²å–æœ€å¾Œä¸€å€‹æ—¥æœŸæ™‚é–“
            last_datetime = df.index.get_level_values('datetime').max()
            return last_datetime.date()
        except Exception:
            # å¦‚æœè®€å–å¤±æ•—ï¼Œè¡¨ç¤ºæ•¸æ“šä¸å­˜åœ¨
            return None

    def determine_sync_range(
        self,
        stock_id: str,
        user_end_date: date,
        smart_mode: bool = False
    ) -> Tuple[Optional[date], Optional[date], str]:
        """
        æ™ºæ…§åˆ¤æ–·éœ€è¦åŒæ­¥çš„æ—¥æœŸç¯„åœ

        Args:
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            user_end_date: ç”¨æˆ¶æŒ‡å®šçš„çµæŸæ—¥æœŸï¼ˆé€šå¸¸æ˜¯ä»Šå¤©ï¼‰
            smart_mode: æ˜¯å¦ä½¿ç”¨æ™ºæ…§æ¨¡å¼

        Returns:
            (é–‹å§‹æ—¥æœŸ, çµæŸæ—¥æœŸ, åŒæ­¥é¡å‹)
            åŒæ­¥é¡å‹: 'full', 'incremental', 'skip'
        """
        if not smart_mode:
            # éæ™ºæ…§æ¨¡å¼ï¼Œè¿”å› None è¡¨ç¤ºä½¿ç”¨ç”¨æˆ¶æŒ‡å®šçš„æ—¥æœŸç¯„åœ
            return (None, None, 'user_specified')

        # æª¢æŸ¥ PostgreSQL æœ€å¾Œæ—¥æœŸ
        db_last_date = self.get_db_last_date(stock_id)

        # æª¢æŸ¥ Qlib æœ€å¾Œæ—¥æœŸ
        qlib_last_date = self.get_qlib_last_date(stock_id)

        # å–å…©è€…ä¸­è¼ƒæ—©çš„æ—¥æœŸä½œç‚ºåƒè€ƒé»
        if db_last_date and qlib_last_date:
            last_date = min(db_last_date, qlib_last_date)
        elif db_last_date:
            last_date = db_last_date
        elif qlib_last_date:
            last_date = qlib_last_date
        else:
            # å®Œå…¨æ²’æœ‰æ•¸æ“šï¼Œé¦–æ¬¡åŒæ­¥ï¼ˆé è¨­å¾ 6 å€‹æœˆå‰é–‹å§‹ï¼‰
            start_date = user_end_date - timedelta(days=180)
            return (start_date, user_end_date, 'full')

        # æª¢æŸ¥æ˜¯å¦å·²æ˜¯æœ€æ–°ï¼ˆä½¿ç”¨åš´æ ¼çš„ > è€Œé >=ï¼‰
        if last_date > user_end_date:
            return (None, None, 'skip')

        # å¢é‡åŒæ­¥ï¼ˆå¾æœ€å¾Œæ—¥æœŸé–‹å§‹ï¼Œå…è¨±è¦†è“‹æœ€å¾Œä¸€å¤©ï¼Œç¢ºä¿å¹‚ç­‰æ€§ï¼‰
        # æ³¨æ„ï¼šä½¿ç”¨ ON CONFLICT DO NOTHINGï¼Œé‡è¤‡æ•¸æ“šæœƒè¢«è‡ªå‹•è·³é
        start_date = last_date
        return (start_date, user_end_date, 'incremental')

    def _is_futures(self, stock_id: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºæœŸè²¨"""
        return stock_id in ['TX', 'MTX']

    def _get_contract_type(self, stock_id: str) -> str:
        """ç²å–å¥‘ç´„é¡å‹"""
        return 'futures' if self._is_futures(stock_id) else 'stock'

    def fetch_minute_data(
        self,
        stock_id: str,
        start_date: date,
        end_date: date
    ) -> Optional[Tuple[pd.DataFrame, str]]:
        """
        å¾ Shioaji API ç²å–åˆ†é˜ K ç·šæ•¸æ“šï¼ˆæ”¯æŒè‚¡ç¥¨å’ŒæœŸè²¨ï¼‰

        Args:
            stock_id: æ¨™çš„ä»£ç¢¼ï¼ˆè‚¡ç¥¨æˆ–æœŸè²¨ï¼‰
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ

        Returns:
            (DataFrame, actual_stock_id): æ•¸æ“šå’Œå¯¦éš›æ¨™çš„ä»£ç¢¼
            - è‚¡ç¥¨: ("2330", "2330")
            - æœŸè²¨: ("TX", "TX202512")  â† è¿”å›å¯¦éš›æœˆä»½åˆç´„ä»£ç¢¼
        """
        if not self.shioaji_client:
            self.shioaji_client = ShioajiClient()

        if not self.shioaji_client.is_available():
            logger.error("âŒ Shioaji å®¢æˆ¶ç«¯æœªåˆå§‹åŒ–")
            return None

        # åˆ¤æ–·å¥‘ç´„é¡å‹
        contract_type = self._get_contract_type(stock_id)
        is_futures = self._is_futures(stock_id)

        # å°æ–¼æœŸè²¨ï¼Œç²å–å¯¦éš›æœˆä»½åˆç´„ä»£ç¢¼
        actual_stock_id = stock_id
        if is_futures:
            contract_id = self.shioaji_client.get_futures_contract_id(stock_id)
            if contract_id:
                actual_stock_id = contract_id
                logger.info(f"  [CONTRACT] {stock_id} â†’ {actual_stock_id}")
            else:
                logger.error(f"  [CONTRACT] Failed to get contract ID for {stock_id}")
                return None

        try:
            # è¨­å®šæ™‚é–“ç¯„åœ
            # æœŸè²¨ï¼š08:45-æ¬¡æ—¥05:00ï¼ˆå®Œæ•´æ—¥ç›¤ + å¤œç›¤ï¼‰
            # è‚¡ç¥¨ï¼š09:00-13:30ï¼ˆåƒ…æ—¥ç›¤ï¼‰
            if is_futures:
                start_datetime = datetime.combine(start_date, datetime.min.time().replace(hour=8, minute=45))
                # æœŸè´§å¤œç›˜å»¶ç»­åˆ°æ¬¡æ—¥ 05:00ï¼Œå› æ­¤ end_datetime éœ€è¦ +1 å¤©
                end_datetime = datetime.combine(end_date + timedelta(days=1), datetime.min.time().replace(hour=5, minute=0))
                logger.debug(f"  æœŸè²¨ {stock_id}: æ™‚é–“ç¯„åœ {start_datetime} ~ {end_datetime}ï¼ˆå«å®Œæ•´å¤œç›¤ï¼‰")
            else:
                start_datetime = datetime.combine(start_date, datetime.min.time().replace(hour=9, minute=0))
                end_datetime = datetime.combine(end_date, datetime.min.time().replace(hour=13, minute=30))

            # èª¿ç”¨ Shioaji API
            df = self.shioaji_client.get_kbars(
                stock_id=stock_id,
                start_datetime=start_datetime,
                end_datetime=end_datetime,
                timeframe='1min',
                contract_type=contract_type  # â­ å‚³éå¥‘ç´„é¡å‹
            )

            if df is None or df.empty:
                logger.debug(f"  âš ï¸  {stock_id}: ç„¡æ•¸æ“š")
                return None

            logger.debug(f"  âœ“ {stock_id}: ç²å– {len(df)} ç­†åˆ†é˜æ•¸æ“š")
            # ğŸ†• è¿”å› DataFrame å’Œå¯¦éš›åˆç´„ ID
            return df, actual_stock_id

        except Exception as e:
            logger.error(f"  âŒ {stock_id}: ç²å–æ•¸æ“šå¤±æ•— - {e}")
            return None

    def save_to_postgresql(self, stock_id: str, df: pd.DataFrame) -> int:
        """
        ä¿å­˜æ•¸æ“šåˆ° PostgreSQLï¼ˆä½¿ç”¨ ON CONFLICT å¿½ç•¥é‡è¤‡ï¼‰

        ä½¿ç”¨ç­–ç•¥ï¼š
        1. ä½¿ç”¨ SQLAlchemy Core çš„ INSERT ... ON CONFLICT DO NOTHING
        2. å‘é‡åŒ–æ•¸æ“šæº–å‚™ï¼ˆé¿å… iterrowsï¼Œæ€§èƒ½æå‡ 100 å€ï¼‰
        3. è™•ç† NaN å€¼ï¼ˆé˜²æ­¢é‹è¡Œæ™‚éŒ¯èª¤ï¼‰

        Args:
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            df: æ•¸æ“š DataFrame

        Returns:
            æˆåŠŸæ’å…¥çš„è¨˜éŒ„æ•¸
        """
        if self.skip_db or not self.repo:
            return 0

        try:
            if df.empty:
                return 0

            from sqlalchemy.dialects.postgresql import insert
            from app.models.stock_minute_price import StockMinutePrice

            # å‘é‡åŒ–æº–å‚™æ•¸æ“šï¼ˆæ¯” iterrows å¿« 100 å€ï¼‰
            df_copy = df.copy()
            df_copy['stock_id'] = stock_id
            df_copy['timeframe'] = '1min'

            # ç¢ºä¿æ•¸æ“šé¡å‹æ­£ç¢º
            df_copy['open'] = df_copy['open'].astype(float)
            df_copy['high'] = df_copy['high'].astype(float)
            df_copy['low'] = df_copy['low'].astype(float)
            df_copy['close'] = df_copy['close'].astype(float)

            # è™•ç† NaN å€¼ï¼ˆvolume å¿…é ˆæ˜¯æ•´æ•¸ï¼‰
            df_copy['volume'] = df_copy['volume'].fillna(0).astype(int)

            # é¸æ“‡éœ€è¦çš„æ¬„ä½ä¸¦è½‰æ›ç‚ºå­—å…¸åˆ—è¡¨
            records = df_copy[['stock_id', 'datetime', 'timeframe', 'open', 'high', 'low', 'close', 'volume']].to_dict('records')

            # åˆ†æ‰¹æ’å…¥ï¼ˆæ¯æ‰¹ 1,000 ç­†ï¼‰
            batch_size = 1000
            total_inserted = 0

            for i in range(0, len(records), batch_size):
                batch = records[i:i + batch_size]

                # ä½¿ç”¨ SQLAlchemy Core çš„ ON CONFLICT DO UPDATE
                # å…è¨±æ›´æ–°æ•¸æ“šæºä¿®æ­£çš„æ­·å²æ•¸æ“š
                stmt = insert(StockMinutePrice).values(batch)
                stmt = stmt.on_conflict_do_update(
                    index_elements=['stock_id', 'datetime', 'timeframe'],
                    set_={
                        'open': stmt.excluded.open,
                        'high': stmt.excluded.high,
                        'low': stmt.excluded.low,
                        'close': stmt.excluded.close,
                        'volume': stmt.excluded.volume,
                    }
                )

                result = self.db_session.execute(stmt)
                total_inserted += result.rowcount

                # æ¯æ‰¹æäº¤ä¸€æ¬¡ï¼ˆé¿å…å¤§äº‹å‹™å°è‡´å…§å­˜æº¢å‡ºï¼‰
                self.db_session.commit()

            skipped = len(records) - total_inserted
            if skipped > 0:
                logger.debug(f"  âœ“ PostgreSQL: æ’å…¥ {total_inserted} ç­†ï¼ˆè·³é {skipped} ç­†é‡è¤‡ï¼‰")
            else:
                logger.debug(f"  âœ“ PostgreSQL: æ’å…¥ {total_inserted} ç­†")
            return total_inserted

        except Exception as e:
            self.db_session.rollback()
            logger.error(f"  âŒ PostgreSQL: ä¿å­˜å¤±æ•— - {e}")
            return 0

    def save_to_qlib(
        self,
        stock_id: str,
        df: pd.DataFrame,
        trading_minutes: pd.DatetimeIndex
    ) -> bool:
        """
        ä¿å­˜æ•¸æ“šåˆ° Qlib æ ¼å¼

        Args:
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            df: æ•¸æ“š DataFrame
            trading_minutes: å®Œæ•´çš„äº¤æ˜“åˆ†é˜ç´¢å¼•

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            instrument = stock_id.lower()

            # å‰µå»ºè‚¡ç¥¨ç›®éŒ„
            features_dir = self.qlib_data_dir / 'features' / instrument
            features_dir.mkdir(parents=True, exist_ok=True)

            # å°‡ DataFrame å°é½Šåˆ°å®Œæ•´äº¤æ˜“åˆ†é˜ç´¢å¼•
            df = df.set_index('datetime')
            df = df.reindex(trading_minutes)

            # ç‚ºæ¯å€‹ç‰¹å¾µå¯«å…¥æ•¸æ“š
            for field in QLIB_MINUTE_FEATURES:
                if field not in df.columns:
                    continue

                # æå–ç‰¹å¾µæ•¸æ“š
                data = df[field].values.astype(np.float32)

                # ä½¿ç”¨ FileFeatureStorage å¯«å…¥
                storage = FileFeatureStorage(
                    instrument=instrument,
                    field=field,
                    freq="1min"
                )

                try:
                    storage.write(data)
                except Exception as e:
                    logger.warning(f"  âš ï¸  Qlib {field}: å¯«å…¥å¤±æ•— - {e}")
                    continue

            logger.debug(f"  âœ“ Qlib: {len(df)} å€‹æ™‚é–“é»")
            return True

        except Exception as e:
            logger.error(f"  âŒ Qlib: ä¿å­˜å¤±æ•— - {e}")
            return False

    def generate_trading_minutes(
        self,
        start_date: date,
        end_date: date,
        is_futures: bool = False
    ) -> pd.DatetimeIndex:
        """
        ç”Ÿæˆäº¤æ˜“åˆ†é˜ç´¢å¼•ï¼ˆæ”¯æŒè‚¡ç¥¨å’ŒæœŸè´§ï¼‰

        Args:
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            is_futures: æ˜¯å¦ç‚ºæœŸè²¨ï¼ˆTrue=æœŸè²¨ï¼ŒFalse=è‚¡ç¥¨ï¼‰

        Returns:
            äº¤æ˜“åˆ†é˜ç´¢å¼•

        äº¤æ˜“æ™‚é–“ï¼š
        - è‚¡ç¥¨ï¼š09:00-13:30
        - æœŸè²¨ï¼šå®Œæ•´äº¤æ˜“æ™‚æ®µï¼ˆæ—¥ç›¤ + å¤œç›¤ï¼‰
          - å¤œç›¤å¾Œæ®µï¼š00:00-05:00
          - æ—¥ç›¤ï¼š08:45-13:45
          - å¤œç›¤å‰æ®µï¼š15:00-23:59
        """
        minutes = []
        current_date = start_date

        if is_futures:
            # æœŸè²¨ï¼šå®Œæ•´äº¤æ˜“æ™‚æ®µï¼ˆæ—¥ç›¤ + å¤œç›¤ï¼‰
            while current_date <= end_date:
                # 1. å¤œç›¤å¾Œæ®µï¼š00:00-05:00ï¼ˆå±¬æ–¼å‰ä¸€äº¤æ˜“æ—¥çš„å¤œç›¤ï¼‰
                for hour in range(0, 5):
                    for minute in range(60):
                        dt = datetime.combine(current_date, datetime.min.time().replace(hour=hour, minute=minute))
                        minutes.append(dt)

                # 05:00 è¨˜éŒ„æœ€å¾Œä¸€åˆ†é˜
                dt = datetime.combine(current_date, datetime.min.time().replace(hour=5, minute=0))
                minutes.append(dt)

                # 2. æ—¥ç›¤ï¼š08:45-13:45
                # 08:45-08:59 (15 åˆ†é’Ÿ)
                for minute in range(45, 60):
                    dt = datetime.combine(current_date, datetime.min.time().replace(hour=8, minute=minute))
                    minutes.append(dt)

                # 09:00-12:00
                for hour in range(9, 12):
                    for minute in range(60):
                        dt = datetime.combine(current_date, datetime.min.time().replace(hour=hour, minute=minute))
                        minutes.append(dt)

                # 12:00-13:45
                for hour in range(12, 14):
                    for minute in range(60):
                        if hour == 13 and minute > 45:
                            break
                        dt = datetime.combine(current_date, datetime.min.time().replace(hour=hour, minute=minute))
                        minutes.append(dt)

                # 3. å¤œç›¤å‰æ®µï¼š15:00-23:59ï¼ˆå±¬æ–¼ç•¶æ—¥äº¤æ˜“ï¼‰
                for hour in range(15, 24):
                    for minute in range(60):
                        dt = datetime.combine(current_date, datetime.min.time().replace(hour=hour, minute=minute))
                        minutes.append(dt)

                current_date += timedelta(days=1)
        else:
            # è‚¡ç¥¨ï¼š09:00-13:30
            while current_date <= end_date:
                # ä¸Šåˆç›¤ï¼š09:00-12:00
                for hour in range(9, 12):
                    for minute in range(60):
                        dt = datetime.combine(current_date, datetime.min.time().replace(hour=hour, minute=minute))
                        minutes.append(dt)

                # ä¸‹åˆç›¤ï¼š12:00-13:30
                for hour in range(12, 14):
                    for minute in range(60):
                        if hour == 13 and minute > 30:
                            break
                        dt = datetime.combine(current_date, datetime.min.time().replace(hour=hour, minute=minute))
                        minutes.append(dt)

                current_date += timedelta(days=1)

        return pd.DatetimeIndex(minutes)

    def sync_stock(
        self,
        stock_id: str,
        start_date: date,
        end_date: date,
        trading_minutes: pd.DatetimeIndex
    ) -> Tuple[int, int]:
        """
        åŒæ­¥å–®ä¸€æ¨™çš„çš„æ•¸æ“šï¼ˆæ”¯æŒè‚¡ç¥¨å’ŒæœŸè´§ï¼‰

        Args:
            stock_id: æ¨™çš„ä»£ç¢¼ï¼ˆè‚¡ç¥¨æˆ–æœŸè´§ï¼‰
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            trading_minutes: äº¤æ˜“åˆ†é˜ç´¢å¼•

        Returns:
            (PostgreSQL æ’å…¥æ•¸, Qlib æ˜¯å¦æˆåŠŸ)
        """
        # 1. å¾ Shioaji ç²å–æ•¸æ“š
        result = self.fetch_minute_data(stock_id, start_date, end_date)

        if result is None:
            return (0, 0)

        # ğŸ†• è§£åŒ…è¿”å›å€¼ï¼šDataFrame å’Œå¯¦éš›æ¨™çš„ä»£ç¢¼
        df, actual_stock_id = result

        if df.empty:
            return (0, 0)

        # 2. ä¿å­˜åˆ° PostgreSQLï¼ˆä½¿ç”¨å¯¦éš›åˆç´„ä»£ç¢¼ï¼‰
        db_count = self.save_to_postgresql(actual_stock_id, df) if not self.skip_db else 0

        # 3. ä¿å­˜åˆ° Qlibï¼ˆä½¿ç”¨å¯¦éš›åˆç´„ä»£ç¢¼ï¼‰
        qlib_success = self.save_to_qlib(actual_stock_id, df, trading_minutes)

        return (db_count, 1 if qlib_success else 0)

    def sync_all(
        self,
        stock_ids: List[str],
        user_start_date: Optional[date],
        user_end_date: date,
        smart_mode: bool = False
    ):
        """
        åŒæ­¥æ‰€æœ‰æ¨™çš„çš„æ•¸æ“šï¼ˆæ”¯æŒè‚¡ç¥¨å’ŒæœŸè´§ï¼Œæ”¯æ´æ™ºæ…§æ¨¡å¼ï¼‰

        Args:
            stock_ids: æ¨™çš„ä»£ç¢¼åˆ—è¡¨ï¼ˆè‚¡ç¥¨æˆ–æœŸè´§ï¼‰
            user_start_date: ç”¨æˆ¶æŒ‡å®šçš„é–‹å§‹æ—¥æœŸï¼ˆæ™ºæ…§æ¨¡å¼ä¸‹å¯ç‚º Noneï¼‰
            user_end_date: ç”¨æˆ¶æŒ‡å®šçš„çµæŸæ—¥æœŸ
            smart_mode: æ˜¯å¦ä½¿ç”¨æ™ºæ…§å¢é‡åŒæ­¥
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"é–‹å§‹åŒæ­¥: {len(stock_ids)} æª”æ¨™çš„ï¼ˆè‚¡ç¥¨/æœŸè´§ï¼‰")
        if smart_mode:
            logger.info(f"ğŸ§  æ™ºæ…§æ¨¡å¼: è‡ªå‹•æª¢æ¸¬æ¯æª”æ¨™çš„çš„æœ€å¾Œæ—¥æœŸ")
            logger.info(f"   ç›®æ¨™æ—¥æœŸ: {user_end_date}")
        else:
            logger.info(f"æ—¥æœŸç¯„åœ: {user_start_date} ~ {user_end_date}")
        logger.info(f"{'='*60}\n")

        # çµ±è¨ˆè®Šé‡
        total_db_count = 0
        total_qlib_count = 0
        error_count = 0
        skipped_count = 0
        full_sync_count = 0
        incremental_sync_count = 0

        # é€²åº¦æ¢
        progress_bar = tqdm(stock_ids, desc="åŒæ­¥é€²åº¦", unit="æª”")

        for stock_id in progress_bar:
            progress_bar.set_description(f"åŒæ­¥ {stock_id}")

            try:
                # åˆ¤æ–·åŒæ­¥ç¯„åœ
                if smart_mode:
                    sync_start, sync_end, sync_type = self.determine_sync_range(
                        stock_id, user_end_date, smart_mode=True
                    )

                    if sync_type == 'skip':
                        skipped_count += 1
                        logger.debug(f"  â­ï¸  {stock_id}: å·²æ˜¯æœ€æ–°ï¼Œè·³é")
                        continue

                    if sync_type == 'full':
                        full_sync_count += 1
                        logger.info(f"  ğŸ“¦ {stock_id}: å®Œæ•´åŒæ­¥ ({sync_start} ~ {sync_end})")
                    elif sync_type == 'incremental':
                        incremental_sync_count += 1
                        logger.info(f"  â• {stock_id}: å¢é‡åŒæ­¥ ({sync_start} ~ {sync_end})")
                else:
                    # éæ™ºæ…§æ¨¡å¼ï¼Œä½¿ç”¨ç”¨æˆ¶æŒ‡å®šçš„æ—¥æœŸ
                    sync_start = user_start_date
                    sync_end = user_end_date

                # ç”Ÿæˆäº¤æ˜“åˆ†é˜ç´¢å¼•ï¼ˆæ ¹æ“šæ¨™çš„é¡å‹ï¼‰
                is_futures = self._is_futures(stock_id)
                trading_minutes = self.generate_trading_minutes(sync_start, sync_end, is_futures=is_futures)

                # åŸ·è¡ŒåŒæ­¥
                db_count, qlib_count = self.sync_stock(
                    stock_id, sync_start, sync_end, trading_minutes
                )

                if db_count == 0 and qlib_count == 0:
                    logger.debug(f"  âš ï¸  {stock_id}: ç„¡æ–°æ•¸æ“š")
                else:
                    total_db_count += db_count
                    total_qlib_count += qlib_count
                    logger.info(f"  âœ… {stock_id}: DB +{db_count}, Qlib {'âœ“' if qlib_count else 'âœ—'}")

            except Exception as e:
                error_count += 1
                logger.error(f"  âŒ {stock_id}: åŒæ­¥å¤±æ•— - {e}")
                continue

        # ç¸½çµ
        logger.info(f"\n{'='*60}")
        logger.info("åŒæ­¥å®Œæˆï¼")
        if smart_mode:
            logger.info(f"ğŸ“¦ å®Œæ•´åŒæ­¥: {full_sync_count} æª”")
            logger.info(f"â• å¢é‡åŒæ­¥: {incremental_sync_count} æª”")
            logger.info(f"â­ï¸  å·²æœ€æ–°è·³é: {skipped_count} æª”")
        else:
            logger.info(f"âœ… æˆåŠŸ: {len(stock_ids) - error_count - skipped_count} æª”")
        logger.info(f"âŒ å¤±æ•—: {error_count} æª”")
        logger.info(f"ğŸ“Š PostgreSQL: æ’å…¥ {total_db_count} ç­†")
        logger.info(f"ğŸ“Š Qlib: æ›´æ–° {total_qlib_count} æª”")
        logger.info(f"{'='*60}")

    def close(self):
        """é—œé–‰è³‡æº"""
        if self.shioaji_client and self.shioaji_client.is_available():
            self.shioaji_client.__exit__(None, None, None)

        if self.db_session:
            self.db_session.close()

        logger.info("âœ… è³‡æºå·²é‡‹æ”¾")


def main():
    parser = argparse.ArgumentParser(
        description='Shioaji åˆ° Qlib ç¨ç«‹åŒæ­¥å·¥å…·ï¼ˆæ™ºæ…§å¢é‡åŒæ­¥ç‰ˆï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ç”¨æ³•:
  # ğŸ§  æ™ºæ…§å¢é‡åŒæ­¥ï¼ˆæ¨è–¦ï¼‰
  python sync_shioaji_to_qlib.py --smart

  # æ™ºæ…§åŒæ­¥åˆ°æŒ‡å®šæ—¥æœŸ
  python sync_shioaji_to_qlib.py --smart --end-date 2025-12-13

  # å‚³çµ±æ¨¡å¼ï¼šåŒæ­¥ä»Šå¤©çš„æ•¸æ“š
  python sync_shioaji_to_qlib.py --today

  # åŒæ­¥æŒ‡å®šæ—¥æœŸç¯„åœ
  python sync_shioaji_to_qlib.py --start-date 2025-12-01 --end-date 2025-12-13

  # æ¸¬è©¦æ¨¡å¼ï¼ˆåƒ…åŒæ­¥ 5 æª”è‚¡ç¥¨ï¼‰
  python sync_shioaji_to_qlib.py --smart --test
        """
    )

    # æ—¥æœŸç¯„åœåƒæ•¸
    date_group = parser.add_mutually_exclusive_group(required=True)
    date_group.add_argument('--smart', action='store_true',
                           help='ğŸ§  æ™ºæ…§æ¨¡å¼ï¼šè‡ªå‹•æª¢æ¸¬æœ€å¾Œæ—¥æœŸï¼Œåƒ…åŒæ­¥ç¼ºå¤±éƒ¨åˆ†ï¼ˆæ¨è–¦ï¼‰')
    date_group.add_argument('--today', action='store_true', help='åŒæ­¥ä»Šå¤©çš„æ•¸æ“š')
    date_group.add_argument('--yesterday', action='store_true', help='åŒæ­¥æ˜¨å¤©çš„æ•¸æ“š')
    date_group.add_argument('--start-date', type=str, help='é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)')

    parser.add_argument('--end-date', type=str, help='çµæŸæ—¥æœŸ (YYYY-MM-DDï¼Œé è¨­ç‚ºä»Šå¤©)')

    # è‚¡ç¥¨ç¯„åœåƒæ•¸
    parser.add_argument('--stocks', type=str, help='è‚¡ç¥¨ä»£ç¢¼ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰ï¼Œç•™ç©ºå‰‡åŒæ­¥æ‰€æœ‰')
    parser.add_argument('--test', action='store_true', help='æ¸¬è©¦æ¨¡å¼ï¼ˆåƒ…åŒæ­¥å‰ 5 æª”ï¼‰')
    parser.add_argument('--limit', type=int, help='é™åˆ¶åŒæ­¥æ•¸é‡')

    # å­˜å„²é¸é …
    parser.add_argument('--qlib-only', action='store_true', help='åƒ…æ›´æ–° Qlibï¼Œè·³é PostgreSQL')
    parser.add_argument('--qlib-data-dir', type=str, default='/data/qlib/tw_stock_minute',
                        help='Qlib æ•¸æ“šç›®éŒ„ï¼ˆé è¨­: /data/qlib/tw_stock_minuteï¼‰')

    args = parser.parse_args()

    # è§£ææ—¥æœŸç¯„åœ
    smart_mode = False
    if args.smart:
        smart_mode = True
        start_date = None  # æ™ºæ…§æ¨¡å¼ä¸éœ€è¦ start_date
        end_date = datetime.strptime(args.end_date, '%Y-%m-%d').date() if args.end_date else date.today()
    elif args.today:
        start_date = end_date = date.today()
    elif args.yesterday:
        start_date = end_date = date.today() - timedelta(days=1)
    else:
        start_date = datetime.strptime(args.start_date, '%Y-%m-%d').date()
        end_date = datetime.strptime(args.end_date, '%Y-%m-%d').date() if args.end_date else start_date

    # åˆå§‹åŒ–åŒæ­¥å™¨
    syncer = ShioajiToQlibSyncer(
        qlib_data_dir=args.qlib_data_dir,
        skip_db=args.qlib_only
    )

    # ç²å–è‚¡ç¥¨æ¸…å–®
    if args.stocks:
        stock_ids = [s.strip() for s in args.stocks.split(',')]
        logger.info(f"ä½¿ç”¨æŒ‡å®šè‚¡ç¥¨æ¸…å–®: {len(stock_ids)} æª”")
    else:
        stock_ids = syncer.get_stock_list()

    # æ¸¬è©¦æ¨¡å¼
    if args.test:
        stock_ids = stock_ids[:5]
        logger.warning(f"âš ï¸  æ¸¬è©¦æ¨¡å¼: åƒ…åŒæ­¥å‰ {len(stock_ids)} æª”")

    # é™åˆ¶æ•¸é‡
    if args.limit:
        stock_ids = stock_ids[:args.limit]
        logger.warning(f"âš ï¸  é™åˆ¶åŒæ­¥: {args.limit} æª”")

    # é–‹å§‹åŒæ­¥
    try:
        syncer.sync_all(stock_ids, start_date, end_date, smart_mode=smart_mode)
    finally:
        syncer.close()


if __name__ == '__main__':
    main()
