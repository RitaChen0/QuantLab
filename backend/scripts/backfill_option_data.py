#!/usr/bin/env python
"""
é¸æ“‡æ¬Šæ­·å²è³‡æ–™å›è£œè…³æœ¬

ä½¿ç”¨ Shioaji API å›è£œé¸æ“‡æ¬Šæ­·å²è³‡æ–™ï¼š
1. ç²å–é¸æ“‡æ¬Šåˆç´„åˆ—è¡¨
2. å°æ¯å€‹åˆç´„æŸ¥è©¢æ­·å²æ—¥ç·šè³‡æ–™
3. è¨ˆç®—æ¯æ—¥å› å­ï¼ˆPCR, ATM IV, Greeksï¼‰
4. å„²å­˜åˆ° option_daily_factors è¡¨

ä½¿ç”¨æ–¹å¼ï¼š
    python scripts/backfill_option_data.py --start-date 2024-12-01 --end-date 2025-12-15
    python scripts/backfill_option_data.py --days-back 30  # å›è£œæœ€è¿‘ 30 å¤©
"""

import sys
import argparse
from datetime import date, datetime, timedelta
from typing import List, Optional
from loguru import logger
from decimal import Decimal

# æ·»åŠ  app ç›®éŒ„åˆ°è·¯å¾‘
sys.path.insert(0, '/app')

from app.db.session import SessionLocal
from app.services.shioaji_client import ShioajiClient
from app.services.option_calculator import OptionFactorCalculator
from app.repositories.option import (
    OptionDailyFactorRepository,
    OptionSyncConfigRepository,
    OptionContractRepository
)
from app.schemas.option import OptionDailyFactorCreate, OptionContractCreate


def generate_date_range(start_date: date, end_date: date) -> List[date]:
    """
    ç”Ÿæˆæ—¥æœŸç¯„åœï¼ˆæ’é™¤é€±æœ«ï¼‰

    Args:
        start_date: é–‹å§‹æ—¥æœŸ
        end_date: çµæŸæ—¥æœŸ

    Returns:
        æ—¥æœŸåˆ—è¡¨ï¼ˆåƒ…äº¤æ˜“æ—¥ï¼‰
    """
    dates = []
    current = start_date
    while current <= end_date:
        # æ’é™¤é€±æœ«ï¼ˆ0=é€±ä¸€, 6=é€±æ—¥ï¼‰
        if current.weekday() < 5:
            dates.append(current)
        current += timedelta(days=1)
    return dates


def get_option_contracts_for_date(
    api,
    underlying: str,
    target_date: date
) -> List:
    """
    ç²å–ç‰¹å®šæ—¥æœŸå­˜åœ¨çš„é¸æ“‡æ¬Šåˆç´„

    Args:
        api: Shioaji API å¯¦ä¾‹
        underlying: æ¨™çš„ä»£ç¢¼ï¼ˆTX, MTXï¼‰
        target_date: ç›®æ¨™æ—¥æœŸ

    Returns:
        åˆç´„åˆ—è¡¨
    """
    try:
        # ç²å–æ‰€æœ‰åˆç´„
        if underlying == 'TX':
            option_contracts_obj = api.Contracts.Options.TXO
        elif underlying == 'MTX':
            if hasattr(api.Contracts.Options, 'MXO'):
                option_contracts_obj = api.Contracts.Options.MXO
            else:
                logger.warning("[BACKFILL] MTX options not available")
                return []
        else:
            logger.error(f"[BACKFILL] Unsupported underlying: {underlying}")
            return []

        # ä½¿ç”¨è¿­ä»£å™¨é¿å…ä¸€æ¬¡æ€§åŠ è¼‰æ‰€æœ‰åˆç´„ï¼ˆå¯èƒ½å°è‡´é˜»å¡ï¼‰
        import time

        active_contracts = []
        total_scanned = 0
        max_contracts = 2000  # å®‰å…¨ä¸Šé™ï¼Œé¿å…ç„¡é™å¾ªç’°

        # ç›´æ¥è¿­ä»£ï¼Œé¿å… list() è½‰æ›
        for contract in option_contracts_obj:
            total_scanned += 1

            # å®‰å…¨ä¸Šé™æª¢æŸ¥
            if total_scanned > max_contracts:
                logger.warning(
                    f"[BACKFILL] Reached max contracts limit ({max_contracts}), "
                    f"stopping scan"
                )
                break

            # æ¯ 100 å€‹åˆç´„æ·»åŠ çŸ­æš«å»¶é²ï¼Œé¿å…éå¿«
            if total_scanned % 100 == 0:
                time.sleep(0.05)

            if hasattr(contract, 'delivery_date'):
                # æª¢æŸ¥åˆ°æœŸæ—¥
                if isinstance(contract.delivery_date, str):
                    expiry = datetime.strptime(contract.delivery_date, "%Y/%m/%d").date()
                else:
                    expiry = contract.delivery_date

                # åˆç´„åœ¨ target_date æ™‚ä»ç„¶æœ‰æ•ˆ
                if expiry >= target_date:
                    active_contracts.append(contract)

        logger.info(
            f"[BACKFILL] Found {len(active_contracts)}/{total_scanned} "
            f"active contracts for {underlying} on {target_date}"
        )
        return active_contracts

    except Exception as e:
        logger.error(f"[BACKFILL] Error getting contracts: {str(e)}")
        return []


def fetch_contract_daily_data(
    api,
    contract,
    target_date: date,
    retry_count: int = 2,
    retry_delay: float = 1.0
) -> Optional[dict]:
    """
    ç²å–åˆç´„åœ¨ç‰¹å®šæ—¥æœŸçš„æ—¥ç·šè³‡æ–™ï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰

    Args:
        api: Shioaji API å¯¦ä¾‹
        contract: åˆç´„ç‰©ä»¶
        target_date: ç›®æ¨™æ—¥æœŸ
        retry_count: é‡è©¦æ¬¡æ•¸
        retry_delay: é‡è©¦å»¶é²ï¼ˆç§’ï¼‰

    Returns:
        åƒ¹æ ¼æ•¸æ“šå­—å…¸ï¼Œå¤±æ•—è¿”å› None
    """
    import time

    for attempt in range(retry_count + 1):
        try:
            # ä½¿ç”¨ kbars ç²å–æ­·å²è³‡æ–™ï¼ˆShioaji API è¿”å›åˆ†é˜ç·šï¼‰
            # æŸ¥è©¢ç•¶å¤©çš„æ•¸æ“š
            kbars = api.kbars(
                contract=contract,
                start=target_date.strftime('%Y-%m-%d'),
                end=target_date.strftime('%Y-%m-%d'),
                timeout=30000
            )

            if not kbars or not hasattr(kbars, 'ts') or len(kbars.ts) == 0:
                return None

            # å–ç•¶å¤©çš„æœ€å¾Œä¸€æ ¹ K ç·šï¼ˆæ”¶ç›¤æ•¸æ“šï¼‰
            last_index = -1

            data = {
                'contract_id': contract.code,
                'close': float(kbars.Close[last_index]),
                'open': float(kbars.Open[last_index]),
                'high': float(kbars.High[last_index]),
                'low': float(kbars.Low[last_index]),
                'volume': int(kbars.Volume[last_index]),
            }

            return data

        except Exception as e:
            if attempt < retry_count:
                # é‡è©¦å‰å»¶é²
                logger.debug(
                    f"[BACKFILL] Retry {attempt + 1}/{retry_count} for {contract.code} "
                    f"after {retry_delay}s: {str(e)[:100]}"
                )
                time.sleep(retry_delay)
            else:
                # æœ€å¾Œä¸€æ¬¡å¤±æ•—ï¼Œåªè¨˜éŒ„ DEBUG ç´šåˆ¥
                logger.debug(f"[BACKFILL] Failed to fetch data for {contract.code}: {str(e)[:150]}")
                return None

    return None


def validate_contract_data(data: dict, contract_code: str) -> bool:
    """
    é©—è­‰åˆç´„æ•¸æ“šåˆç†æ€§

    Args:
        data: åˆç´„åƒ¹æ ¼æ•¸æ“š
        contract_code: åˆç´„ä»£ç¢¼ï¼ˆç”¨æ–¼æ—¥èªŒï¼‰

    Returns:
        True å¦‚æœæ•¸æ“šæœ‰æ•ˆï¼ŒFalse å¦‚æœç™¼ç¾ç•°å¸¸
    """
    try:
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_fields = ['close', 'open', 'high', 'low', 'volume']
        for field in required_fields:
            if field not in data:
                logger.warning(f"[VALIDATE] âŒ Missing field '{field}' for {contract_code}")
                return False

        close = data['close']
        open_price = data['open']
        high = data['high']
        low = data['low']
        volume = data['volume']

        # 1. åƒ¹æ ¼å¿…é ˆç‚ºæ­£
        if close <= 0:
            logger.warning(f"[VALIDATE] âŒ Invalid close price ({close}) for {contract_code}")
            return False

        if open_price <= 0:
            logger.warning(f"[VALIDATE] âŒ Invalid open price ({open_price}) for {contract_code}")
            return False

        if high <= 0:
            logger.warning(f"[VALIDATE] âŒ Invalid high price ({high}) for {contract_code}")
            return False

        if low <= 0:
            logger.warning(f"[VALIDATE] âŒ Invalid low price ({low}) for {contract_code}")
            return False

        # 2. OHLC é—œä¿‚å¿…é ˆåˆç†ï¼ˆlow <= open/close/high <= highï¼‰
        if not (low <= close <= high):
            logger.warning(
                f"[VALIDATE] âŒ Invalid OHLC relationship: "
                f"low={low}, close={close}, high={high} for {contract_code}"
            )
            return False

        if not (low <= open_price <= high):
            logger.warning(
                f"[VALIDATE] âŒ Invalid OHLC relationship: "
                f"low={low}, open={open_price}, high={high} for {contract_code}"
            )
            return False

        if low > high:
            logger.warning(
                f"[VALIDATE] âŒ Low > High: low={low}, high={high} for {contract_code}"
            )
            return False

        # 3. æˆäº¤é‡ä¸èƒ½ç‚ºè² 
        if volume < 0:
            logger.warning(f"[VALIDATE] âŒ Negative volume ({volume}) for {contract_code}")
            return False

        # 4. æª¢æŸ¥åƒ¹æ ¼æ˜¯å¦ç•°å¸¸ï¼ˆä¾‹å¦‚ close = 999999 é€™ç¨®æ˜é¡¯éŒ¯èª¤ï¼‰
        if close > 100000 or open_price > 100000 or high > 100000:
            logger.warning(
                f"[VALIDATE] âŒ Suspiciously high price detected for {contract_code}: "
                f"close={close}, open={open_price}, high={high}"
            )
            return False

        # 5. æª¢æŸ¥åƒ¹æ ¼ç¯„åœæ˜¯å¦åˆç†ï¼ˆhigh-low ä¸æ‡‰è©²è¶…é close çš„ 50%ï¼‰
        if high - low > close * 0.5:
            logger.warning(
                f"[VALIDATE] âš ï¸  Large price range detected for {contract_code}: "
                f"range={high-low}, close={close}"
            )
            # é€™ä¸æ˜¯è‡´å‘½éŒ¯èª¤ï¼Œåªè¨˜éŒ„è­¦å‘Šä½†ä»ç„¶è¿”å› True

        return True

    except Exception as e:
        logger.error(f"[VALIDATE] âŒ Validation error for {contract_code}: {str(e)}")
        return False


def backfill_option_factors(
    underlying: str,
    start_date: date,
    end_date: date,
    dry_run: bool = False
):
    """
    å›è£œé¸æ“‡æ¬Šå› å­æ•¸æ“š

    Args:
        underlying: æ¨™çš„ä»£ç¢¼ï¼ˆTX, MTXï¼‰
        start_date: é–‹å§‹æ—¥æœŸ
        end_date: çµæŸæ—¥æœŸ
        dry_run: æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼ï¼ˆä¸å¯«å…¥è³‡æ–™åº«ï¼‰
    """
    logger.info(f"[BACKFILL] ğŸš€ Starting option data backfill for {underlying}")
    logger.info(f"[BACKFILL] ğŸ“… Date range: {start_date} to {end_date}")
    logger.info(f"[BACKFILL] ğŸ§ª Dry run: {dry_run}")

    # ç”Ÿæˆæ—¥æœŸç¯„åœ
    dates = generate_date_range(start_date, end_date)
    logger.info(f"[BACKFILL] ğŸ“Š Total trading days: {len(dates)}")

    # åˆå§‹åŒ–è³‡æ–™åº«ï¼ˆä½¿ç”¨ psycopg2 é¿é–‹ ORM æ˜ å°„å•é¡Œï¼‰
    import psycopg2
    from urllib.parse import urlparse
    from app.core.config import settings

    # å®‰å…¨è§£æè³‡æ–™åº«é€£ç·šå­—ä¸²
    db_url = settings.DATABASE_URL.replace('+psycopg2', '')
    parsed = urlparse(db_url)

    conn = psycopg2.connect(
        host=parsed.hostname,
        port=parsed.port or 5432,
        database=parsed.path.lstrip('/'),
        user=parsed.username,
        password=parsed.password
    )
    cur = conn.cursor()

    # åˆå§‹åŒ– Shioaji å®¢æˆ¶ç«¯
    with ShioajiClient() as shioaji:
        if not shioaji.is_available():
            logger.error("[BACKFILL] âŒ Shioaji client not available")
            return

        api = shioaji._api

        # çµ±è¨ˆ
        stats = {
            'total_days': len(dates),
            'days_processed': 0,
            'days_success': 0,
            'days_failed': 0,
            'total_contracts': 0,
            'contracts_fetched': 0,
            'factors_saved': 0
        }

        # é€æ—¥å›è£œ
        for i, target_date in enumerate(dates, 1):
            try:
                logger.info(
                    f"[BACKFILL] ğŸ“… Processing {target_date} "
                    f"({i}/{len(dates)}, {i/len(dates)*100:.1f}%)"
                )

                # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆä½¿ç”¨ SQLï¼‰
                cur.execute(
                    "SELECT 1 FROM option_daily_factors WHERE underlying_id = %s AND date = %s",
                    (underlying, target_date)
                )
                if cur.fetchone() and not dry_run:
                    logger.info(f"[BACKFILL] â­ï¸  Data already exists for {target_date}, skipping")
                    stats['days_processed'] += 1
                    continue

                # ç²å–ç•¶å¤©çš„åˆç´„åˆ—è¡¨
                contracts = get_option_contracts_for_date(api, underlying, target_date)
                if not contracts:
                    logger.warning(f"[BACKFILL] âš ï¸  No contracts for {target_date}")
                    stats['days_failed'] += 1
                    stats['days_processed'] += 1
                    continue

                stats['total_contracts'] += len(contracts)

                # ç²å–æ¯å€‹åˆç´„çš„åƒ¹æ ¼æ•¸æ“šï¼ˆåˆ†æ‰¹è™•ç†ï¼Œé¿å…é€Ÿç‡é™åˆ¶ï¼‰
                import time

                contract_data = []
                batch_size = 50  # æ¯æ‰¹è™•ç† 50 å€‹åˆç´„
                batch_delay = 2.0  # æ¯æ‰¹ä¹‹é–“å»¶é² 2 ç§’
                request_delay = 0.1  # æ¯å€‹è«‹æ±‚ä¹‹é–“å»¶é² 0.1 ç§’

                for i, contract in enumerate(contracts):
                    # æ¯æ‰¹ä¹‹é–“æ·»åŠ å»¶é²
                    if i > 0 and i % batch_size == 0:
                        logger.info(
                            f"[BACKFILL] ğŸ’¤ Batch {i // batch_size} completed, "
                            f"sleeping {batch_delay}s to avoid rate limit..."
                        )
                        time.sleep(batch_delay)

                    # ç²å–åˆç´„æ•¸æ“š
                    data = fetch_contract_daily_data(api, contract, target_date)
                    if data:
                        # é©—è­‰æ•¸æ“šåˆç†æ€§
                        if not validate_contract_data(data, contract.code):
                            logger.warning(
                                f"[BACKFILL] âš ï¸  Skipping invalid data for {contract.code}"
                            )
                            continue

                        # è£œå……åˆç´„è³‡è¨Š
                        # ç¢ºä¿ expiry_date æ˜¯ date ç‰©ä»¶è€Œéå­—ä¸²
                        if isinstance(contract.delivery_date, str):
                            expiry_date = datetime.strptime(contract.delivery_date, "%Y/%m/%d").date()
                        else:
                            expiry_date = contract.delivery_date

                        data.update({
                            'underlying_id': underlying,
                            'underlying_type': 'FUTURES',
                            'option_type': 'CALL' if 'C' in contract.code else 'PUT',
                            'strike_price': float(contract.strike_price),
                            'expiry_date': expiry_date
                        })
                        contract_data.append(data)
                        stats['contracts_fetched'] += 1

                    # æ¯å€‹è«‹æ±‚ä¹‹é–“æ·»åŠ å°å»¶é²
                    if i < len(contracts) - 1:
                        time.sleep(request_delay)

                if not contract_data:
                    logger.warning(
                        f"[BACKFILL] âš ï¸  No data fetched for {target_date} "
                        f"(tried {len(contracts)} contracts)"
                    )
                    stats['days_failed'] += 1
                    stats['days_processed'] += 1
                    continue

                logger.info(
                    f"[BACKFILL] âœ… Fetched {len(contract_data)}/{len(contracts)} contracts "
                    f"({len(contract_data)/len(contracts)*100:.1f}%)"
                )

                # è¨ˆç®—å› å­ï¼ˆç›´æ¥ä½¿ç”¨å·²ç²å–çš„æ•¸æ“šï¼‰
                import pandas as pd
                option_chain = pd.DataFrame(contract_data)

                # ä½¿ç”¨ OptionFactorCalculator çš„å…§éƒ¨æ–¹æ³•è¨ˆç®—å› å­
                calculator = OptionFactorCalculator(None, None)

                # æ‰‹å‹•è¨ˆç®—éšæ®µä¸€å› å­
                factors = {}
                factors.update(calculator._calculate_pcr(option_chain))
                factors.update(calculator._calculate_atm_iv(option_chain))

                # éšæ®µä¸‰ï¼šGreeks æ‘˜è¦ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
                try:
                    cur.execute("SELECT value FROM option_sync_config WHERE key = 'stage'")
                    stage_row = cur.fetchone()
                    stage = int(stage_row[0]) if stage_row else 1
                    if stage >= 3:
                        factors.update(calculator._calculate_greeks_summary(option_chain))
                except Exception as e:
                    logger.debug(f"[BACKFILL] Greeks calculation skipped: {str(e)}")

                # æ·»åŠ ç‰ˆæœ¬å’Œå“è³ªè©•åˆ†
                factors['calculation_version'] = calculator.VERSION
                factors['data_quality_score'] = calculator._assess_quality(factors, option_chain)

                # å„²å­˜åˆ°è³‡æ–™åº«ï¼ˆä½¿ç”¨ SQLï¼‰
                if not dry_run:
                    try:
                        # æº–å‚™æ’å…¥/æ›´æ–°æ•¸æ“š
                        pcr_volume = factors.get('pcr_volume')
                        pcr_open_interest = factors.get('pcr_open_interest')
                        atm_iv = factors.get('atm_iv')
                        avg_call_delta = factors.get('avg_call_delta')
                        avg_put_delta = factors.get('avg_put_delta')
                        gamma_exposure = factors.get('gamma_exposure')
                        vanna_exposure = factors.get('vanna_exposure')
                        quality_score = factors.get('data_quality_score')
                        version = factors.get('calculation_version')

                        # Upsert æ“ä½œ
                        cur.execute("""
                            INSERT INTO option_daily_factors (
                                underlying_id, date,
                                pcr_volume, pcr_open_interest, atm_iv,
                                avg_call_delta, avg_put_delta, gamma_exposure, vanna_exposure,
                                data_quality_score, calculation_version,
                                created_at
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
                            ON CONFLICT (underlying_id, date)
                            DO UPDATE SET
                                pcr_volume = EXCLUDED.pcr_volume,
                                pcr_open_interest = EXCLUDED.pcr_open_interest,
                                atm_iv = EXCLUDED.atm_iv,
                                avg_call_delta = EXCLUDED.avg_call_delta,
                                avg_put_delta = EXCLUDED.avg_put_delta,
                                gamma_exposure = EXCLUDED.gamma_exposure,
                                vanna_exposure = EXCLUDED.vanna_exposure,
                                data_quality_score = EXCLUDED.data_quality_score,
                                calculation_version = EXCLUDED.calculation_version
                        """, (
                            underlying, target_date,
                            pcr_volume, pcr_open_interest, atm_iv,
                            avg_call_delta, avg_put_delta, gamma_exposure, vanna_exposure,
                            quality_score, version
                        ))
                        conn.commit()

                        stats['factors_saved'] += 1
                        stats['days_success'] += 1
                        logger.info(
                            f"[BACKFILL] ğŸ’¾ Saved factors for {target_date}: "
                            f"PCR={pcr_volume}, ATM_IV={atm_iv}, Quality={quality_score}"
                        )

                    except Exception as e:
                        conn.rollback()
                        logger.error(
                            f"[BACKFILL] âŒ Error saving factors for {target_date}: {str(e)}"
                        )
                        stats['days_failed'] += 1
                else:
                    # Dry run: åªé¡¯ç¤ºçµæœ
                    logger.info(
                        f"[BACKFILL] ğŸ§ª [DRY RUN] Would save: "
                        f"PCR={factors.get('pcr_volume')}, "
                        f"ATM_IV={factors.get('atm_iv')}, "
                        f"Quality={factors.get('data_quality_score')}"
                    )
                    stats['days_success'] += 1

                stats['days_processed'] += 1

            except Exception as e:
                logger.error(
                    f"[BACKFILL] âŒ Error processing {target_date}: {str(e)}",
                    exc_info=True
                )
                stats['days_failed'] += 1
                stats['days_processed'] += 1

    # é—œé–‰è³‡æ–™åº«
    cur.close()
    conn.close()

    # è¼¸å‡ºçµ±è¨ˆ
    logger.info("=" * 60)
    logger.info("[BACKFILL] ğŸ Backfill completed!")
    logger.info("=" * 60)
    logger.info(f"Days processed: {stats['days_processed']}/{stats['total_days']}")
    logger.info(f"Days success: {stats['days_success']}")
    logger.info(f"Days failed: {stats['days_failed']}")
    logger.info(f"Contracts total: {stats['total_contracts']}")
    logger.info(f"Contracts fetched: {stats['contracts_fetched']}")
    logger.info(f"Factors saved: {stats['factors_saved']}")

    if stats['total_contracts'] > 0:
        fetch_rate = stats['contracts_fetched'] / stats['total_contracts'] * 100
        logger.info(f"Fetch success rate: {fetch_rate:.1f}%")

    success_rate = stats['days_success'] / stats['total_days'] * 100 if stats['total_days'] > 0 else 0
    logger.info(f"Overall success rate: {success_rate:.1f}%")


def main():
    parser = argparse.ArgumentParser(description='é¸æ“‡æ¬Šæ­·å²è³‡æ–™å›è£œ')
    parser.add_argument(
        '--underlying',
        type=str,
        default='TX',
        choices=['TX', 'MTX'],
        help='æ¨™çš„ä»£ç¢¼ï¼ˆé è¨­: TXï¼‰'
    )
    parser.add_argument(
        '--start-date',
        type=str,
        help='é–‹å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰'
    )
    parser.add_argument(
        '--end-date',
        type=str,
        help='çµæŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼Œé è¨­: ä»Šå¤©ï¼‰'
    )
    parser.add_argument(
        '--days-back',
        type=int,
        help='å›è£œæœ€è¿‘ N å¤©ï¼ˆæ›¿ä»£ start-dateï¼‰'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='æ¸¬è©¦æ¨¡å¼ï¼ˆä¸å¯«å…¥è³‡æ–™åº«ï¼‰'
    )

    args = parser.parse_args()

    # è§£ææ—¥æœŸ
    if args.days_back:
        end_date = date.today()
        start_date = end_date - timedelta(days=args.days_back)
    elif args.start_date:
        start_date = datetime.strptime(args.start_date, '%Y-%m-%d').date()
        if args.end_date:
            end_date = datetime.strptime(args.end_date, '%Y-%m-%d').date()
        else:
            end_date = date.today()
    else:
        # é è¨­ï¼šå›è£œæœ€è¿‘ 7 å¤©
        end_date = date.today()
        start_date = end_date - timedelta(days=7)
        logger.warning("[BACKFILL] No date specified, defaulting to last 7 days")

    # åŸ·è¡Œå›è£œ
    backfill_option_factors(
        underlying=args.underlying,
        start_date=start_date,
        end_date=end_date,
        dry_run=args.dry_run
    )


if __name__ == '__main__':
    main()
