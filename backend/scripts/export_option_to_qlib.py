#!/usr/bin/env python3
"""
å°‡é¸æ“‡æ¬Šå› å­åŒ¯å‡ºåˆ° Qlib æ ¼å¼

æ”¯æ´ä¸‰éšæ®µæ¼”é€²å¼åŒ¯å‡ºï¼š
- éšæ®µä¸€ï¼š3 å€‹å› å­ï¼ˆpcr, pcr_oi, atm_ivï¼‰
- éšæ®µäºŒï¼š+5 å€‹å› å­ï¼ˆiv_skew, max_pain ç­‰ï¼‰
- éšæ®µä¸‰ï¼š+10 å€‹å› å­ï¼ˆGreeks ç›¸é—œï¼‰

ç›®éŒ„çµæ§‹ï¼š
    <output_dir>/
    â”œâ”€â”€ calendars/
    â”‚   â””â”€â”€ day.txt                     # äº¤æ˜“æ—¥æ›†
    â””â”€â”€ features/
        â””â”€â”€ <instrument>/                # è‚¡ç¥¨ç›®éŒ„ï¼ˆå¦‚ 2330ï¼‰
            â”œâ”€â”€ pcr.day.bin             # éšæ®µä¸€å› å­
            â”œâ”€â”€ pcr_oi.day.bin
            â”œâ”€â”€ atm_iv.day.bin
            â”œâ”€â”€ iv_skew.day.bin         # éšæ®µäºŒå› å­
            â””â”€â”€ gamma_exp.day.bin       # éšæ®µä¸‰å› å­

ä½¿ç”¨æ–¹å¼ï¼š
    # åŒ¯å‡ºæ‰€æœ‰éšæ®µä¸€å› å­ï¼ˆæ™ºæ…§å¢é‡ï¼‰
    python export_option_to_qlib.py --output-dir /data/qlib/tw_stock_v2 --smart

    # å®Œæ•´é‡æ–°åŒ¯å‡º
    python export_option_to_qlib.py --output-dir /data/qlib/tw_stock_v2

    # æ¸¬è©¦æ¨¡å¼ï¼ˆåƒ… TXï¼‰
    python export_option_to_qlib.py --output-dir /data/qlib/tw_stock_v2 --test
"""

import sys
import os
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import argparse
from datetime import datetime, date, timedelta
from typing import List, Optional, Tuple
import pandas as pd
import numpy as np
from loguru import logger

from sqlalchemy import create_engine, text
from app.core.config import settings

# Qlib imports
import qlib
from qlib.config import REG_CN
from qlib.data.storage.file_storage import FileFeatureStorage
from qlib.data import D

# éšæ®µä¸€å› å­æ˜ å°„
STAGE1_FACTORS = {
    'pcr_volume': 'pcr',           # Put/Call Ratio (æˆäº¤é‡)
    'pcr_open_interest': 'pcr_oi', # Put/Call Ratio (æœªå¹³å€‰é‡)
    'atm_iv': 'atm_iv',            # ATM éš±å«æ³¢å‹•ç‡
}

# éšæ®µäºŒå› å­æ˜ å°„ï¼ˆé ç•™ï¼‰
STAGE2_FACTORS = {
    'iv_skew': 'iv_skew',
    'max_pain_strike': 'max_pain',
    'total_call_oi': 'call_oi',
    'total_put_oi': 'put_oi',
}

# éšæ®µä¸‰å› å­æ˜ å°„ï¼ˆé ç•™ï¼‰
STAGE3_FACTORS = {
    'gamma_exposure': 'gamma_exp',
    'vanna_exposure': 'vanna_exp',
    'avg_call_delta': 'call_delta',
    'avg_put_delta': 'put_delta',
}


def get_db_engine():
    """å»ºç«‹è³‡æ–™åº«é€£æ¥"""
    return create_engine(settings.DATABASE_URL)


def get_current_stage(engine) -> int:
    """ç²å–ç•¶å‰éšæ®µ"""
    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT value FROM option_sync_config WHERE key = 'stage'
        """))
        row = result.fetchone()
        return int(row[0]) if row else 1


def get_enabled_underlyings(engine) -> List[str]:
    """ç²å–å•Ÿç”¨çš„æ¨™çš„ç‰©åˆ—è¡¨"""
    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT value FROM option_sync_config WHERE key = 'enabled_underlyings'
        """))
        row = result.fetchone()
        if row and row[0]:
            return [s.strip() for s in row[0].split(',')]
        return []


def get_available_factors(stage: int) -> dict:
    """
    ç²å–ç•¶å‰éšæ®µå¯ç”¨çš„å› å­

    Args:
        stage: éšæ®µè™Ÿï¼ˆ1/2/3ï¼‰

    Returns:
        å› å­æ˜ å°„å­—å…¸
    """
    factors = {}

    if stage >= 1:
        factors.update(STAGE1_FACTORS)

    if stage >= 2:
        factors.update(STAGE2_FACTORS)

    if stage >= 3:
        factors.update(STAGE3_FACTORS)

    return factors


def get_factor_data(
    engine,
    underlying_id: str,
    factor_name: str,
    start_date: Optional[date] = None,
    end_date: Optional[date] = None
) -> pd.DataFrame:
    """
    å¾è³‡æ–™åº«ç²å–å› å­æ•¸æ“š

    Args:
        engine: è³‡æ–™åº«å¼•æ“
        underlying_id: æ¨™çš„ä»£ç¢¼
        factor_name: å› å­åç¨±ï¼ˆè³‡æ–™åº«æ¬„ä½åï¼‰
        start_date: é–‹å§‹æ—¥æœŸ
        end_date: çµæŸæ—¥æœŸ

    Returns:
        DataFrame with columns: [date, value]
    """
    query = f"""
        SELECT date, {factor_name}
        FROM option_daily_factors
        WHERE underlying_id = :underlying_id
          AND {factor_name} IS NOT NULL
    """

    params = {'underlying_id': underlying_id}

    if start_date:
        query += " AND date >= :start_date"
        params['start_date'] = start_date

    if end_date:
        query += " AND date <= :end_date"
        params['end_date'] = end_date

    query += " ORDER BY date ASC"

    with engine.connect() as conn:
        df = pd.read_sql(text(query), conn, params=params)

    if df.empty:
        return pd.DataFrame(columns=['date', 'value'])

    df = df.rename(columns={factor_name: 'value'})
    df['date'] = pd.to_datetime(df['date'])

    return df


def get_qlib_last_date(underlying_id: str, factor_field: str) -> Optional[date]:
    """
    ç²å– Qlib å·²æœ‰æ•¸æ“šçš„æœ€å¾Œæ—¥æœŸ

    Args:
        underlying_id: æ¨™çš„ä»£ç¢¼
        factor_field: Qlib å› å­åç¨±ï¼ˆå¦‚ '$pcr'ï¼‰

    Returns:
        æœ€å¾Œæ—¥æœŸæˆ– None
    """
    try:
        df = D.features([underlying_id], [factor_field], freq='day')

        if df is None or df.empty:
            return None

        last_datetime = df.index.get_level_values('datetime').max()
        return last_datetime.date()
    except Exception:
        return None


def determine_sync_range(
    engine,
    underlying_id: str,
    factor_name: str,
    factor_field: str,
    smart_mode: bool = False
) -> Tuple[Optional[date], Optional[date], str]:
    """
    æ™ºæ…§åˆ¤æ–·éœ€è¦åŒæ­¥çš„æ—¥æœŸç¯„åœ

    Args:
        engine: è³‡æ–™åº«å¼•æ“
        underlying_id: æ¨™çš„ä»£ç¢¼
        factor_name: è³‡æ–™åº«æ¬„ä½å
        factor_field: Qlib å› å­å
        smart_mode: æ˜¯å¦ä½¿ç”¨æ™ºæ…§æ¨¡å¼

    Returns:
        (é–‹å§‹æ—¥æœŸ, çµæŸæ—¥æœŸ, åŒæ­¥é¡å‹)
    """
    # ç²å–è³‡æ–™åº«æ—¥æœŸç¯„åœ
    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT MIN(date) as min_date, MAX(date) as max_date
            FROM option_daily_factors
            WHERE underlying_id = :underlying_id
              AND {factor_name} IS NOT NULL
        """.format(factor_name=factor_name)), {"underlying_id": underlying_id})
        row = result.fetchone()

        if not row or not row[0]:
            logger.warning(f"[QLIB] No data for {underlying_id} - {factor_name}")
            return (None, None, 'skip')

        db_min_date = row[0]
        db_max_date = row[1]

    if not smart_mode:
        # å®Œæ•´é‡æ–°åŒ¯å‡º
        return (db_min_date, db_max_date, 'full')

    # æ™ºæ…§æ¨¡å¼ï¼šæª¢æŸ¥ Qlib æœ€å¾Œæ—¥æœŸ
    qlib_last_date = get_qlib_last_date(underlying_id, f'${factor_field}')

    if qlib_last_date is None:
        # Qlib ç„¡æ•¸æ“šï¼Œå®Œæ•´åŒ¯å‡º
        logger.info(f"[QLIB] {underlying_id} - {factor_field}: é¦–æ¬¡åŒ¯å‡º")
        return (db_min_date, db_max_date, 'full')

    if qlib_last_date >= db_max_date:
        # Qlib å·²æ˜¯æœ€æ–°
        logger.info(f"[QLIB] {underlying_id} - {factor_field}: å·²æ˜¯æœ€æ–° ({qlib_last_date})")
        return (None, None, 'skip')

    # å¢é‡åŒ¯å‡º
    start_date = qlib_last_date + timedelta(days=1)
    logger.info(
        f"[QLIB] {underlying_id} - {factor_field}: "
        f"å¢é‡åŒ¯å‡º {start_date} -> {db_max_date}"
    )
    return (start_date, db_max_date, 'incremental')


def write_qlib_feature(
    instrument: str,
    field: str,
    freq: str,
    data: np.ndarray,
    dates: pd.DatetimeIndex
) -> bool:
    """
    å¯«å…¥ Qlib ç‰¹å¾µ

    Args:
        instrument: è‚¡ç¥¨ä»£ç¢¼
        field: ç‰¹å¾µåç¨±
        freq: é »ç‡ï¼ˆ'day'ï¼‰
        data: numpy array
        dates: æ—¥æœŸç´¢å¼•

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        storage = FileFeatureStorage(
            instrument=instrument,
            field=field,
            freq=freq
        )

        # ç¢ºä¿æ•¸æ“šé¡å‹æ­£ç¢º
        data = np.asarray(data, dtype=np.float32)

        storage.write(data, index=dates)
        return True

    except Exception as e:
        logger.error(f"[QLIB] Failed to write {instrument}/{field}: {str(e)}")
        return False


def export_factor(
    engine,
    underlying_id: str,
    factor_name: str,
    factor_field: str,
    smart_mode: bool = False
) -> bool:
    """
    åŒ¯å‡ºå–®ä¸€å› å­

    Args:
        engine: è³‡æ–™åº«å¼•æ“
        underlying_id: æ¨™çš„ä»£ç¢¼
        factor_name: è³‡æ–™åº«æ¬„ä½å
        factor_field: Qlib å› å­å
        smart_mode: æ™ºæ…§å¢é‡æ¨¡å¼

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    # åˆ¤æ–·åŒæ­¥ç¯„åœ
    start_date, end_date, sync_type = determine_sync_range(
        engine,
        underlying_id,
        factor_name,
        factor_field,
        smart_mode
    )

    if sync_type == 'skip':
        return True

    # ç²å–å› å­æ•¸æ“š
    df = get_factor_data(engine, underlying_id, factor_name, start_date, end_date)

    if df.empty:
        logger.warning(f"[QLIB] No data to export for {underlying_id} - {factor_field}")
        return False

    # è½‰æ›ç‚º numpy array
    dates = pd.DatetimeIndex(df['date'])
    values = df['value'].values.astype(np.float32)

    # å¯«å…¥ Qlib
    success = write_qlib_feature(
        instrument=underlying_id,
        field=factor_field,
        freq='day',
        data=values,
        dates=dates
    )

    if success:
        logger.info(
            f"[QLIB] âœ… Exported {underlying_id}/{factor_field}: "
            f"{len(df)} records ({sync_type})"
        )
    else:
        logger.error(f"[QLIB] âŒ Failed to export {underlying_id}/{factor_field}")

    return success


def export_option_factors_to_qlib(
    output_dir: str,
    smart_mode: bool = False,
    test_mode: bool = False
):
    """
    åŒ¯å‡ºé¸æ“‡æ¬Šå› å­åˆ° Qlib

    Args:
        output_dir: Qlib è³‡æ–™ç›®éŒ„
        smart_mode: æ™ºæ…§å¢é‡æ¨¡å¼
        test_mode: æ¸¬è©¦æ¨¡å¼ï¼ˆåƒ… TXï¼‰
    """
    logger.info("=" * 60)
    logger.info("é¸æ“‡æ¬Šå› å­åŒ¯å‡ºåˆ° Qlib")
    logger.info("=" * 60)

    # åˆå§‹åŒ– Qlib
    qlib.init(provider_uri=output_dir, region=REG_CN)
    logger.info(f"[QLIB] Initialized: {output_dir}")

    # ç²å–è³‡æ–™åº«é€£æ¥
    engine = get_db_engine()

    # ç²å–ç•¶å‰éšæ®µ
    stage = get_current_stage(engine)
    logger.info(f"[QLIB] Current stage: {stage}")

    # ç²å–å¯ç”¨å› å­
    factors = get_available_factors(stage)
    logger.info(f"[QLIB] Available factors: {list(factors.values())}")

    # ç²å–æ¨™çš„ç‰©åˆ—è¡¨
    if test_mode:
        underlyings = ['TX']
        logger.info("[QLIB] Test mode: only TX")
    else:
        underlyings = get_enabled_underlyings(engine)
        if not underlyings:
            underlyings = ['TX', 'MTX']
        logger.info(f"[QLIB] Underlyings: {underlyings}")

    # çµ±è¨ˆ
    stats = {
        'total_underlyings': len(underlyings),
        'total_factors': len(factors),
        'success_count': 0,
        'error_count': 0,
        'skip_count': 0,
    }

    # é€å€‹æ¨™çš„ç‰©åŒ¯å‡º
    for underlying_id in underlyings:
        logger.info(f"\n[QLIB] Processing {underlying_id}...")

        for db_field, qlib_field in factors.items():
            try:
                success = export_factor(
                    engine,
                    underlying_id,
                    db_field,
                    qlib_field,
                    smart_mode
                )

                if success:
                    stats['success_count'] += 1
                else:
                    stats['skip_count'] += 1

            except Exception as e:
                logger.error(
                    f"[QLIB] Error exporting {underlying_id}/{qlib_field}: {str(e)}"
                )
                stats['error_count'] += 1

    # ç¸½çµ
    logger.info("")
    logger.info("=" * 60)
    logger.info("åŒ¯å‡ºçµæœç¸½çµ")
    logger.info("=" * 60)
    logger.info(f"æ¨™çš„ç‰©æ•¸é‡: {stats['total_underlyings']}")
    logger.info(f"å› å­æ•¸é‡: {stats['total_factors']}")
    logger.info(f"æˆåŠŸåŒ¯å‡º: {stats['success_count']}")
    logger.info(f"è·³é: {stats['skip_count']}")
    logger.info(f"éŒ¯èª¤: {stats['error_count']}")

    total_expected = stats['total_underlyings'] * stats['total_factors']
    success_rate = stats['success_count'] / total_expected * 100 if total_expected > 0 else 0

    logger.info(f"æˆåŠŸç‡: {success_rate:.1f}%")

    if stats['error_count'] == 0:
        logger.info("ğŸ‰ æ‰€æœ‰å› å­åŒ¯å‡ºæˆåŠŸï¼")
    else:
        logger.warning(f"âš ï¸  {stats['error_count']} å€‹å› å­åŒ¯å‡ºå¤±æ•—")


def main():
    parser = argparse.ArgumentParser(description='åŒ¯å‡ºé¸æ“‡æ¬Šå› å­åˆ° Qlib')
    parser.add_argument(
        '--output-dir',
        type=str,
        default='/data/qlib/tw_stock_v2',
        help='Qlib è³‡æ–™ç›®éŒ„ï¼ˆé è¨­: /data/qlib/tw_stock_v2ï¼‰'
    )
    parser.add_argument(
        '--smart',
        action='store_true',
        help='æ™ºæ…§å¢é‡åŒ¯å‡ºï¼ˆåªæ›´æ–°æ–°æ•¸æ“šï¼‰'
    )
    parser.add_argument(
        '--test',
        action='store_true',
        help='æ¸¬è©¦æ¨¡å¼ï¼ˆåƒ… TXï¼‰'
    )

    args = parser.parse_args()

    logger.info(f"Output directory: {args.output_dir}")
    logger.info(f"Smart mode: {args.smart}")
    logger.info(f"Test mode: {args.test}")
    logger.info("")

    export_option_factors_to_qlib(
        output_dir=args.output_dir,
        smart_mode=args.smart,
        test_mode=args.test
    )


if __name__ == '__main__':
    main()
