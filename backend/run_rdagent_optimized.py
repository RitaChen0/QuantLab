#!/usr/bin/env python3
"""
RD-Agent å„ªåŒ–ç‰ˆå› å­æŒ–æ˜

æ”¹é€²é»ï¼š
1. æ›´è©³ç´°çš„ç ”ç©¶ç›®æ¨™æè¿°
2. æ˜ç¢ºè¦æ±‚ Qlib è¡¨é”å¼æ ¼å¼
3. å¢åŠ å› å­æ•¸é‡å’Œè¿­ä»£æ¬¡æ•¸
4. æä¾›å…·é«”ç¯„ä¾‹å¼•å° LLM
"""

import sys
import os
from pathlib import Path
from datetime import datetime

# è¨­ç½®è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent / 'backend'))

from loguru import logger
from sqlalchemy.orm import Session
from app.db.session import SessionLocal
from app.db.base import import_models
from app.services.rdagent_service import RDAgentService
from app.models.rdagent import TaskStatus
from app.schemas.rdagent import FactorMiningRequest

# å°å…¥æ‰€æœ‰æ¨¡å‹ï¼ˆè§£æ±ºé—œä¿‚å¼•ç”¨å•é¡Œï¼‰
import_models()

# é…ç½®æ—¥èªŒ
logger.remove()
logger.add(sys.stdout, format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}", level="INFO")
logger.add(f"/tmp/rdagent_optimized_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log", rotation="500 MB")

logger.info("=" * 80)
logger.info("ğŸ¤– RD-Agent å„ªåŒ–ç‰ˆ LLM å› å­æŒ–æ˜")
logger.info("=" * 80)
logger.info(f"â° é–‹å§‹æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
logger.info(f"ğŸ’¡ å„ªåŒ–é‡é»ï¼šè©³ç´° Prompt + æ›´å¤šå› å­ + Qlib æ ¼å¼")
logger.info("")

# æ­¥é©Ÿ 1ï¼šæª¢æŸ¥ç’°å¢ƒ
logger.info("æ­¥é©Ÿ 1ï¼šæª¢æŸ¥ç’°å¢ƒé…ç½®")
logger.info("-" * 80)

openai_key = os.getenv("OPENAI_API_KEY")
if not openai_key:
    logger.error("âŒ OPENAI_API_KEY æœªè¨­ç½®")
    sys.exit(1)

logger.info(f"âœ… OpenAI API Key: {openai_key[:10]}...{openai_key[-4:]}")

# æ­¥é©Ÿ 2ï¼šé…ç½®å„ªåŒ–å¾Œçš„åƒæ•¸
logger.info("")
logger.info("æ­¥é©Ÿ 2ï¼šé…ç½®å„ªåŒ–å¾Œçš„å› å­æŒ–æ˜åƒæ•¸")
logger.info("-" * 80)

# å„ªåŒ–å¾Œçš„ç ”ç©¶ç›®æ¨™ï¼ˆæ›´è©³ç´°ã€æ›´å…·é«”ï¼‰
optimized_research_goal = """
ç‚ºå°æŒ‡æœŸè²¨ï¼ˆTXï¼‰è¨­è¨ˆå‰µæ–°çš„çŸ­æœŸå‹•é‡å› å­ï¼Œç›®æ¨™æ˜¯æ•æ‰ 5-20 æ—¥çš„åƒ¹æ ¼è¶¨å‹¢ã€‚

ã€æ ¸å¿ƒè¦æ±‚ã€‘
1. ä½¿ç”¨ Qlib è¡¨é”å¼èªæ³•ï¼ˆä¾‹å¦‚ï¼šMean($close, 20), Std($close, 10), Correlation($close, $volume, 5)ï¼‰
2. çµåˆå¤šå€‹ç¶­åº¦ï¼šåƒ¹é‡é—œä¿‚ã€æ³¢å‹•ç‡èª¿æ•´ã€è¶¨å‹¢å¼·åº¦
3. å‰µæ–°çµ„åˆï¼šé¿å…å–®ç´”çš„ç§»å‹•å¹³å‡ï¼Œæ‡‰çµ„åˆå¤šå€‹å› å­
4. æä¾›è‡³å°‘ 5 å€‹ä¸åŒçš„å€™é¸å› å­

ã€Qlib å¯ç”¨å‡½æ•¸ã€‘
- æ»¯å¾Œï¼šRef($close, 5) - 5å¤©å‰çš„æ”¶ç›¤åƒ¹
- ç§»å‹•å¹³å‡ï¼šMean($close, 20), EMA($close, 12)
- çµ±è¨ˆï¼šStd($close, 20), Max($high, 10), Min($low, 10)
- ç›¸é—œæ€§ï¼šCorrelation($close, $volume, 10)
- æ’åï¼šRank($close), Quantile($close, 0.8)
- æ¢ä»¶ï¼šIf($close > Mean($close, 20), 1, -1)
- é‹ç®—ï¼š+, -, *, /, abs(), sign()

ã€å› å­ç¯„ä¾‹ã€‘
1. åƒ¹é‡å‹•é‡ï¼šCorrelation($close, $volume, 10) * ($close / Ref($close, 5) - 1)
2. æ³¢å‹•èª¿æ•´å‹•é‡ï¼š($close - Mean($close, 20)) / Std($close, 20)
3. è¶¨å‹¢å¼·åº¦ï¼š(Mean($close, 5) - Mean($close, 20)) / Mean($close, 20)
4. åƒ¹é‡èƒŒé›¢ï¼šSign($close - Ref($close, 1)) * Sign($volume - Mean($volume, 20))
5. ç›¸å°å¼·åº¦ï¼šRank($close / Ref($close, 10))

ã€è¼¸å‡ºæ ¼å¼è¦æ±‚ã€‘
- å› å­åç¨±ï¼šä½¿ç”¨è‹±æ–‡ï¼Œç°¡æ½”æè¿°ï¼ˆä¾‹å¦‚ï¼šVolAdjMomentum_10_20ï¼‰
- å…¬å¼ï¼šå¿…é ˆæ˜¯ Qlib è¡¨é”å¼ï¼Œä¸è¦ä½¿ç”¨æ•¸å­¸ç¬¦è™Ÿï¼ˆLaTeXï¼‰
- æè¿°ï¼šç°¡è¦èªªæ˜å› å­é‚è¼¯å’Œé©ç”¨å ´æ™¯
- åˆ†é¡ï¼šmomentum, volatility, volume, trend ä¹‹ä¸€

è«‹ç”Ÿæˆ 5 å€‹å‰µæ–°ä¸”å¯¦ç”¨çš„å› å­ã€‚
"""

request = FactorMiningRequest(
    research_goal=optimized_research_goal,
    stock_pool="tx",
    max_factors=5,           # å¢åŠ åˆ° 5 å€‹
    max_iterations=5,        # å¢åŠ è¿­ä»£æ¬¡æ•¸
    llm_model="gpt-4-turbo"
)

logger.info(f"ğŸ“Š ç ”ç©¶ç›®æ¨™å­—æ•¸ï¼š{len(optimized_research_goal)}")
logger.info(f"ğŸ“ˆ æ¨™çš„æ± ï¼š{request.stock_pool}")
logger.info(f"ğŸ”¢ æœ€å¤§å› å­æ•¸ï¼š{request.max_factors}")
logger.info(f"ğŸ”„ æœ€å¤§è¿­ä»£æ¬¡æ•¸ï¼š{request.max_iterations}")
logger.info(f"ğŸ¤– LLM æ¨¡å‹ï¼š{request.llm_model}")

# æ­¥é©Ÿ 3ï¼šå‰µå»ºä»»å‹™
logger.info("")
logger.info("æ­¥é©Ÿ 3ï¼šå‰µå»º RD-Agent ä»»å‹™")
logger.info("-" * 80)

db: Session = SessionLocal()

try:
    service = RDAgentService(db)
    
    # å‰µå»ºä»»å‹™è¨˜éŒ„
    task = service.create_factor_mining_task(user_id=1, request=request)
    logger.info(f"âœ… ä»»å‹™å·²å‰µå»º (ID: {task.id})")
    
    # æ›´æ–°ç‹€æ…‹ç‚ºé‹è¡Œä¸­
    service.update_task_status(task.id, TaskStatus.RUNNING)
    logger.info(f"âœ… ä»»å‹™ç‹€æ…‹ï¼šRUNNING")
    
    # æ­¥é©Ÿ 4ï¼šåŸ·è¡Œå› å­æŒ–æ˜
    logger.info("")
    logger.info("æ­¥é©Ÿ 4ï¼šåŸ·è¡Œ LLM å› å­æŒ–æ˜")
    logger.info("-" * 80)
    logger.info("ğŸ¤– æ­£åœ¨èª¿ç”¨ GPT-4 ç”Ÿæˆå› å­...")
    logger.info("ğŸ“ ä½¿ç”¨å„ªåŒ–å¾Œçš„ Promptï¼ˆæ›´è©³ç´°çš„è¦æ±‚å’Œç¯„ä¾‹ï¼‰")
    logger.info("âš ï¸  é è¨ˆåŸ·è¡Œæ™‚é–“ï¼š10-20 åˆ†é˜ï¼ˆå› å­æ•¸å’Œè¿­ä»£æ¬¡æ•¸è¼ƒå¤šï¼‰")
    logger.info("")
    
    start_time = datetime.now()
    
    try:
        # åŸ·è¡Œ RD-Agent
        log_dir = service.execute_factor_mining(
            task_id=task.id,
            research_goal=request.research_goal,
            max_iterations=request.max_iterations,
            llm_model=request.llm_model
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds() / 60
        
        logger.info("")
        logger.info("âœ… å› å­æŒ–æ˜åŸ·è¡Œå®Œæˆï¼")
        logger.info(f"â±ï¸  åŸ·è¡Œæ™‚é–“ï¼š{duration:.1f} åˆ†é˜")
        logger.info(f"ğŸ“ æ—¥èªŒç›®éŒ„ï¼š{log_dir}")
        
        # æ­¥é©Ÿ 5ï¼šè§£æçµæœ
        logger.info("")
        logger.info("æ­¥é©Ÿ 5ï¼šè§£æç”Ÿæˆçš„å› å­")
        logger.info("-" * 80)
        
        factors = service.parse_rdagent_results(log_dir)
        logger.info(f"âœ… æˆåŠŸè§£æ {len(factors)} å€‹å› å­")
        
        # è¨ˆç®—æˆæœ¬
        llm_calls, llm_cost = service.calculate_llm_costs(log_dir)
        logger.info(f"ğŸ’° LLM èª¿ç”¨æ¬¡æ•¸ï¼š{llm_calls}")
        logger.info(f"ğŸ’° ä¼°è¨ˆæˆæœ¬ï¼š${llm_cost:.4f} USD")
        
        # æ­¥é©Ÿ 6ï¼šä¿å­˜å› å­
        logger.info("")
        logger.info("æ­¥é©Ÿ 6ï¼šä¿å­˜å› å­åˆ°è³‡æ–™åº«")
        logger.info("-" * 80)
        
        saved_factors = []
        for i, factor_data in enumerate(factors, 1):
            try:
                # æª¢æŸ¥å…¬å¼æ˜¯å¦ç‚º Qlib æ ¼å¼
                formula = factor_data.get("formula", "")
                is_qlib_format = '$' in formula or 'Mean' in formula or 'Std' in formula
                
                logger.info(f"ğŸ“Š [{i}/{len(factors)}] {factor_data.get('name', f'Factor_{i}')}")
                logger.info(f"   å…¬å¼ï¼š{formula[:80]}...")
                logger.info(f"   æ ¼å¼ï¼š{'âœ… Qlib æ ¼å¼' if is_qlib_format else 'âš ï¸ å¯èƒ½éœ€è¦è½‰æ›'}")
                
                factor = service.save_generated_factor(
                    task_id=task.id,
                    user_id=1,
                    name=factor_data.get("name", f"Factor_{i}"),
                    formula=formula,
                    description=factor_data.get("description", ""),
                    category=factor_data.get("category", "llm_generated"),
                    metadata={
                        **factor_data.get("metadata", {}),
                        "is_qlib_format": is_qlib_format,
                        "prompt_version": "optimized_v2"
                    }
                )
                saved_factors.append(factor)
                logger.info(f"   âœ… å› å­å·²ä¿å­˜ (ID: {factor.id})")
                logger.info("")
            except Exception as e:
                logger.error(f"   âŒ ä¿å­˜å¤±æ•—ï¼š{e}")
                logger.error("")
        
        # æ›´æ–°ä»»å‹™ç‹€æ…‹
        service.update_task_status(
            task.id,
            TaskStatus.COMPLETED,
            result={
                "factors_generated": len(saved_factors),
                "execution_time_minutes": duration,
                "log_dir": log_dir,
                "prompt_version": "optimized_v2",
                "factors": [
                    {
                        "id": f.id,
                        "name": f.name,
                        "formula": f.formula,
                        "category": f.category
                    }
                    for f in saved_factors
                ]
            },
            llm_calls=llm_calls,
            llm_cost=llm_cost
        )
        
        # é¡¯ç¤ºçµæœ
        logger.info("")
        logger.info("=" * 80)
        logger.info("ğŸ‰ å„ªåŒ–ç‰ˆå› å­æŒ–æ˜æµç¨‹æˆåŠŸï¼")
        logger.info("=" * 80)
        logger.info(f"ğŸ“Š ä»»å‹™ IDï¼š{task.id}")
        logger.info(f"ğŸ“ˆ ç”Ÿæˆå› å­æ•¸ï¼š{len(saved_factors)}")
        logger.info(f"â±ï¸  ç¸½è€—æ™‚ï¼š{duration:.1f} åˆ†é˜")
        logger.info(f"ğŸ’° LLM æˆæœ¬ï¼š${llm_cost:.4f} USD")
        logger.info("")
        logger.info("ğŸ“‹ ç”Ÿæˆçš„å› å­ï¼š")
        for factor in saved_factors:
            logger.info("")
            logger.info(f"   ğŸ“ˆ {factor.name} (ID: {factor.id})")
            logger.info(f"      å…¬å¼ï¼š{factor.formula[:100]}...")
            logger.info(f"      åˆ†é¡ï¼š{factor.category}")
        logger.info("")
        logger.info("ğŸ’¡ ä¸‹ä¸€æ­¥ï¼š")
        logger.info("   1. é©—è­‰æ¯å€‹å› å­çš„ Qlib è¡¨é”å¼")
        logger.info("   2. è¨ˆç®—å› å­ IC å€¼")
        logger.info("   3. æ’å…¥ç­–ç•¥é€²è¡Œå›æ¸¬")
        
    except Exception as e:
        # åŸ·è¡Œå¤±æ•—
        logger.error("")
        logger.error("=" * 80)
        logger.error("âŒ å› å­æŒ–æ˜åŸ·è¡Œå¤±æ•—")
        logger.error("=" * 80)
        logger.error(f"éŒ¯èª¤è¨Šæ¯ï¼š{e}")
        
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"å®Œæ•´éŒ¯èª¤ï¼š\n{error_trace}")
        
        # æ›´æ–°ä»»å‹™ç‹€æ…‹ç‚ºå¤±æ•—
        service.update_task_status(
            task.id,
            TaskStatus.FAILED,
            error_message=str(e)
        )
        
        sys.exit(1)
        
finally:
    db.close()

logger.info("")
logger.info(f"â° çµæŸæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
